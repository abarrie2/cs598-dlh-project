{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abarrie2/cs598-dlh-project/blob/main/DL4H_Team_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The paper selected for this project is titled \"Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study\" [1].\n",
        "\n",
        "## Background of the problem\n",
        "\n",
        "The problem being investigated by this study relates to the prediction of Intraoperative Hypotension (IOH). IOH is an event that can occur during durgery where there is a drop in mean arterial blood pressure to less than 65 mmHg. This event is important to consider because it can be associated with multiple negative postoperative outcomes including postoperative myocardial infarction, acute kidney injury, and postoperative mortality. There are multiple factors that can contribute to instances of IOH, and if there were an ability to identify IOH in advance then medical personnel could take steps to mitigate the IOH event. This is important because a prevention or minimization of IOH events may reduce the probability of the negative postoperative outcomes described above. The paper is an investigation into the problem of IOH event prediction, specifically predicting whether, based on vital signals, there will be an IOH event in 7, 5, 10, or 15 minutes time.\n",
        "\n",
        "Our selected paper is an extension of another study titled \"Machine-learning Algorithm to Predict Hypotension Based on High-fidelity Arterial Pressure Waveform Analysis\" [2], which attempted to train a model to predict instances of Intraoperative Hypotension using Arterial Blood Pressure (ABP) signals. While that original paper focused solely on training against arterial blood pressure (ABP) waveforms, our selected paper seeks to measure whether predictive outcomes are improved by incorporating additional vital signals. Specifically, the paper investigates the impact to quality of IOH prediction by training not only on ABP signals, but also electrocardiogram (ECG) signals, electroencephalogram (EEG) signals, and various combination of all three.\n",
        "\n",
        "The key difficulty in this area of research is that the benefit of a predictive model would occur only by the use of such a model within a surgical environment. This paper does not aim to demonstrate the feasibility of operating a realtime signal analysis model, instead focusing on the potential predictive benefits of incorporating vital signals beyond ABP in order to improve the quality of predictions for IOH events.\n",
        "\n",
        "While this paper is an investigation into the augmentation of ABP signal analysis with additional vital signals, the state of the art for IOH prediction involves models that have been incorporated into medical devices that are deployed in the operating room. A recently published study titled \"AcumenTM hypotension prediction index guidance for prevention and treatment of hypotension in noncardiac surgery: a prospective, single-arm, multicenter trial\" [3] wherein the predictive models were used during surgeries. The participants clinicians were warned by the predictive technology and enabled to intervene and prevent or reduce the duration of IOH events. The conclusion of the AcumenTM paper determined that the use of such prediction software was associated with a clinically meaningful reudction in the duration of IOH events, but that further studies are required to investigate whether these models could be used to prevent IOH events entirely.\n",
        "\n",
        "## Our Paper\n",
        "\n",
        "The paper proposed that training a model on some combination of ABP, ECG, and EEG signals would improve result in a model that would function better at predicting IOH. The key innovation relative to preceding research in this area is the inclusion of EEG and ECG signal data in the operation of the model, whereas preceding research focused primarily on making predictions based solely on ABP data. The paper concluded that the combination of ABP and EEG signals may result in improved model performance when predicting IOH events. The experimental results demonstrated that by both area under the receiver operating characteristic (AUROC) and area under the precision-recall curve (AUPRC) measures, a model trained on the combination of ABP and EEG scored higher than a model trained solely on ABP across all prediction intervals (i.e., for predictions 7, 5, 10, and 15 minutes ahead of an IOH event). The main contribution to the research regime for prediction IOH is that it validates the hypothesis that a combination of vital signals able to monitored during surgery will improve predictive quality. While that benefit is marginal, this research provides a quantifiable measure to demonstrate the magnitude of this improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "The original paper investigated the following hypotheses:\n",
        "\n",
        "1.   Hypothesis 1: Using AUROC and AUPRC scores, a model using ABP and ECG will perform better than a model using only ABP.\n",
        "2.   Hypothesis 2: Using AUROC and AUPRC scores, a model using ABP and EEG will perform better than a model using only ABP.\n",
        "3.   Hypothesis 3: Using AUROC and AUPRC scores, a model using ABP, EEG, and ECG will perform better than a model using only ABP.\n",
        "\n",
        "Based on the results described in the original paper, we expect that Hypothesis 2 will be confirmed, and that Hypotheses 1 and 3 will not be confirmed. In order to perform the corresponding experiments, we will implement a CNN-based model that can be configured to train and infer using the following four model variations:\n",
        "\n",
        "1.   ABP data alone\n",
        "2.   ABP and ECG data\n",
        "3.   ABP and EEG data\n",
        "4.   ABP, ECG, and EEG data\n",
        "\n",
        "We will measure the performance of these configurations using the same AUROC and AUPRC metrics as used in the original paper. To test hypothesis 1 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 2. To test hypothesis 2 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 3. To test hypothesis 3 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 4. For all of the above measures and experiment combinations, we are going to be operating multiple experiments, one where the time-to-IOH event prediction will be broken out into the following times:\n",
        "\n",
        "1. 3 minutes before event\n",
        "2. 5 minutes before event\n",
        "3. 10 minutes before event\n",
        "4. 15 minutes before event\n",
        "\n",
        "[note to self: should we include Table 3 from the original paper (auroc/auprc/sensitive/specificity/threshold scores for all signal combinations)]\n",
        "\n",
        "[note to self: should we include Figure 4 from the original paper (charts comparing risk indices for ABP, EEG, ABP+EEG)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "TODO for draft: plain english summary of the objectives of all of the code sections within the methodology section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create environment\n",
        "\n",
        "Create `conda` environment for the project using the `environment.yml` file:\n",
        "\n",
        "```bash\n",
        "conda env create --prefix .envs/dlh-team24 -f environment.yml\n",
        "```\n",
        "\n",
        "Activate the environment with:\n",
        "```bash\n",
        "conda activate .envs/dlh-team24\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "#install vitaldb\n",
        "%pip install vitaldb\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import vitaldb\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "#from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data\n",
        "\n",
        "TODO for draft: author this section\n",
        "\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Up Local Data Caches\n",
        "\n",
        "Since the VitalDB data is static, local copies are stored and reused to avoid expensive downloads and to speed up data processing.\n",
        "\n",
        "The default directory defined below is already in the project `.gitignore` file. If later modified, it should also be added to the project `.gitignore`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VITALDB_CACHE = './vitaldb_cache'\n",
        "VITAL_ALL = 'vital_all'\n",
        "VITAL_MINI = 'vital_mini'\n",
        "VITAL_METADATA = 'metadata'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.name == 'nt':\n",
        "  # windows variant\n",
        "  if not os.path.exists(VITALDB_CACHE):\n",
        "    os.mkdir(VITALDB_CACHE)\n",
        "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_ALL}'):\n",
        "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_ALL}')\n",
        "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_MINI}'):\n",
        "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_MINI}')\n",
        "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_METADATA}'):\n",
        "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_METADATA}')\n",
        "\n",
        "  print(os.listdir(VITALDB_CACHE))\n",
        "else:\n",
        "  # mac/linux variant\n",
        "  !mkdir -p $VITALDB_CACHE\n",
        "  !mkdir -p $VITALDB_CACHE/$VITAL_ALL\n",
        "  !mkdir -p $VITALDB_CACHE/$VITAL_MINI\n",
        "  !mkdir -p $VITALDB_CACHE/$VITAL_METADATA\n",
        "  !ls -l $VITALDB_CACHE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OSFS Bulk Data Download\n",
        "\n",
        "**This step is not required, but will significantly speed up downstream processing and avoid a high volume of API requests to the VitalDB web site.**\n",
        "\n",
        "The cache population code checks if OSFS bulk download data of VitalDB vital files is locally available.\n",
        "\n",
        "- Manually downloaded the OSF Store archives from the following site: https://osf.io/dtc45/\n",
        "    - `Vital Files 0001-2000`\n",
        "    - `Vital Files 2001-4000`\n",
        "    - `Vital Files 4001-6388`\n",
        "- Once the `OSF Storage (United States)` link is clicked a `Download as zip` link will appear.\n",
        "- Once downloaded, extract each of the 3 zip archives.\n",
        "- Move all files from each of the unzip directories into the `${VITALDB_CACHE}/${VITAL_ALL}` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Returns the Pandas DataFrame for the specified dataset.\n",
        "#   One of 'cases', 'labs', or 'trks'\n",
        "# If the file exists locally, create and return the DataFrame.\n",
        "# Else, download and cache the csv first, then return the DataFrame.\n",
        "def vitaldb_dataframe_loader(dataset_name):\n",
        "    if dataset_name not in ['cases', 'labs', 'trks']:\n",
        "        raise ValueError(f'Invalid dataset name: {dataset_name}')\n",
        "    file_path = f'{VITALDB_CACHE}/{VITAL_METADATA}/{dataset_name}.csv'\n",
        "    if os.path.isfile(file_path):\n",
        "        print(f'{dataset_name}.csv exists locally.')\n",
        "        df = pd.read_csv(file_path)\n",
        "        return df\n",
        "    else:\n",
        "        print(f'downloading {dataset_name} and storing in the local cache for future reuse.')\n",
        "        df = pd.read_csv(f'https://api.vitaldb.net/{dataset_name}')\n",
        "        df.to_csv(file_path, index=False)\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cases = vitaldb_dataframe_loader('cases')\n",
        "cases = cases.set_index('caseid')\n",
        "cases.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cases.index.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cases.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cases['sex'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks = vitaldb_dataframe_loader('trks')\n",
        "trks = trks.set_index('caseid')\n",
        "trks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks.index.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks.groupby('caseid')[['tid']].count().plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks.groupby('caseid')[['tid']].count().hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks.groupby('tname').count().sort_values(by='tid', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters of Interest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hemodynamic Parameters Reference\n",
        "https://vitaldb.net/dataset/?query=overview#h.f7d712ycdpk2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Solar8000/ART_MBP**\n",
        "\n",
        "mean blood pressure\n",
        "\n",
        "Parameter, Description, Type/Hz, Unit\n",
        "\n",
        "Solar8000/ART_MBP, Mean arterial pressure, N, mmHg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks[trks['tname'].str.contains('Solar8000/ART_MBP')].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**SNUADC/ART**\n",
        "\n",
        "arterial blood pressure waveform\n",
        "\n",
        "Parameter, Description, Type/Hz, Unit\n",
        "\n",
        "SNUADC/ART, Arterial pressure wave, W/500, mmHg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks[trks['tname'].str.contains('SNUADC/ART')].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**SNUADC/ECG_II**\n",
        "\n",
        "electrocardiogram waveform\n",
        "\n",
        "Parameter, Description, Type/Hz, Unit\n",
        "\n",
        "SNUADC/ECG_II, ECG lead II wave, W/500, mV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks[trks['tname'].str.contains('SNUADC/ECG_II')].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BIS/EEG1_WAV**\n",
        "\n",
        "electroencephalogram waveform\n",
        "\n",
        "Parameter, Description, Type/Hz, Unit\n",
        "\n",
        "BIS/EEG1_WAV, EEG wave from channel 1, W/128, uV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks[trks['tname'].str.contains('BIS/EEG1_WAV')].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cases of Interest\n",
        "\n",
        "These are the subset of case ids for which modelling and analysis will be performed based upon inclusion criteria and waveform data availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']\n",
        "TRACK_SRATES = [500, 500, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# As in the paper, select cases which meet the following criteria:\n",
        "#\n",
        "# For patients, the inclusion criteria were as follows:\n",
        "# (1) adults (age >= 18)\n",
        "# (2) administered general anaesthesia\n",
        "# (3) undergone non-cardiac surgery. \n",
        "#\n",
        "# For waveform data, the inclusion criteria were as follows:\n",
        "# (1) no missing monitoring for ABP, ECG, and EEG waveforms\n",
        "# (2) no cases containing false events or non-events due to poor signal quality\n",
        "#     (checked in second stage of data preprocessing)\n",
        "\n",
        "# adult\n",
        "inclusion_1 = cases.loc[cases['age'] >= 18].index\n",
        "print(f'{len(cases)-len(inclusion_1)} cases excluded, {len(inclusion_1)} remaining due to age criteria')\n",
        "\n",
        "# general anesthesia\n",
        "inclusion_2 = cases.loc[cases['ane_type'] == 'General'].index\n",
        "print(f'{len(cases)-len(inclusion_2)} cases excluded, {len(inclusion_2)} remaining due to anesthesia criteria')\n",
        "\n",
        "# non-cardiac surgery\n",
        "inclusion_3 = cases.loc[\n",
        "    ~cases['opname'].str.contains(\"cardiac\", case=False)\n",
        "    & ~cases['opname'].str.contains(\"aneurysmal\", case=False)\n",
        "].index\n",
        "print(f'{len(cases)-len(inclusion_3)} cases excluded, {len(inclusion_3)} remaining due to non-cardiac surgery criteria')\n",
        "\n",
        "# ABP, ECG, EEG waveforms\n",
        "inclusion_4 = trks.loc[trks['tname'].isin(TRACK_NAMES)].index.value_counts()\n",
        "inclusion_4 = inclusion_4[inclusion_4 == len(TRACK_NAMES)].index\n",
        "print(f'{len(cases)-len(inclusion_4)} cases excluded, {len(inclusion_4)} remaining due to missing waveform data')\n",
        "\n",
        "cases_of_interest_idx = inclusion_1 \\\n",
        "    .intersection(inclusion_2) \\\n",
        "    .intersection(inclusion_3) \\\n",
        "    .intersection(inclusion_4)\n",
        "\n",
        "cases_of_interest = cases.loc[cases_of_interest_idx]\n",
        "\n",
        "print()\n",
        "print(f'{cases_of_interest_idx.shape[0]} out of {cases.shape[0]} total cases remaining after exclusions applied')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cases_of_interest.head(n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tracks of Interest\n",
        "\n",
        "These are the subset of tracks (waveforms) for the cases of interest identified above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A single case maps to one or more waveform tracks. Select only the tracks required for analysis.\n",
        "trks_of_interest = trks.loc[cases_of_interest_idx][trks.loc[cases_of_interest_idx]['tname'].isin(TRACK_NAMES)]\n",
        "trks_of_interest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks_of_interest.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trks_of_interest_idx = trks_of_interest.set_index('tid').index\n",
        "trks_of_interest_idx.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Tracks Cache for Local Processing\n",
        "\n",
        "Tracks data are large and therefore expensive to download every time used.\n",
        "By default, the vital file format stores all tracks for each case internally. Since only certain tracks per case are required, each vital file can be further truncated to only store the tracks for needed waveforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Maximum number of cases of interest for which to download data.\n",
        "# Set to a small value for demo purposes, else set to None to disable and download all.\n",
        "MAX_CASES = None\n",
        "#MAX_CASES = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trim cases of interest to MAX_CASES\n",
        "if MAX_CASES:\n",
        "    cases_of_interest_idx = cases_of_interest_idx[:MAX_CASES]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure the full vital file dataset is available for cases of interest.\n",
        "count_downloaded = 0\n",
        "count_present = 0\n",
        "\n",
        "#for i, idx in enumerate(cases.index):\n",
        "for i, idx in enumerate(cases_of_interest_idx):\n",
        "    if MAX_CASES and i >= MAX_CASES:\n",
        "        break\n",
        "\n",
        "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
        "    if not os.path.isfile(full_path):\n",
        "        print(f'Missing vital file: {full_path}')\n",
        "        # Download and save the file.\n",
        "        vf = vitaldb.VitalFile(idx)\n",
        "        vf.to_vital(full_path)\n",
        "        count_downloaded += 1\n",
        "    else:\n",
        "        count_present += 1\n",
        "\n",
        "print()\n",
        "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
        "print(f'Count of vital files downloaded:      {count_downloaded}')\n",
        "print(f'Count of vital files already present: {count_present}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert vital files to \"mini\" versions including only the subset of tracks based on TRACK_NAMES defined above.\n",
        "# Only perform conversion for the cases of interest.\n",
        "# NOTE: If this cell is interrupted, it can be restarted and will continue where it left off.\n",
        "count_minified = 0\n",
        "count_present = 0\n",
        "\n",
        "for i, idx in enumerate(cases_of_interest_idx):\n",
        "    if MAX_CASES and i >= MAX_CASES:\n",
        "        break\n",
        "    \n",
        "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
        "    mini_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{idx:04d}_mini.vital'\n",
        "    if not os.path.isfile(mini_path):\n",
        "        print(f'Creating mini vital file: {idx}')\n",
        "        vf = vitaldb.VitalFile(full_path, TRACK_NAMES)\n",
        "        vf.to_vital(mini_path)\n",
        "        count_minified += 1\n",
        "    else:\n",
        "        count_present += 1\n",
        "\n",
        "print()\n",
        "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
        "print(f'Count of vital files minified:        {count_minified}')\n",
        "print(f'Count of vital files already present: {count_present}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exclude cases where ABP j signal quality (jSQI) < 0.8\n",
        "# TODO: Implement jSQI function\n",
        "# TODO: Filter cases with jSQI < 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate hypotensive events\n",
        "# Hypotensive events are defined as a 1-minute interval with sustained ABP of less than 65 mmHg\n",
        "# Note: Hypotensive events should be at least 20 minutes apart to minimize potential residual effects from previous events\n",
        "# TODO: Implement hypotension event generation function\n",
        "# TODO: Generate hypotension events\n",
        "\n",
        "# Generate hypotension non-events\n",
        "# To sample non-events, 30-minute segments where the ABP was above 75 mmHG were selected, and then\n",
        "# three one-minute samples of each waveform were obtained from the middle of the segment\n",
        "# TODO: Implement hypotension non-event generation function\n",
        "# TODO: Generate hypotension non-events\n",
        "\n",
        "# XXX Create dummy events with random labels for now\n",
        "def generate_dummy_data(cases_of_interest_idx):\n",
        "    # Initialize an empty DataFrame\n",
        "    generated_data = []\n",
        "    \n",
        "    # Loop through each case index\n",
        "    for case in cases_of_interest_idx:\n",
        "        # Generate a random number of rows between 5 and 20\n",
        "        num_rows = random.randint(5, 20)\n",
        "        \n",
        "        # Generate data for each row\n",
        "        for _ in range(num_rows):\n",
        "            starttime = random.randint(0, 1200)\n",
        "            endtime = starttime + 60\n",
        "            label = random.randint(0, 1)\n",
        "            \n",
        "            # Append the data to the DataFrame\n",
        "            generated_data.append([\n",
        "                case,\n",
        "                starttime,\n",
        "                endtime,\n",
        "                label\n",
        "            ])\n",
        "    \n",
        "    return pd.DataFrame(generated_data, columns=['caseidx', 'starttime', 'endtime', 'label'])\n",
        "samples = generate_dummy_data(cases_of_interest_idx)\n",
        "samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data tracks\n",
        "\n",
        "# ABP waveforms are used without further pre-processing\n",
        "# ECG waveforms are band-pass filtered between 1 and 40 Hz, and Z-score normalized\n",
        "# EEG waveforms are band-pass filtered between 0.5 and 40 Hz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training, validation, and test sets\n",
        "# Use 6:1:3 ratio and prevent samples from a single case from being split across different sets\n",
        "# Note: number of samples at each time point is not the same, because the first event can occur before the 3/5/10/15 minute mark\n",
        "\n",
        "# Set target sizes\n",
        "train_ratio = 0.6\n",
        "val_ratio = 0.1\n",
        "test_ratio = 1 - train_ratio - val_ratio # ensure ratios sum to 1\n",
        "\n",
        "# Assume that on average cases have the ~same number of events so we can split by case rather than event\n",
        "# Note: this means that the ratios will be approximate\n",
        "\n",
        "# Get unique cases\n",
        "unique_cases = samples['caseidx'].unique()\n",
        "\n",
        "# Split cases into train and other\n",
        "train_caseidx, other_caseidx = train_test_split(unique_cases, test_size=(1 - train_ratio), random_state=42)\n",
        "# Split other into val and test\n",
        "val_caseidx, test_caseidx = train_test_split(other_caseidx, test_size=(test_ratio / (1 - train_ratio)), random_state=42)\n",
        "\n",
        "# Create datasets\n",
        "samples_train = samples[samples['caseidx'].isin(train_caseidx)]\n",
        "samples_val = samples[samples['caseidx'].isin(val_caseidx)]\n",
        "samples_test = samples[samples['caseidx'].isin(test_caseidx)]\n",
        "\n",
        "# Check how many samples are in each set\n",
        "print(f\"Train samples: {len(samples_train)}, ({len(samples_train) / len(samples):.2%})\")\n",
        "print(f\"Val samples: {len(samples_val)}, ({len(samples_val) / len(samples):.2%})\")\n",
        "print(f\"Test samples: {len(samples_test)}, ({len(samples_test) / len(samples):.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create vitalDataset class\n",
        "class vitalDataset(Dataset):\n",
        "    def __init__(self, file_dir, samples, track_names, track_srates_hz):\n",
        "        # samples should be a list of (caseidx, starttime, endtime, label)\n",
        "        self.file_dir = file_dir\n",
        "        self.samples = samples\n",
        "        self.track_names = track_names\n",
        "        self.track_srates_hz = track_srates_hz\n",
        "        self.vf_dict = {}\n",
        "\n",
        "        self.ABP_TRACK_NAME = \"SNUADC/ART\"\n",
        "        self.ECG_TRACK_NAME = \"SNUADC/ECG_II\"\n",
        "        self.EEG_TRACK_NAME = \"BIS/EEG1_WAV\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get metadata for this event\n",
        "        caseidx, starttime, endtime, label = self.samples.iloc[idx]\n",
        "\n",
        "        # Load vital file\n",
        "        # commented version is for the full vital file\n",
        "        # file_path = os.path.join(self.file_dir, f\"{caseidx:04d}.vital\")\n",
        "        file_path = os.path.join(self.file_dir, f\"{caseidx:04d}_mini.vital\")\n",
        "\n",
        "        if file_path not in self.vf_dict:\n",
        "          print(f\"[{datetime.now()}] Loading vital file {file_path}\")\n",
        "          # TODO in-mem filecache has no pruning mechanism. will bloat dramatically if full dataset used\n",
        "          vf = vitaldb.VitalFile(file_path, self.track_names)\n",
        "          # Crop samples to target interval\n",
        "          vf.crop(starttime, endtime)\n",
        "          self.vf_dict[file_path] = vf\n",
        "          \n",
        "        # pull parsed VitalFile object from in-mem cache rather than parse same input file multiple times for each segment of interest\n",
        "        vf = self.vf_dict[file_path]\n",
        "\n",
        "        abp = None\n",
        "        eeg = None\n",
        "        ecg = None\n",
        "        # Populate each track\n",
        "        for i, (track_name, rate) in enumerate(zip(self.track_names, self.track_srates_hz)):\n",
        "            # Get samples for this track\n",
        "            track_samples, _ = vf.get_samples(track_name, 1/rate)\n",
        "            # Convert to tensor and store in samples\n",
        "            start = int((endtime-starttime)*rate)\n",
        "            end = start + int((endtime-starttime)*rate)\n",
        "\n",
        "            # for some reason only pulling out one minute with each read. as a result, trying to index by random start/end runs past the end of len(track_samples)\n",
        "            #interval_data = torch.tensor(track_samples[start:end])\n",
        "            interval_data = torch.tensor(track_samples[0:end-start])\n",
        "            \n",
        "            if track_name == self.ABP_TRACK_NAME:\n",
        "                abp = interval_data\n",
        "            elif track_name == self.ECG_TRACK_NAME:\n",
        "                ecg = interval_data\n",
        "            elif track_name == self.EEG_TRACK_NAME:\n",
        "                eeg = interval_data\n",
        "\n",
        "        return abp, ecg, eeg, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = vitalDataset(f'{VITALDB_CACHE}/{VITAL_MINI}/', samples_train, TRACK_NAMES, TRACK_SRATES)\n",
        "val_dataset = vitalDataset(f'{VITALDB_CACHE}/{VITAL_MINI}/', samples_val, TRACK_NAMES, TRACK_SRATES)\n",
        "test_dataset = vitalDataset(f'{VITALDB_CACHE}/{VITAL_MINI}/', samples_test, TRACK_NAMES, TRACK_SRATES)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "# dir and function to load raw data\n",
        "raw_data_dir = '/content/gdrive/My Drive/Colab Notebooks/<path-to-raw-data>'\n",
        "\n",
        "def load_raw_data(raw_data_dir):\n",
        "  # implement this function to load raw data to dataframe/numpy array/tensor\n",
        "  return None\n",
        "\n",
        "raw_data = load_raw_data(raw_data_dir)\n",
        "\n",
        "# calculate statistics\n",
        "def calculate_stats(raw_data):\n",
        "  # implement this function to calculate the statistics\n",
        "  # it is encouraged to print out the results\n",
        "  return None\n",
        "\n",
        "# process raw data\n",
        "def process_data(raw_data):\n",
        "    # implement this function to process the data as you need\n",
        "  return None\n",
        "\n",
        "processed_data = process_data(raw_data)\n",
        "\n",
        "''' you can load the processed data directly\n",
        "processed_data_dir = '/content/gdrive/My Drive/Colab Notebooks/<path-to-raw-data>'\n",
        "def load_processed_data(raw_data_dir):\n",
        "  pass\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##   Model\n",
        "\n",
        "This model is an implementation of the CNN described in our selected paper. It can train and infer using 1, 2, or 3 different signal categories. I.e., the same model definition can use different initialization parameters to drive a model that uses:\n",
        " * ABP alone\n",
        " * EEG alone\n",
        " * ECG alone\n",
        " * ABP + EEG\n",
        " * ABP + ECG\n",
        " * EEG + ECG\n",
        " * ABP + EEG + ECG\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "[TODO for final report - embed Figure 2 from the original paper]\n",
        "\n",
        "Due to different frequency of the input signal, the hyperparameters will differ for EEG signals as opposed to ABP and ECG signals, but aside from that the general model architecture will be the same for each signal. The model is defined by a residual block containing 7 layers which will be described below. Each signal will pass through 12 instances of the residual block before being flattened and passed through a linear layer ultimately producing 32 parameters. Each signal path will then be concatenated (unless only one signal was configured for use). This concatenated set will be passed through two more linear layers to produce a single vector representing the IOH index. A threshold value would be subsequently applied to this index to perform the binary classification determining whether or not an IOH event is being predicted. This means that each signal passes through 85 layers before concatenation, and then 2 more linear layers and an output sigmoid activation layer before the prediction measure is produced.\n",
        "\n",
        "### Residual Block Definition\n",
        "\n",
        "Each residual block is made of the following seven layers:\n",
        " \n",
        " * Batch normalization\n",
        " * ReLU\n",
        " * Dropout (0.5)\n",
        " * 1D convolution\n",
        " * Batch normalization\n",
        " * ReLU\n",
        " * 1D convolution\n",
        "\n",
        "Each block also features a skip connection which is itself conditionally passed through a 1D convolution where appropriate to maintain dimensions consistent with the output of the layers.\n",
        "\n",
        "#### Residual Block Parameters\n",
        "##### ECG and ABP\n",
        " * Residual block 1:\n",
        "   * Input size: 30000 * 1\n",
        "   * Kernel Size 15\n",
        "   * Channel Size 2\n",
        "   * Output size: 15000 * 2 (downsize via Max Pooling)\n",
        " * Residual block 2:\n",
        "   * Input size: 15000 * 2\n",
        "   * Kernel Size 15\n",
        "   * Channel Size 2\n",
        "   * Output size: 15000 * 2\n",
        " * Residual block 3:\n",
        "   * Input size: 15000 * 2\n",
        "   * Kernel Size 15\n",
        "   * Channel Size 2\n",
        "   * Output size: 7500 * 2 (downsize via Max Pooling)\n",
        " * Residual block 4:\n",
        "   * Input size: 7500 * 2\n",
        "   * Kernel Size 15\n",
        "   * Channel Size 2\n",
        "   * Output size: 7500 * 2\n",
        " * Residual block 5:\n",
        "   * Input size: 7500 * 2\n",
        "   * Kernel Size 15\n",
        "   * Channel Size 2\n",
        "   * Output size: 3750 * 2 (downsize via Max Pooling)\n",
        " * Residual block 6:\n",
        "   * Input size: 3750 * 2\n",
        "   * Kernel Size 15\n",
        "   * Channel Size 4\n",
        "   * Output size: 3750 * 4\n",
        " * Residual block 7:\n",
        "   * Input size: 3750 * 4\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 4\n",
        "   * Output size: 1875 * 4 (downsize via Max Pooling)\n",
        " * Residual block 8:\n",
        "   * Input size: 1875 * 4\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 4\n",
        "   * Output size: 1875 * 4\n",
        " * Residual block 9:\n",
        "   * Input size: 1875 * 4\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 4\n",
        "   * Output size: 938 * 4 (downsize via Max Pooling)\n",
        " * Residual block 10:\n",
        "   * Input size: 938 * 4\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 6\n",
        "   * Output size: 938 * 6\n",
        " * Residual block 11:\n",
        "   * Input size: 938 * 6\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 4\n",
        "   * Output size: 496 * 6 (downsize via Max Pooling)\n",
        " * Residual block 12:\n",
        "   * Input size: 496 * 6\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 6\n",
        "   * Output size: 496 * 6\n",
        "##### EEG\n",
        " * Residual block 1:\n",
        "   * Input size: 7680 * 1\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 2\n",
        "   * Output size: 3840 * 2 (downsize via Max Pooling)\n",
        " * Residual block 2:\n",
        "   * Input size: 3840 * 2\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 2\n",
        "   * Output size: 3840 * 2\n",
        " * Residual block 3:\n",
        "   * Input size: 3840 * 2\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 2\n",
        "   * Output size: 1920 * 2 (downsize via Max Pooling)\n",
        " * Residual block 4:\n",
        "   * Input size: 1920 * 2\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 2\n",
        "   * Output size: 1920 * 2\n",
        " * Residual block 5:\n",
        "   * Input size: 1920 * 2\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 2\n",
        "   * Output size: 960 * 2 (downsize via Max Pooling)\n",
        " * Residual block 6:\n",
        "   * Input size: 960 * 2\n",
        "   * Kernel Size 7\n",
        "   * Channel Size 4\n",
        "   * Output size: 960 * 4\n",
        " * Residual block 7:\n",
        "   * Input size: 960 * 4\n",
        "   * Kernel Size 3\n",
        "   * Channel Size 4\n",
        "   * Output size: 480 * 4 (downsize via Max Pooling)\n",
        " * Residual block 8:\n",
        "   * Input size: 480 * 4\n",
        "   * Kernel Size 3\n",
        "   * Channel Size 4\n",
        "   * Output size: 480 * 4\n",
        " * Residual block 9:\n",
        "   * Input size: 480 * 4\n",
        "   * Kernel Size 3\n",
        "   * Channel Size 4\n",
        "   * Output size: 240 * 4 (downsize via Max Pooling)\n",
        " * Residual block 10:\n",
        "   * Input size: 240 * 4\n",
        "   * Kernel Size 3\n",
        "   * Channel Size 6\n",
        "   * Output size: 240 * 6\n",
        " * Residual block 11:\n",
        "   * Input size: 240 * 6\n",
        "   * Kernel Size 3\n",
        "   * Channel Size 4\n",
        "   * Output size: 120 * 6 (downsize via Max Pooling)\n",
        " * Residual block 12:\n",
        "   * Input size: 120 * 6\n",
        "   * Kernel Size 3\n",
        "   * Channel Size 6\n",
        "   * Output size: 120 * 6\n",
        "\n",
        "### Training Objectives\n",
        "Our model replicates the loss function and optimizer decisions used in our selected paper. The loss function uses binary cross entropy, and the optimizer is Adam. A learning rate of 0.0001 is used. The model will train for 100 epochs, but will exit early if there is no measured \n",
        "\n",
        "[TODO for final report - weight of each loss term]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "outputs": [],
      "source": [
        "# First define the residual block which is reused 12x for each data track for each sample.\n",
        "# Second define the primary model.\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, size_down: bool = False) -> None:\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        # calculate the appropriate padding required to ensure expected sequence lengths out of each residual block\n",
        "        padding = int((((stride-1)*in_features)-stride+kernel_size)/2)\n",
        "\n",
        "        # TODO for final - paper is not clear where the size down occurs \n",
        "        self.size_down = size_down\n",
        "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
        "        \n",
        "        self.residualConv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
        "\n",
        "        # unclear where in sequence this hsuold take place. Size down expressed in Supplemental table S1\n",
        "        if self.size_down:\n",
        "            pool_padding = (1 if (in_features % 2 > 0) else 0)\n",
        "            self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding = pool_padding)\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "        \n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        if self.size_down:\n",
        "            out = self.downsample(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        \n",
        "        if out.shape != identity.shape:\n",
        "            # run the residual through a convolution when necessary\n",
        "            identity = self.residualConv(identity)\n",
        "            \n",
        "            outlen = np.prod(out.shape)\n",
        "            idlen = np.prod(identity.shape)\n",
        "            # downsample when required\n",
        "            if idlen > outlen:\n",
        "                identity = self.downsample(identity)\n",
        "            # match dimensions\n",
        "            identity = identity.reshape(out.shape)\n",
        "       \n",
        "        # add the residual       \n",
        "        out += identity\n",
        "\n",
        "        return  out\n",
        "\n",
        "class HypotensionCNN(nn.Module):\n",
        "    def __init__(self, useAbp: bool = True, useEeg: bool = False, useEcg: bool = False) -> None:\n",
        "        super(HypotensionCNN, self).__init__()\n",
        "\n",
        "        self.useAbp = useAbp\n",
        "        self.useEeg = useEeg\n",
        "        self.useEcg = useEcg\n",
        "\n",
        "        if useAbp:\n",
        "            self.abpBlock1 = ResidualBlock(30000, 15000, 1, 2, 15, 1, True)\n",
        "            self.abpBlock2 = ResidualBlock(15000, 15000, 2, 2, 15, 1, False)\n",
        "            self.abpBlock3 = ResidualBlock(15000, 7500, 2, 2, 15, 1, True)\n",
        "            self.abpBlock4 = ResidualBlock(7500, 7500, 2, 2, 15, 1, False)\n",
        "            self.abpBlock5 = ResidualBlock(7500, 3750, 2, 2, 15, 1, True)\n",
        "            self.abpBlock6 = ResidualBlock(3750, 3750, 2, 4, 15, 1, False)\n",
        "            self.abpBlock7 = ResidualBlock(3750, 1875, 4, 4, 7, 1, True)\n",
        "            self.abpBlock8 = ResidualBlock(1875, 1875, 4, 4, 7, 1, False)\n",
        "            self.abpBlock9 = ResidualBlock(1875, 938, 4, 4, 7, 1, True)\n",
        "            self.abpBlock10 = ResidualBlock(938, 938, 4, 4, 7, 1, False)\n",
        "            self.abpBlock11 = ResidualBlock(938, 469, 4, 6, 7, 1, True)\n",
        "            self.abpBlock12 = ResidualBlock(469, 469, 6, 6, 7, 1, False)\n",
        "            self.abpFc = nn.Linear(6*469, 32)\n",
        "        \n",
        "        if useEcg:\n",
        "            self.ecgBlock1 = ResidualBlock(30000, 15000, 1, 2, 15, 1, True)\n",
        "            self.ecgBlock2 = ResidualBlock(15000, 15000, 2, 2, 15, 1, False)\n",
        "            self.ecgBlock3 = ResidualBlock(15000, 7500, 2, 2, 15, 1, True)\n",
        "            self.ecgBlock4 = ResidualBlock(7500, 7500, 2, 2, 15, 1, False)\n",
        "            self.ecgBlock5 = ResidualBlock(7500, 3750, 2, 2, 15, 1, True)\n",
        "            self.ecgBlock6 = ResidualBlock(3750, 3750, 2, 4, 15, 1, False)\n",
        "            self.ecgBlock7 = ResidualBlock(3750, 1875, 4, 4, 7, 1, True)\n",
        "            self.ecgBlock8 = ResidualBlock(1875, 1875, 4, 4, 7, 1, False)\n",
        "            self.ecgBlock9 = ResidualBlock(1875, 938, 4, 4, 7, 1, True)\n",
        "            self.ecgBlock10 = ResidualBlock(938, 938, 4, 4, 7, 1, False)\n",
        "            self.ecgBlock11 = ResidualBlock(938, 469, 4, 6, 7, 1, True)\n",
        "            self.ecgBlock12 = ResidualBlock(469, 469, 6, 6, 7, 1, False)\n",
        "            self.ecgFc = nn.Linear(6 * 469, 32)\n",
        "        \n",
        "        if useEeg:\n",
        "            self.eegBlock1 = ResidualBlock(7680, 3840, 1, 2, 7, 1, True)\n",
        "            self.eegBlock2 = ResidualBlock(3840, 3840, 2, 2, 7, 1, False)\n",
        "            self.eegBlock3 = ResidualBlock(3840, 1920, 2, 2, 7, 1, True)\n",
        "            self.eegBlock4 = ResidualBlock(1920, 1920, 2, 2, 7, 1, False)\n",
        "            self.eegBlock5 = ResidualBlock(1920, 960, 2, 2, 7, 1, True)\n",
        "            self.eegBlock6 = ResidualBlock(960, 960, 2, 4, 7, 1, False)\n",
        "            self.eegBlock7 = ResidualBlock(960, 480, 4, 4, 3, 1, True)\n",
        "            self.eegBlock8 = ResidualBlock(480, 480, 4, 4, 3, 1, False)\n",
        "            self.eegBlock9 = ResidualBlock(480, 240, 4, 4, 3, 1, True)\n",
        "            self.eegBlock10 = ResidualBlock(240, 240, 4, 4, 3, 1, False)\n",
        "            self.eegBlock11 = ResidualBlock(240, 120, 4, 6, 3, 1, True)\n",
        "            self.eegBlock12 = ResidualBlock(120, 120, 6, 6, 3, 1, False)\n",
        "            self.eegFc = nn.Linear(6 * 120, 32)\n",
        "\n",
        "        concatSize = 0\n",
        "        if useAbp:\n",
        "            concatSize += 32\n",
        "        if useEeg:\n",
        "            concatSize += 32\n",
        "        if useEcg:\n",
        "            concatSize += 32\n",
        "\n",
        "        self.fullLinear1 = nn.Linear(concatSize, 16)\n",
        "        self.fullLinear2 = nn.Linear(16, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, abp: torch.Tensor, eeg: torch.Tensor, ecg: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        batchSize = len(abp)\n",
        "\n",
        "        # conditionally operate ABP, EEG, and ECG networks\n",
        "        if self.useAbp:\n",
        "            abp = self.abpBlock1(abp)\n",
        "            abp = self.abpBlock2(abp)\n",
        "            abp = self.abpBlock3(abp)\n",
        "            abp = self.abpBlock4(abp)\n",
        "            abp = self.abpBlock5(abp)\n",
        "            abp = self.abpBlock6(abp)\n",
        "            abp = self.abpBlock7(abp)\n",
        "            abp = self.abpBlock8(abp)\n",
        "            abp = self.abpBlock9(abp)\n",
        "            abp = self.abpBlock10(abp)\n",
        "            abp = self.abpBlock11(abp)\n",
        "            abp = self.abpBlock12(abp)\n",
        "            totalLen = np.prod(abp.shape)\n",
        "            abp = torch.reshape(abp, (batchSize, int(totalLen / batchSize)))\n",
        "            abp = self.abpFc(abp)\n",
        "\n",
        "        if self.useEeg:\n",
        "            eeg = self.eegBlock1(eeg)\n",
        "            eeg = self.eegBlock2(eeg)\n",
        "            eeg = self.eegBlock3(eeg)\n",
        "            eeg = self.eegBlock4(eeg)\n",
        "            eeg = self.eegBlock5(eeg)\n",
        "            eeg = self.eegBlock6(eeg)\n",
        "            eeg = self.eegBlock7(eeg)\n",
        "            eeg = self.eegBlock8(eeg)\n",
        "            eeg = self.eegBlock9(eeg)\n",
        "            eeg = self.eegBlock10(eeg)\n",
        "            eeg = self.eegBlock11(eeg)\n",
        "            eeg = self.eegBlock12(eeg)\n",
        "            totalLen = np.prod(eeg.shape)\n",
        "            eeg = torch.reshape(eeg, (batchSize, int(totalLen / batchSize)))\n",
        "            eeg = self.eegFc(eeg)\n",
        "        \n",
        "        if self.useEcg:\n",
        "            ecg = self.ecgBlock1(ecg)\n",
        "            ecg = self.ecgBlock2(ecg)\n",
        "            ecg = self.ecgBlock3(ecg)\n",
        "            ecg = self.ecgBlock4(ecg)\n",
        "            ecg = self.ecgBlock5(ecg)\n",
        "            ecg = self.ecgBlock6(ecg)\n",
        "            ecg = self.ecgBlock7(ecg)\n",
        "            ecg = self.ecgBlock8(ecg)\n",
        "            ecg = self.ecgBlock9(ecg)\n",
        "            ecg = self.ecgBlock10(ecg)\n",
        "            ecg = self.ecgBlock11(ecg)\n",
        "            ecg = self.ecgBlock12(ecg)\n",
        "            #ecg = torch.flatten(ecg)\n",
        "            totalLen = np.prod(ecg.shape)\n",
        "            ecg = torch.reshape(ecg, (batchSize, int(totalLen / batchSize)))\n",
        "            ecg = self.ecgFc(ecg)\n",
        "        \n",
        "        # concatenation\n",
        "        merged = None\n",
        "        if self.useAbp and self.useEeg and self.useEcg:\n",
        "            merged = torch.cat((abp, eeg, ecg))\n",
        "        elif self.useAbp and self.useEeg:\n",
        "            merged = torch.cat((abp, eeg))\n",
        "        elif self.useAbp and self.useEcg:\n",
        "            merged = torch.cat((abp, ecg))\n",
        "        elif self.useEeg and self.useEcg:\n",
        "            merged = torch.cat((eeg, ecg))\n",
        "        elif self.useAbp:\n",
        "            merged = abp\n",
        "        elif self.useEeg:\n",
        "            merged = eeg\n",
        "        elif self.useEcg:\n",
        "            merged = ecg\n",
        "\n",
        "        totalLen = np.prod(merged.shape)\n",
        "        merged = torch.reshape(merged, (batchSize, int(totalLen / batchSize)))\n",
        "        out = self.fullLinear1(merged)\n",
        "        out = self.fullLinear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        out = torch.nan_to_num(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n",
        "\n",
        "Reiterating details from the Model summary: our training uses Binary Cross Entropy Loss as the loss function and Adam as the optimizer. The learning rate is set to 0.0001. The model will train for 100 epochs and will stop early when we see no loss reduction over the last 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "useAbp = True\n",
        "useEeg = True\n",
        "useEcg = True\n",
        "\n",
        "model = HypotensionCNN(useAbp, useEeg, useEcg)\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model = model.to(device)\n",
        "\n",
        "def train_model_one_iter(model, loss_func, optimizer, dataloader):\n",
        "  \n",
        "  curr_epoch_loss = []\n",
        "  i = 0\n",
        "  #for abp, ecg, eeg, label in tqdm(dataloader):\n",
        "  for abp, ecg, eeg, label in dataloader:\n",
        "\n",
        "    batch = len(abp)\n",
        "\n",
        "    abp = torch.nan_to_num(abp.reshape(batch, 1, abp.shape[2])).type(torch.FloatTensor)\n",
        "    ecg = torch.nan_to_num(ecg.reshape(batch, 1, ecg.shape[2])).type(torch.FloatTensor)\n",
        "    eeg = torch.nan_to_num(eeg.reshape(batch, 1, eeg.shape[2])).type(torch.FloatTensor)\n",
        "    #label = label.reshape(1, 1).type(torch.float)\n",
        "    label = label.type(torch.float).reshape(batch, 1)\n",
        "    i += 1\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    abp = abp.to(device)\n",
        "    eeg = eeg.to(device)\n",
        "    ecg = ecg.to(device)\n",
        "    label = label.to(device)\n",
        "    mdl = model(abp, eeg, ecg)\n",
        "    loss = loss_func(torch.nan_to_num(mdl), label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    curr_epoch_loss.append(loss.cpu().data.numpy())\n",
        "  return np.mean(curr_epoch_loss)\n",
        "\n",
        "num_epoch = 10\n",
        "# model training loop: it is better to print the training/validation losses during the training\n",
        "model.train(True)\n",
        "for i in range(num_epoch):\n",
        "  print(f\"[{datetime.now()}] Starting epoch {i}\")\n",
        "  train_loss = train_model_one_iter(model, loss_func, optimizer, train_loader)\n",
        "  print(f\"[{datetime.now()}] Completed epoch {i} with train loss {train_loss}\")\n",
        "  valid_loss = 0\n",
        "  #print(\"Train Loss: %.2f, Validation Loss: %.2f\" % (train_loss, valid_loss))\n",
        "model.train(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results (Planned results for Draft submission)\n",
        "\n",
        "When we complete our experiments, we will build comparison tables that compare a set of measures for each experiment performed. The full set of experiments and measures are listed below.\n",
        "\n",
        "## Experiments\n",
        "\n",
        " * ABP only\n",
        " * ECG only\n",
        " * EEG only\n",
        " * ABP + ECG\n",
        " * ABP + EEG\n",
        " * ECG + EEG\n",
        " * ABP + ECG + EEG\n",
        "\n",
        "Note: each experiment will be repeated with the following time-to-IOH-event durations:\n",
        " * 3 minutes\n",
        " * 5 minutes\n",
        " * 10 minutes\n",
        " * 15 minutes\n",
        "\n",
        "## Measures\n",
        "\n",
        " * AUROC\n",
        " * AUPRC\n",
        " * Sensitivity\n",
        " * Specificity\n",
        " * Threshold\n",
        " * Loss Shrinkage\n",
        "\n",
        "[ TODO for final report - complete the implementation of the model and collect data for all measures listed above. ]\n",
        "\n",
        "[ TODO for final report - generate ROC and PRC plots for each experiment ]\n",
        "\n",
        "We are collecting a broad set of measures across each experiment in order to perform a comprehensive comparison of all measures listed across all comparable experiments executed in the original paper. However, our key experimental results will be focused on a subset of these results that address the main experiments defined at the beginning of this notebook.\n",
        "\n",
        "The key experimental result measures will be as follows:\n",
        "\n",
        "1. For 3 minutes ahead of the predicted IOH event:\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+EEG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG+EEG\n",
        "2. For 5 minutes ahead of the predicted IOH event:\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+EEG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG+EEG\n",
        "3. For 10 minutes ahead of the predicted IOH event:\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+EEG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG+EEG\n",
        "4. For 15 minutes ahead of the predicted IOH event:\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+EEG\n",
        "    - compare AUROC and AUPRC for ABP only vs ABP+ECG+EEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "outputs": [],
      "source": [
        "# calculate AUROC, AUPRC, sensitivity, specificity, thresold\n",
        "def getMeasures(model):\n",
        "    auroc = None\n",
        "    auprc = None\n",
        "    sensitivity = None\n",
        "    specificity = None\n",
        "    threshold = None\n",
        "    loss_shrinkage = None\n",
        "    return (auroc, auprc, sensitivity, specificity, threshold, loss_shrinkage)\n",
        "\n",
        "abp3 = getMeasures(\"abp 3 minute\")\n",
        "abp5 = getMeasures(\"abp 5 minute\")\n",
        "abp10 = getMeasures(\"abp 10 minute\")\n",
        "abp15 = getMeasures(\"abp 15 minute\")\n",
        "\n",
        "ecg3 = getMeasures(\"ecg 3 minute\")\n",
        "ecg5 = getMeasures(\"ecg 5 minute\")\n",
        "ecg10 = getMeasures(\"ecg 10 minute\")\n",
        "ecg15 = getMeasures(\"ecg 15 minute\")\n",
        "\n",
        "eeg3 = getMeasures(\"eeg 3 minute\")\n",
        "eeg5 = getMeasures(\"eeg 5 minute\")\n",
        "eeg10 = getMeasures(\"eeg 10 minute\")\n",
        "eeg15 = getMeasures(\"eeg 15 minute\")\n",
        "\n",
        "abpEcg3 = getMeasures(\"abp+Ecg 3 minute\")\n",
        "abpEcg5 = getMeasures(\"abp+Ecg 5 minute\")\n",
        "abpEcg10 = getMeasures(\"abp+Ecg 10 minute\")\n",
        "abpEcg15 = getMeasures(\"abp+Ecg 15 minute\")\n",
        "\n",
        "abpEeg3 = getMeasures(\"abp+Eeg 3 minute\")\n",
        "abpEeg5 = getMeasures(\"abp+Eeg 5 minute\")\n",
        "abpEeg10 = getMeasures(\"abp+Eeg 10 minute\")\n",
        "abpEeg15 = getMeasures(\"abp+Eeg 15 minute\")\n",
        "\n",
        "ecgEeg3 = getMeasures(\"ecg+Eeg 3 minute\")\n",
        "ecgEeg5 = getMeasures(\"ecg+Eeg 5 minute\")\n",
        "ecgEeg10 = getMeasures(\"ecg+Eeg 10 minute\")\n",
        "ecgEeg15 = getMeasures(\"ecg+Eeg 15 minute\")\n",
        "\n",
        "abpEcgEeg3 = getMeasures(\"abp+Ecg+Eeg 3 minute\")\n",
        "abpEcgEeg5 = getMeasures(\"abp+Ecg+Eeg 5 minute\")\n",
        "abpEcgEeg10 = getMeasures(\"abp+Ecg+Eeg 10 minute\")\n",
        "abpEcgEeg15 = getMeasures(\"abp+Ecg+Eeg 15 minute\")\n",
        "\n",
        "# TODO for final report - generate plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "## Model comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "outputs": [],
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper\n",
        "\n",
        "# TODO for final report - embed tabular comparison of our results with those listed in Table 3 from the original paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe What was easy and What was difficult during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "outputs": [],
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can read and plot it here like the Scope of Reproducibility\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Jo Y-Y, Jang J-H, Kwon J-m, Lee H-C, Jung C-W, Byun S, et al. Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study. PLoS ONE, (2022) 17(8): e0272055 https://doi.org/10.1371/journal.pone.0272055\n",
        "2. Hatib, Feras, Zhongping J, Buddi S, Lee C, Settels J, Sibert K, Rhinehart J, Cannesson M Machine-learning Algorithm to Predict Hypotension Based on High-fidelity Arterial Pressure Waveform Analysis Anesthesiology (2018) 129:4 https://doi.org/10.1097/ALN.0000000000002300\n",
        "3. Bao, X., Kumar, S.S., Shah, N.J. et al. AcumenTM hypotension prediction index guidance for prevention and treatment of hypotension in noncardiac surgery: a prospective, single-arm, multicenter trial. Perioperative Medicine (2024) 13:13 https://doi.org/10.1186/s13741-024-00369-9\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
