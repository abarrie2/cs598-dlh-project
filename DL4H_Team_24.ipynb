{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/abarrie2/cs598-dlh-project/blob/main/DL4H_Team_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The paper selected for this project is titled \"Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study\" [1].\n",
    "\n",
    "## LICENSING NOTICE\n",
    "\n",
    "Note that all users who use Vital DB, an open biosignal dataset, must agree to the Data Use Agreement below. If you do not agree, please close this window. The Data Use Agreement is available here:\n",
    "https://vitaldb.net/dataset/#h.vcpgs1yemdb5\n",
    "\n",
    "## Background of the problem\n",
    "\n",
    "The problem being investigated by this study relates to the prediction of Intraoperative Hypotension (IOH). IOH is an event that can occur during durgery where there is a drop in mean arterial blood pressure to less than 65 mmHg. This event is important to consider because it can be associated with multiple negative postoperative outcomes including postoperative myocardial infarction, acute kidney injury, and postoperative mortality. There are multiple factors that can contribute to instances of IOH, and if there were an ability to identify IOH in advance then medical personnel could take steps to mitigate the IOH event. This is important because a prevention or minimization of IOH events may reduce the probability of the negative postoperative outcomes described above. The paper is an investigation into the problem of IOH event prediction, specifically predicting whether, based on vital signals, there will be an IOH event in 7, 5, 10, or 15 minutes time.\n",
    "\n",
    "Our selected paper is an extension of another study titled \"Machine-learning Algorithm to Predict Hypotension Based on High-fidelity Arterial Pressure Waveform Analysis\" [2], which attempted to train a model to predict instances of Intraoperative Hypotension using Arterial Blood Pressure (ABP) signals. While that original paper focused solely on training against arterial blood pressure (ABP) waveforms, our selected paper seeks to measure whether predictive outcomes are improved by incorporating additional vital signals. Specifically, the paper investigates the impact to quality of IOH prediction by training not only on ABP signals, but also electrocardiogram (ECG) signals, electroencephalogram (EEG) signals, and various combination of all three.\n",
    "\n",
    "The key difficulty in this area of research is that the benefit of a predictive model would occur only by the use of such a model within a surgical environment. This paper does not aim to demonstrate the feasibility of operating a realtime signal analysis model, instead focusing on the potential predictive benefits of incorporating vital signals beyond ABP in order to improve the quality of predictions for IOH events.\n",
    "\n",
    "While this paper is an investigation into the augmentation of ABP signal analysis with additional vital signals, the state of the art for IOH prediction involves models that have been incorporated into medical devices that are deployed in the operating room. A recently published study titled \"AcumenTM hypotension prediction index guidance for prevention and treatment of hypotension in noncardiac surgery: a prospective, single-arm, multicenter trial\" [3] wherein the predictive models were used during surgeries. The participants clinicians were warned by the predictive technology and enabled to intervene and prevent or reduce the duration of IOH events. The conclusion of the AcumenTM paper determined that the use of such prediction software was associated with a clinically meaningful reudction in the duration of IOH events, but that further studies are required to investigate whether these models could be used to prevent IOH events entirely.\n",
    "\n",
    "## Our Paper\n",
    "\n",
    "The paper proposed that training a model on some combination of ABP, ECG, and EEG signals would improve result in a model that would function better at predicting IOH. The key innovation relative to preceding research in this area is the inclusion of EEG and ECG signal data in the operation of the model, whereas preceding research focused primarily on making predictions based solely on ABP data. The paper concluded that the combination of ABP and EEG signals may result in improved model performance when predicting IOH events. The experimental results demonstrated that by both area under the receiver operating characteristic (AUROC) and area under the precision-recall curve (AUPRC) measures, a model trained on the combination of ABP and EEG scored higher than a model trained solely on ABP across all prediction intervals (i.e., for predictions 7, 5, 10, and 15 minutes ahead of an IOH event). The main contribution to the research regime for prediction IOH is that it validates the hypothesis that a combination of vital signals able to monitored during surgery will improve predictive quality. While that benefit is marginal, this research provides a quantifiable measure to demonstrate the magnitude of this improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "The original paper investigated the following hypotheses:\n",
    "\n",
    "1.   Hypothesis 1: Using AUROC and AUPRC scores, a model using ABP and ECG will perform better than a model using only ABP.\n",
    "2.   Hypothesis 2: Using AUROC and AUPRC scores, a model using ABP and EEG will perform better than a model using only ABP.\n",
    "3.   Hypothesis 3: Using AUROC and AUPRC scores, a model using ABP, EEG, and ECG will perform better than a model using only ABP.\n",
    "\n",
    "Based on the results described in the original paper, we expect that Hypothesis 2 will be confirmed, and that Hypotheses 1 and 3 will not be confirmed. In order to perform the corresponding experiments, we will implement a CNN-based model that can be configured to train and infer using the following four model variations:\n",
    "\n",
    "1.   ABP data alone\n",
    "2.   ABP and ECG data\n",
    "3.   ABP and EEG data\n",
    "4.   ABP, ECG, and EEG data\n",
    "\n",
    "We will measure the performance of these configurations using the same AUROC and AUPRC metrics as used in the original paper. To test hypothesis 1 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 2. To test hypothesis 2 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 3. To test hypothesis 3 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 4. For all of the above measures and experiment combinations, we are going to be operating multiple experiments, one where the time-to-IOH event prediction will be broken out into the following times:\n",
    "\n",
    "1. 3 minutes before event\n",
    "2. 5 minutes before event\n",
    "3. 10 minutes before event\n",
    "4. 15 minutes before event\n",
    "\n",
    "[note to self: should we include Table 3 from the original paper (auroc/auprc/sensitive/specificity/threshold scores for all signal combinations)]\n",
    "\n",
    "[note to self: should we include Figure 4 from the original paper (charts comparing risk indices for ABP, EEG, ABP+EEG)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology\n",
    "\n",
    "TODO for draft: plain english summary of the objectives of all of the code sections within the methodology section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment\n",
    "\n",
    "Create `conda` environment for the project using the `environment.yml` file:\n",
    "\n",
    "```bash\n",
    "conda env create --prefix .envs/dlh-team24 -f environment.yml\n",
    "```\n",
    "\n",
    "Activate the environment with:\n",
    "```bash\n",
    "conda activate .envs/dlh-team24\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu61Jp1xrnKk"
   },
   "outputs": [],
   "source": [
    "#install vitaldb\n",
    "%pip install vitaldb\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import vitaldb\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "#from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seeds for consistent results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "#torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "##  Data\n",
    "\n",
    "TODO for draft: author this section\n",
    "\n",
    "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
    "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
    "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
    "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
    "  * Illustration: printing results, plotting figures for illustration.\n",
    "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Local Data Caches\n",
    "\n",
    "Since the VitalDB data is static, local copies are stored and reused to avoid expensive downloads and to speed up data processing.\n",
    "\n",
    "The default directory defined below is already in the project `.gitignore` file. If later modified, it should also be added to the project `.gitignore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VITALDB_CACHE = './vitaldb_cache'\n",
    "VITAL_ALL = 'vital_all'\n",
    "VITAL_MINI = 'vital_mini'\n",
    "VITAL_METADATA = 'metadata'\n",
    "VITAL_MODELS = 'models'\n",
    "\n",
    "TRACK_CACHE = None\n",
    "\n",
    "# When RESET_CACHE is set to True, it will ensure the TRACK_CACHE is disposed and recreated when we do dataset initialization. Use as a shortcut to wiping cache rather than restarting kernel\n",
    "RESET_CACHE = False\n",
    "\n",
    "# Maximum number of cases of interest for which to download data.\n",
    "# Set to a small value for demo purposes, else set to None to disable and download all.\n",
    "#MAX_CASES = None\n",
    "MAX_CASES = 20\n",
    "\n",
    "# Preloading Cases: when true, all matched cases will have the _mini tracks extracted and put into in-mem dict\n",
    "PRELOADING_CASES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "  # windows variant\n",
    "  if not os.path.exists(VITALDB_CACHE):\n",
    "    os.mkdir(VITALDB_CACHE)\n",
    "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_ALL}'):\n",
    "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_ALL}')\n",
    "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_MINI}'):\n",
    "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_MINI}')\n",
    "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_METADATA}'):\n",
    "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_METADATA}')\n",
    "  if not os.path.exists(f'{VITALDB_CACHE}/{VITAL_MODELS}'):\n",
    "    os.mkdir(f'{VITALDB_CACHE}/{VITAL_MODELS}')\n",
    "\n",
    "  print(os.listdir(VITALDB_CACHE))\n",
    "else:\n",
    "  # mac/linux variant\n",
    "  !mkdir -p $VITALDB_CACHE\n",
    "  !mkdir -p $VITALDB_CACHE/$VITAL_ALL\n",
    "  !mkdir -p $VITALDB_CACHE/$VITAL_MINI\n",
    "  !mkdir -p $VITALDB_CACHE/$VITAL_METADATA\n",
    "  !ls -l $VITALDB_CACHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSFS Bulk Data Download\n",
    "\n",
    "**This step is not required, but will significantly speed up downstream processing and avoid a high volume of API requests to the VitalDB web site.**\n",
    "\n",
    "The cache population code checks if OSFS bulk download data of VitalDB vital files is locally available.\n",
    "\n",
    "- Manually downloaded the OSF Store archives from the following site: https://osf.io/dtc45/\n",
    "    - `Vital Files 0001-2000`\n",
    "    - `Vital Files 2001-4000`\n",
    "    - `Vital Files 4001-6388`\n",
    "- Once the `OSF Storage (United States)` link is clicked a `Download as zip` link will appear.\n",
    "- Once downloaded, extract each of the 3 zip archives.\n",
    "- Move all files from each of the unzip directories into the `${VITALDB_CACHE}/${VITAL_ALL}` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pandas DataFrame for the specified dataset.\n",
    "#   One of 'cases', 'labs', or 'trks'\n",
    "# If the file exists locally, create and return the DataFrame.\n",
    "# Else, download and cache the csv first, then return the DataFrame.\n",
    "def vitaldb_dataframe_loader(dataset_name):\n",
    "    if dataset_name not in ['cases', 'labs', 'trks']:\n",
    "        raise ValueError(f'Invalid dataset name: {dataset_name}')\n",
    "    file_path = f'{VITALDB_CACHE}/{VITAL_METADATA}/{dataset_name}.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f'{dataset_name}.csv exists locally.')\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        print(f'downloading {dataset_name} and storing in the local cache for future reuse.')\n",
    "        df = pd.read_csv(f'https://api.vitaldb.net/{dataset_name}')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = vitaldb_dataframe_loader('cases')\n",
    "cases = cases.set_index('caseid')\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks = vitaldb_dataframe_loader('trks')\n",
    "trks = trks.set_index('caseid')\n",
    "trks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('tname').count().sort_values(by='tid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hemodynamic Parameters Reference\n",
    "https://vitaldb.net/dataset/?query=overview#h.f7d712ycdpk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solar8000/ART_MBP**\n",
    "\n",
    "mean blood pressure\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "Solar8000/ART_MBP, Mean arterial pressure, N, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('Solar8000/ART_MBP')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNUADC/ART**\n",
    "\n",
    "arterial blood pressure waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ART, Arterial pressure wave, W/500, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ART')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNUADC/ECG_II**\n",
    "\n",
    "electrocardiogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ECG_II, ECG lead II wave, W/500, mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ECG_II')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIS/EEG1_WAV**\n",
    "\n",
    "electroencephalogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "BIS/EEG1_WAV, EEG wave from channel 1, W/128, uV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('BIS/EEG1_WAV')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases of Interest\n",
    "\n",
    "These are the subset of case ids for which modelling and analysis will be performed based upon inclusion criteria and waveform data availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']\n",
    "TRACK_SRATES = [500, 500, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in the paper, select cases which meet the following criteria:\n",
    "#\n",
    "# For patients, the inclusion criteria were as follows:\n",
    "# (1) adults (age >= 18)\n",
    "# (2) administered general anaesthesia\n",
    "# (3) undergone non-cardiac surgery. \n",
    "#\n",
    "# For waveform data, the inclusion criteria were as follows:\n",
    "# (1) no missing monitoring for ABP, ECG, and EEG waveforms\n",
    "# (2) no cases containing false events or non-events due to poor signal quality\n",
    "#     (checked in second stage of data preprocessing)\n",
    "\n",
    "# adult\n",
    "inclusion_1 = cases.loc[cases['age'] >= 18].index\n",
    "print(f'{len(cases)-len(inclusion_1)} cases excluded, {len(inclusion_1)} remaining due to age criteria')\n",
    "\n",
    "# general anesthesia\n",
    "inclusion_2 = cases.loc[cases['ane_type'] == 'General'].index\n",
    "print(f'{len(cases)-len(inclusion_2)} cases excluded, {len(inclusion_2)} remaining due to anesthesia criteria')\n",
    "\n",
    "# non-cardiac surgery\n",
    "inclusion_3 = cases.loc[\n",
    "    ~cases['opname'].str.contains(\"cardiac\", case=False)\n",
    "    & ~cases['opname'].str.contains(\"aneurysmal\", case=False)\n",
    "].index\n",
    "print(f'{len(cases)-len(inclusion_3)} cases excluded, {len(inclusion_3)} remaining due to non-cardiac surgery criteria')\n",
    "\n",
    "# ABP, ECG, EEG waveforms\n",
    "inclusion_4 = trks.loc[trks['tname'].isin(TRACK_NAMES)].index.value_counts()\n",
    "inclusion_4 = inclusion_4[inclusion_4 == len(TRACK_NAMES)].index\n",
    "print(f'{len(cases)-len(inclusion_4)} cases excluded, {len(inclusion_4)} remaining due to missing waveform data')\n",
    "\n",
    "cases_of_interest_idx = inclusion_1 \\\n",
    "    .intersection(inclusion_2) \\\n",
    "    .intersection(inclusion_3) \\\n",
    "    .intersection(inclusion_4)\n",
    "\n",
    "cases_of_interest = cases.loc[cases_of_interest_idx]\n",
    "\n",
    "print()\n",
    "print(f'{cases_of_interest_idx.shape[0]} out of {cases.shape[0]} total cases remaining after exclusions applied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracks of Interest\n",
    "\n",
    "These are the subset of tracks (waveforms) for the cases of interest identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single case maps to one or more waveform tracks. Select only the tracks required for analysis.\n",
    "trks_of_interest = trks.loc[cases_of_interest_idx][trks.loc[cases_of_interest_idx]['tname'].isin(TRACK_NAMES)]\n",
    "trks_of_interest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest_idx = trks_of_interest.set_index('tid').index\n",
    "trks_of_interest_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tracks Cache for Local Processing\n",
    "\n",
    "Tracks data are large and therefore expensive to download every time used.\n",
    "By default, the vital file format stores all tracks for each case internally. Since only certain tracks per case are required, each vital file can be further truncated to only store the tracks for needed waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim cases of interest to MAX_CASES\n",
    "if MAX_CASES:\n",
    "    cases_of_interest_idx = cases_of_interest_idx[:MAX_CASES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the full vital file dataset is available for cases of interest.\n",
    "count_downloaded = 0\n",
    "count_present = 0\n",
    "\n",
    "#for i, idx in enumerate(cases.index):\n",
    "for i, idx in enumerate(cases_of_interest_idx):\n",
    "    if MAX_CASES and i >= MAX_CASES:\n",
    "        break\n",
    "\n",
    "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
    "    if not os.path.isfile(full_path):\n",
    "        print(f'Missing vital file: {full_path}')\n",
    "        # Download and save the file.\n",
    "        vf = vitaldb.VitalFile(idx)\n",
    "        vf.to_vital(full_path)\n",
    "        count_downloaded += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files downloaded:      {count_downloaded}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vital files to \"mini\" versions including only the subset of tracks based on TRACK_NAMES defined above.\n",
    "# Only perform conversion for the cases of interest.\n",
    "# NOTE: If this cell is interrupted, it can be restarted and will continue where it left off.\n",
    "count_minified = 0\n",
    "count_present = 0\n",
    "\n",
    "for i, idx in enumerate(cases_of_interest_idx):\n",
    "    if MAX_CASES and i >= MAX_CASES:\n",
    "        break\n",
    "    \n",
    "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
    "    mini_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{idx:04d}_mini.vital'\n",
    "    if not os.path.isfile(mini_path):\n",
    "        print(f'Creating mini vital file: {idx}')\n",
    "        vf = vitaldb.VitalFile(full_path, TRACK_NAMES)\n",
    "        vf.to_vital(mini_path)\n",
    "        count_minified += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files minified:        {count_minified}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude cases where ABP j signal quality (jSQI) < 0.8\n",
    "# TODO: Implement jSQI function\n",
    "# TODO: Filter cases with jSQI < 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering\n",
    "\n",
    "Preprocessing characteristics are different for each of the three signal categories:\n",
    " * ABP: no preprocessing, use as-is\n",
    " * ECG: apply a 1-40Hz bandpass filter, then perform Z-score normalization\n",
    " * EEG: apply a 0.5-50Hz bandpass filter\n",
    "\n",
    "apply_bandpass_filter() implements the bandpass filter using scipy.signal\n",
    "\n",
    "apply_zscore_normalization() implements the Z-score normalization using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, spectrogram\n",
    "\n",
    "# define two methods for data preprocessing\n",
    "\n",
    "def apply_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def apply_zscore_normalization(signal):\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    return (signal - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Demonstration\n",
    "\n",
    "# temp experimental, code to be incorporated into overall preloader process\n",
    "# for now it's just dumping example plots of the before/after filtered signal data\n",
    "folder = f'{VITALDB_CACHE}/{VITAL_MINI}/'\n",
    "caseidx = 13\n",
    "file_path = os.path.join(folder, f\"{caseidx:04d}_mini.vital\")\n",
    "vf = vitaldb.VitalFile(file_path, TRACK_NAMES)\n",
    "\n",
    "originalAbp = None\n",
    "filteredAbp = None\n",
    "originalEcg = None\n",
    "filteredEcg = None\n",
    "originalEeg = None\n",
    "filteredEeg = None\n",
    "\n",
    "ABP_TRACK_NAME = \"SNUADC/ART\"\n",
    "ECG_TRACK_NAME = \"SNUADC/ECG_II\"\n",
    "EEG_TRACK_NAME = \"BIS/EEG1_WAV\"\n",
    "\n",
    "for i, (track_name, rate) in enumerate(zip(TRACK_NAMES, TRACK_SRATES)):\n",
    "    # Get samples for this track\n",
    "    track_samples = vf.get_track_samples(track_name, 1/rate)\n",
    "    #track_samples, _ = vf.get_samples(track_name, 1/rate)\n",
    "    print(f\"Track {track_name} @ {rate}Hz shape {len(track_samples)}\")\n",
    "\n",
    "    if track_name == ABP_TRACK_NAME:\n",
    "        # ABP waveforms are used without further pre-processing\n",
    "        originalAbp = track_samples\n",
    "        filteredAbp = track_samples\n",
    "    elif track_name == ECG_TRACK_NAME:\n",
    "        originalEcg = track_samples\n",
    "        # ECG waveforms are band-pass filtered between 1 and 40 Hz, and Z-score normalized\n",
    "        # first apply bandpass filter\n",
    "        filteredEcg = apply_bandpass_filter(track_samples, 1, 40, rate)\n",
    "        # then do z-score normalization\n",
    "        filteredEcg = apply_zscore_normalization(filteredEcg)\n",
    "    elif track_name == EEG_TRACK_NAME:\n",
    "        # EEG waveforms are band-pass filtered between 0.5 and 50 Hz\n",
    "        originalEeg = track_samples\n",
    "        filteredEeg = apply_bandpass_filter(track_samples, 0.5, 50, rate, 2)\n",
    "\n",
    "def plotSignal(data, title):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plotSignal(originalAbp, \"Original ABP\")\n",
    "plotSignal(originalAbp, \"Unfiltered ABP\")\n",
    "plotSignal(originalEcg, \"Original ECG\")\n",
    "plotSignal(filteredEcg, \"Filtered ECG\")\n",
    "plotSignal(originalEeg, \"Original EEG\")\n",
    "plotSignal(filteredEeg, \"Filtered EEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hypotensive events\n",
    "# Hypotensive events are defined as a 1-minute interval with sustained ABP of less than 65 mmHg\n",
    "# Note: Hypotensive events should be at least 20 minutes apart to minimize potential residual effects from previous events\n",
    "# TODO: Implement hypotension event generation function\n",
    "# TODO: Generate hypotension events\n",
    "\n",
    "# Generate hypotension non-events\n",
    "# To sample non-events, 30-minute segments where the ABP was above 75 mmHG were selected, and then\n",
    "# three one-minute samples of each waveform were obtained from the middle of the segment\n",
    "# TODO: Implement hypotension non-event generation function\n",
    "# TODO: Generate hypotension non-events\n",
    "\n",
    "# XXX Create dummy events with random labels for now\n",
    "def generate_dummy_data(cases_of_interest_idx):\n",
    "    # Initialize an empty DataFrame\n",
    "    generated_data = []\n",
    "    \n",
    "    # Loop through each case index\n",
    "    for case in cases_of_interest_idx:\n",
    "        # Generate a random number of rows between 5 and 20\n",
    "        num_rows = random.randint(5, 20)\n",
    "        \n",
    "        # Generate data for each row\n",
    "        for _ in range(num_rows):\n",
    "            starttime = random.randint(0, 1200)\n",
    "            endtime = starttime + 60\n",
    "            label = random.randint(0, 1)\n",
    "            \n",
    "            # Append the data to the DataFrame\n",
    "            generated_data.append([\n",
    "                case,\n",
    "                starttime,\n",
    "                endtime,\n",
    "                label\n",
    "            ])\n",
    "    \n",
    "    return pd.DataFrame(generated_data, columns=['caseidx', 'starttime', 'endtime', 'label'])\n",
    "samples = generate_dummy_data(cases_of_interest_idx)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data tracks\n",
    "ABP_TRACK_NAME = \"SNUADC/ART\"\n",
    "ECG_TRACK_NAME = \"SNUADC/ECG_II\"\n",
    "EEG_TRACK_NAME = \"BIS/EEG1_WAV\"\n",
    "FILE_FOLDER = f'{VITALDB_CACHE}/{VITAL_MINI}/'\n",
    "\n",
    "if RESET_CACHE:\n",
    "    TRACK_CACHE = None\n",
    "\n",
    "if TRACK_CACHE is None:\n",
    "    TRACK_CACHE = {}\n",
    "\n",
    "def get_track_data(case, print_when_file_loaded = False):\n",
    "    parsedFile = None\n",
    "    abp = None\n",
    "    eeg = None\n",
    "    ecg = None\n",
    "    for i, (track_name, rate) in enumerate(zip(TRACK_NAMES, TRACK_SRATES)):\n",
    "        # use integer case id and track name, delimited by pipe, as cache key\n",
    "        cache_label = f\"{case}|{track_name}\"\n",
    "        if cache_label not in TRACK_CACHE:\n",
    "            if parsedFile is None:\n",
    "                file_path = os.path.join(FILE_FOLDER, f\"{case:04d}_mini.vital\")\n",
    "                if print_when_file_loaded:\n",
    "                    print(f\"[{datetime.now()}] Loading vital file {file_path}\")\n",
    "                parsedFile = vitaldb.VitalFile(file_path, TRACK_NAMES)\n",
    "            dataset = np.array(vf.get_track_samples(track_name, 1/rate))\n",
    "            if track_name == ABP_TRACK_NAME:\n",
    "                # no filtering for ABP\n",
    "                abp = dataset\n",
    "                TRACK_CACHE[cache_label] = abp\n",
    "            elif track_name == ECG_TRACK_NAME:\n",
    "                ecg = dataset\n",
    "                # apply ECG filtering: first bandpass then do z-score normalization\n",
    "                ecg = apply_bandpass_filter(ecg, 1, 40, rate, 2)\n",
    "                ecg = apply_zscore_normalization(ecg)\n",
    "                TRACK_CACHE[cache_label] = ecg\n",
    "            elif track_name == EEG_TRACK_NAME:\n",
    "                eeg = dataset\n",
    "                # apply EEG filtering: bandpass only\n",
    "                eeg = apply_bandpass_filter(eeg, 0.5, 50, rate, 2)\n",
    "                TRACK_CACHE[cache_label] = eeg\n",
    "        else:\n",
    "            # cache hit, pull from cache\n",
    "            if track_name == ABP_TRACK_NAME:\n",
    "                abp = TRACK_CACHE[cache_label]\n",
    "            elif track_name == ECG_TRACK_NAME:\n",
    "                ecg = TRACK_CACHE[cache_label]\n",
    "            elif track_name == EEG_TRACK_NAME:\n",
    "                eeg = TRACK_CACHE[cache_label]\n",
    "\n",
    "    return (abp, ecg, eeg)\n",
    "\n",
    "# ABP waveforms are used without further pre-processing\n",
    "# ECG waveforms are band-pass filtered between 1 and 40 Hz, and Z-score normalized\n",
    "# EEG waveforms are band-pass filtered between 0.5 and 40 Hz\n",
    "if PRELOADING_CASES:\n",
    "    print(f\"At beginning of process, the track cache has {len(TRACK_CACHE)} entries present.\")\n",
    "    for track in tqdm(cases_of_interest_idx):\n",
    "        # getting track data will cause a cache-check and fill when missing\n",
    "        # will also apply appropriate filtering per track\n",
    "        get_track_data(track, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets\n",
    "# Use 6:1:3 ratio and prevent samples from a single case from being split across different sets\n",
    "# Note: number of samples at each time point is not the same, because the first event can occur before the 3/5/10/15 minute mark\n",
    "\n",
    "# Set target sizes\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.1\n",
    "test_ratio = 1 - train_ratio - val_ratio # ensure ratios sum to 1\n",
    "\n",
    "# Assume that on average cases have the ~same number of events so we can split by case rather than event\n",
    "# Note: this means that the ratios will be approximate\n",
    "\n",
    "# Get unique cases\n",
    "unique_cases = samples['caseidx'].unique()\n",
    "\n",
    "# Split cases into train and other\n",
    "train_caseidx, other_caseidx = train_test_split(unique_cases, test_size=(1 - train_ratio), random_state=42)\n",
    "# Split other into val and test\n",
    "val_caseidx, test_caseidx = train_test_split(other_caseidx, test_size=(test_ratio / (1 - train_ratio)), random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "samples_train = samples[samples['caseidx'].isin(train_caseidx)]\n",
    "samples_val = samples[samples['caseidx'].isin(val_caseidx)]\n",
    "samples_test = samples[samples['caseidx'].isin(test_caseidx)]\n",
    "\n",
    "# Check how many samples are in each set\n",
    "print(f\"Train samples: {len(samples_train)}, ({len(samples_train) / len(samples):.2%})\")\n",
    "print(f\"Val samples: {len(samples_val)}, ({len(samples_val) / len(samples):.2%})\")\n",
    "print(f\"Test samples: {len(samples_test)}, ({len(samples_test) / len(samples):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vitalDataset class\n",
    "class vitalDataset(Dataset):\n",
    "    def __init__(self, file_dir, samples, track_names, track_srates_hz):\n",
    "        # samples should be a list of (caseidx, starttime, endtime, label)\n",
    "        self.file_dir = file_dir\n",
    "        self.samples = samples\n",
    "        self.track_names = track_names\n",
    "        self.track_srates_hz = track_srates_hz\n",
    "        self.vf_dict = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get metadata for this event\n",
    "        caseidx, starttime, endtime, label = self.samples.iloc[idx]\n",
    "\n",
    "        (fullAbp, fullEcg, fullEeg) = get_track_data(caseidx)\n",
    "\n",
    "        abp = None\n",
    "        ecg = None\n",
    "        eeg = None\n",
    "\n",
    "        for i, (track_name, rate) in enumerate(zip(self.track_names, self.track_srates_hz)):\n",
    "            # Convert to tensor and store in samples\n",
    "            start = int((endtime-starttime)*rate)\n",
    "            end = start + int((endtime-starttime)*rate)\n",
    "\n",
    "            if track_name == ABP_TRACK_NAME:\n",
    "                abp = torch.tensor(np.array(fullAbp[start:end]))\n",
    "                #abp = torch.tensor(np.array(fullAbp[0:end-start]))\n",
    "            elif track_name == ECG_TRACK_NAME:\n",
    "                ecg = torch.tensor(np.array(fullEcg[start:end]))\n",
    "                #ecg = torch.tensor(np.array(fullEcg[0:end-start]))\n",
    "            elif track_name == EEG_TRACK_NAME:\n",
    "                eeg = torch.tensor(np.array(fullEeg[start:end]))\n",
    "                #eeg = torch.tensor(np.array(fullEeg[0:end-start]))\n",
    "\n",
    "        return abp, ecg, eeg, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = vitalDataset(f'{VITALDB_CACHE}/{VITAL_MINI}/', samples_train, TRACK_NAMES, TRACK_SRATES)\n",
    "val_dataset = vitalDataset(f'{VITALDB_CACHE}/{VITAL_MINI}/', samples_val, TRACK_NAMES, TRACK_SRATES)\n",
    "test_dataset = vitalDataset(f'{VITALDB_CACHE}/{VITAL_MINI}/', samples_test, TRACK_NAMES, TRACK_SRATES)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Model\n",
    "\n",
    "This model is an implementation of the CNN described in our selected paper. It can train and infer using 1, 2, or 3 different signal categories. I.e., the same model definition can use different initialization parameters to drive a model that uses:\n",
    " * ABP alone\n",
    " * EEG alone\n",
    " * ECG alone\n",
    " * ABP + EEG\n",
    " * ABP + ECG\n",
    " * EEG + ECG\n",
    " * ABP + EEG + ECG\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The following image os Figure 2 from our original paper, which describes he architecture of the model. The hyperparameter values are specified in Supplemental Table 1 from the original paper and a screenshot of these hyperparameters is included further below in the section describing Residual Block Hyperparameters.\n",
    "\n",
    "![Figure 2 from original paper](<https://github.com/abarrie2/cs598-dlh-project/blob/main/img/figure_2_model.PNG?raw=true>)\n",
    "\n",
    "Due to different frequency of the input signal, the hyperparameters will differ for EEG signals as opposed to ABP and ECG signals, but aside from that the general model architecture will be the same for each signal. The model is defined by a residual block containing 7 layers which will be described below. Each signal will pass through 12 instances of the residual block before being flattened and passed through a linear layer ultimately producing 32 parameters. Each signal path will then be concatenated (unless only one signal was configured for use). This concatenated set will be passed through two more linear layers to produce a single vector representing the IOH index. A threshold value would be subsequently applied to this index to perform the binary classification determining whether or not an IOH event is being predicted. This means that each signal passes through 85 layers before concatenation, and then 2 more linear layers and an output sigmoid activation layer before the prediction measure is produced.\n",
    "\n",
    "### Residual Block Definition\n",
    "\n",
    "Each residual block is made of the following seven layers:\n",
    " \n",
    " * Batch normalization\n",
    " * ReLU\n",
    " * Dropout (0.5)\n",
    " * 1D convolution\n",
    " * Batch normalization\n",
    " * ReLU\n",
    " * 1D convolution\n",
    "\n",
    "Each block also features a skip connection which is itself conditionally passed through a 1D convolution where appropriate to maintain dimensions consistent with the output of the layers.\n",
    "\n",
    "#### Residual Block Hyperparameters\n",
    "\n",
    "The hyperparameters are specified in Supplemental Table 1 from our original paper and a screenshot has been included below.\n",
    "\n",
    "![Supplemental Table 1 from original paper](<https://github.com/abarrie2/cs598-dlh-project/blob/main/img/table_1_hyperparameters.png?raw=true>)\n",
    "\n",
    "Please note that the output size as specified for ECG+ABP in Residual Blocks 11 and 12 contain a typo. The output size is listed as 496 * 6 and should have been listed as 469 * 6.\n",
    "\n",
    "### Training Objectives\n",
    "Our model replicates the loss function and optimizer decisions used in our selected paper. The loss function uses binary cross entropy, and the optimizer is Adam. A learning rate of 0.0001 is used. The model will train for 100 epochs, but will exit early if there is no measured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBdVZoTvsSFV"
   },
   "outputs": [],
   "source": [
    "# First define the residual block which is reused 12x for each data track for each sample.\n",
    "# Second define the primary model.\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, size_down: bool = False) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # calculate the appropriate padding required to ensure expected sequence lengths out of each residual block\n",
    "        padding = int((((stride-1)*in_features)-stride+kernel_size)/2)\n",
    "\n",
    "        self.size_down = size_down\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "        \n",
    "        self.residualConv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "\n",
    "        # unclear where in sequence this hsuold take place. Size down expressed in Supplemental table S1\n",
    "        if self.size_down:\n",
    "            pool_padding = (1 if (in_features % 2 > 0) else 0)\n",
    "            self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding = pool_padding)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        if self.size_down:\n",
    "            out = self.downsample(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if out.shape != identity.shape:\n",
    "            # run the residual through a convolution when necessary\n",
    "            identity = self.residualConv(identity)\n",
    "            \n",
    "            outlen = np.prod(out.shape)\n",
    "            idlen = np.prod(identity.shape)\n",
    "            # downsample when required\n",
    "            if idlen > outlen:\n",
    "                identity = self.downsample(identity)\n",
    "            # match dimensions\n",
    "            identity = identity.reshape(out.shape)\n",
    "       \n",
    "        # add the residual       \n",
    "        out += identity\n",
    "\n",
    "        return  out\n",
    "\n",
    "class HypotensionCNN(nn.Module):\n",
    "    def __init__(self, useAbp: bool = True, useEeg: bool = False, useEcg: bool = False) -> None:\n",
    "        super(HypotensionCNN, self).__init__()\n",
    "\n",
    "        self.useAbp = useAbp\n",
    "        self.useEeg = useEeg\n",
    "        self.useEcg = useEcg\n",
    "\n",
    "        if useAbp:\n",
    "            self.abpBlock1 = ResidualBlock(30000, 15000, 1, 2, 15, 1, True)\n",
    "            self.abpBlock2 = ResidualBlock(15000, 15000, 2, 2, 15, 1, False)\n",
    "            self.abpBlock3 = ResidualBlock(15000, 7500, 2, 2, 15, 1, True)\n",
    "            self.abpBlock4 = ResidualBlock(7500, 7500, 2, 2, 15, 1, False)\n",
    "            self.abpBlock5 = ResidualBlock(7500, 3750, 2, 2, 15, 1, True)\n",
    "            self.abpBlock6 = ResidualBlock(3750, 3750, 2, 4, 15, 1, False)\n",
    "            self.abpBlock7 = ResidualBlock(3750, 1875, 4, 4, 7, 1, True)\n",
    "            self.abpBlock8 = ResidualBlock(1875, 1875, 4, 4, 7, 1, False)\n",
    "            self.abpBlock9 = ResidualBlock(1875, 938, 4, 4, 7, 1, True)\n",
    "            self.abpBlock10 = ResidualBlock(938, 938, 4, 4, 7, 1, False)\n",
    "            self.abpBlock11 = ResidualBlock(938, 469, 4, 6, 7, 1, True)\n",
    "            self.abpBlock12 = ResidualBlock(469, 469, 6, 6, 7, 1, False)\n",
    "            self.abpFc = nn.Linear(6*469, 32)\n",
    "        \n",
    "        if useEcg:\n",
    "            self.ecgBlock1 = ResidualBlock(30000, 15000, 1, 2, 15, 1, True)\n",
    "            self.ecgBlock2 = ResidualBlock(15000, 15000, 2, 2, 15, 1, False)\n",
    "            self.ecgBlock3 = ResidualBlock(15000, 7500, 2, 2, 15, 1, True)\n",
    "            self.ecgBlock4 = ResidualBlock(7500, 7500, 2, 2, 15, 1, False)\n",
    "            self.ecgBlock5 = ResidualBlock(7500, 3750, 2, 2, 15, 1, True)\n",
    "            self.ecgBlock6 = ResidualBlock(3750, 3750, 2, 4, 15, 1, False)\n",
    "            self.ecgBlock7 = ResidualBlock(3750, 1875, 4, 4, 7, 1, True)\n",
    "            self.ecgBlock8 = ResidualBlock(1875, 1875, 4, 4, 7, 1, False)\n",
    "            self.ecgBlock9 = ResidualBlock(1875, 938, 4, 4, 7, 1, True)\n",
    "            self.ecgBlock10 = ResidualBlock(938, 938, 4, 4, 7, 1, False)\n",
    "            self.ecgBlock11 = ResidualBlock(938, 469, 4, 6, 7, 1, True)\n",
    "            self.ecgBlock12 = ResidualBlock(469, 469, 6, 6, 7, 1, False)\n",
    "            self.ecgFc = nn.Linear(6 * 469, 32)\n",
    "        \n",
    "        if useEeg:\n",
    "            self.eegBlock1 = ResidualBlock(7680, 3840, 1, 2, 7, 1, True)\n",
    "            self.eegBlock2 = ResidualBlock(3840, 3840, 2, 2, 7, 1, False)\n",
    "            self.eegBlock3 = ResidualBlock(3840, 1920, 2, 2, 7, 1, True)\n",
    "            self.eegBlock4 = ResidualBlock(1920, 1920, 2, 2, 7, 1, False)\n",
    "            self.eegBlock5 = ResidualBlock(1920, 960, 2, 2, 7, 1, True)\n",
    "            self.eegBlock6 = ResidualBlock(960, 960, 2, 4, 7, 1, False)\n",
    "            self.eegBlock7 = ResidualBlock(960, 480, 4, 4, 3, 1, True)\n",
    "            self.eegBlock8 = ResidualBlock(480, 480, 4, 4, 3, 1, False)\n",
    "            self.eegBlock9 = ResidualBlock(480, 240, 4, 4, 3, 1, True)\n",
    "            self.eegBlock10 = ResidualBlock(240, 240, 4, 4, 3, 1, False)\n",
    "            self.eegBlock11 = ResidualBlock(240, 120, 4, 6, 3, 1, True)\n",
    "            self.eegBlock12 = ResidualBlock(120, 120, 6, 6, 3, 1, False)\n",
    "            self.eegFc = nn.Linear(6 * 120, 32)\n",
    "\n",
    "        concatSize = 0\n",
    "        if useAbp:\n",
    "            concatSize += 32\n",
    "        if useEeg:\n",
    "            concatSize += 32\n",
    "        if useEcg:\n",
    "            concatSize += 32\n",
    "\n",
    "        self.fullLinear1 = nn.Linear(concatSize, 16)\n",
    "        self.fullLinear2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, abp: torch.Tensor, eeg: torch.Tensor, ecg: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        batchSize = len(abp)\n",
    "\n",
    "        # conditionally operate ABP, EEG, and ECG networks\n",
    "        if self.useAbp:\n",
    "            abp = self.abpBlock1(abp)\n",
    "            abp = self.abpBlock2(abp)\n",
    "            abp = self.abpBlock3(abp)\n",
    "            abp = self.abpBlock4(abp)\n",
    "            abp = self.abpBlock5(abp)\n",
    "            abp = self.abpBlock6(abp)\n",
    "            abp = self.abpBlock7(abp)\n",
    "            abp = self.abpBlock8(abp)\n",
    "            abp = self.abpBlock9(abp)\n",
    "            abp = self.abpBlock10(abp)\n",
    "            abp = self.abpBlock11(abp)\n",
    "            abp = self.abpBlock12(abp)\n",
    "            totalLen = np.prod(abp.shape)\n",
    "            abp = torch.reshape(abp, (batchSize, int(totalLen / batchSize)))\n",
    "            abp = self.abpFc(abp)\n",
    "\n",
    "        if self.useEeg:\n",
    "            eeg = self.eegBlock1(eeg)\n",
    "            eeg = self.eegBlock2(eeg)\n",
    "            eeg = self.eegBlock3(eeg)\n",
    "            eeg = self.eegBlock4(eeg)\n",
    "            eeg = self.eegBlock5(eeg)\n",
    "            eeg = self.eegBlock6(eeg)\n",
    "            eeg = self.eegBlock7(eeg)\n",
    "            eeg = self.eegBlock8(eeg)\n",
    "            eeg = self.eegBlock9(eeg)\n",
    "            eeg = self.eegBlock10(eeg)\n",
    "            eeg = self.eegBlock11(eeg)\n",
    "            eeg = self.eegBlock12(eeg)\n",
    "            totalLen = np.prod(eeg.shape)\n",
    "            eeg = torch.reshape(eeg, (batchSize, int(totalLen / batchSize)))\n",
    "            eeg = self.eegFc(eeg)\n",
    "        \n",
    "        if self.useEcg:\n",
    "            ecg = self.ecgBlock1(ecg)\n",
    "            ecg = self.ecgBlock2(ecg)\n",
    "            ecg = self.ecgBlock3(ecg)\n",
    "            ecg = self.ecgBlock4(ecg)\n",
    "            ecg = self.ecgBlock5(ecg)\n",
    "            ecg = self.ecgBlock6(ecg)\n",
    "            ecg = self.ecgBlock7(ecg)\n",
    "            ecg = self.ecgBlock8(ecg)\n",
    "            ecg = self.ecgBlock9(ecg)\n",
    "            ecg = self.ecgBlock10(ecg)\n",
    "            ecg = self.ecgBlock11(ecg)\n",
    "            ecg = self.ecgBlock12(ecg)\n",
    "            #ecg = torch.flatten(ecg)\n",
    "            totalLen = np.prod(ecg.shape)\n",
    "            ecg = torch.reshape(ecg, (batchSize, int(totalLen / batchSize)))\n",
    "            ecg = self.ecgFc(ecg)\n",
    "        \n",
    "        # concatenation\n",
    "        merged = None\n",
    "        if self.useAbp and self.useEeg and self.useEcg:\n",
    "            merged = torch.cat((abp, eeg, ecg))\n",
    "        elif self.useAbp and self.useEeg:\n",
    "            merged = torch.cat((abp, eeg))\n",
    "        elif self.useAbp and self.useEcg:\n",
    "            merged = torch.cat((abp, ecg))\n",
    "        elif self.useEeg and self.useEcg:\n",
    "            merged = torch.cat((eeg, ecg))\n",
    "        elif self.useAbp:\n",
    "            merged = abp\n",
    "        elif self.useEeg:\n",
    "            merged = eeg\n",
    "        elif self.useEcg:\n",
    "            merged = ecg\n",
    "\n",
    "        totalLen = np.prod(merged.shape)\n",
    "        merged = torch.reshape(merged, (batchSize, int(totalLen / batchSize)))\n",
    "        out = self.fullLinear1(merged)\n",
    "        out = self.fullLinear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        out = torch.nan_to_num(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Reiterating details from the Model summary: our training uses Binary Cross Entropy Loss as the loss function and Adam as the optimizer. The learning rate is set to 0.0001. The model will train for 100 epochs and will stop early when we see no loss reduction over the last 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentName = \"ABP_EEG_ECG_DEFAULT\"\n",
    "useAbp = True\n",
    "useEeg = True\n",
    "useEcg = True\n",
    "\n",
    "model = HypotensionCNN(useAbp, useEeg, useEcg)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "def train_model_one_iter(model, loss_func, optimizer, dataloader):\n",
    "  curr_epoch_loss = []\n",
    "  for abp, ecg, eeg, label in tqdm(dataloader):\n",
    "    batch = len(abp)\n",
    "    \n",
    "    abpSampleCount = int(np.prod(abp.shape)/batch)\n",
    "    ecgSampleCount = int(np.prod(ecg.shape)/batch)\n",
    "    eegSampleCount = int(np.prod(eeg.shape)/batch)\n",
    "\n",
    "    abp = torch.nan_to_num(abp.reshape(batch, 1, abpSampleCount)).type(torch.FloatTensor)\n",
    "    ecg = torch.nan_to_num(ecg.reshape(batch, 1, ecgSampleCount)).type(torch.FloatTensor)\n",
    "    eeg = torch.nan_to_num(eeg.reshape(batch, 1, eegSampleCount)).type(torch.FloatTensor)\n",
    "    label = label.type(torch.float).reshape(batch, 1)\n",
    "   \n",
    "    abp = abp.to(device)\n",
    "    eeg = eeg.to(device)\n",
    "    ecg = ecg.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    mdl = model(abp, eeg, ecg)\n",
    "    loss = loss_func(torch.nan_to_num(mdl), label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "  return np.mean(curr_epoch_loss)\n",
    "\n",
    "def eval_model(model, dataloader):\n",
    "  y_pred = []\n",
    "  y_true = []\n",
    "  for abp, ecg, eeg, label in tqdm(dataloader):\n",
    "    batch = len(abp)\n",
    "    abpSampleCount = int(np.prod(abp.shape)/batch)\n",
    "    ecgSampleCount = int(np.prod(ecg.shape)/batch)\n",
    "    eegSampleCount = int(np.prod(eeg.shape)/batch)\n",
    "\n",
    "    abp = abp.to(device)\n",
    "    eeg = eeg.to(device)\n",
    "    ecg = ecg.to(device)\n",
    "    #label = label.to(device)\n",
    "\n",
    "    abp = torch.nan_to_num(abp.reshape(batch, 1, abpSampleCount)).type(torch.FloatTensor)\n",
    "    ecg = torch.nan_to_num(ecg.reshape(batch, 1, ecgSampleCount)).type(torch.FloatTensor)\n",
    "    eeg = torch.nan_to_num(eeg.reshape(batch, 1, eegSampleCount)).type(torch.FloatTensor)\n",
    "    #label = label.type(torch.float).reshape(batch, 1)\n",
    "    \n",
    "    mdl = model(abp, eeg, ecg)\n",
    "\n",
    "    y_pred.append(mdl)\n",
    "    y_true.append(label)\n",
    "    \n",
    "  return y_pred, y_true\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "# model training loop: it is better to print the training/validation losses during the training\n",
    "model.train(True)\n",
    "losses = []\n",
    "for i in range(num_epoch):\n",
    "  exit_early = False\n",
    "  train_loss = train_model_one_iter(model, loss_func, optimizer, train_loader)\n",
    "  if (len(losses) >= 5):\n",
    "    mean_loss = np.mean(losses)\n",
    "    if mean_loss - train_loss < 0.0001:\n",
    "      exit_early = True\n",
    "    else:\n",
    "      losses.pop(0)\n",
    "      losses.append(train_loss)\n",
    "  else:\n",
    "    losses.append(train_loss)\n",
    "  print(f\"[{datetime.now()}] Completed epoch {i} with train loss {train_loss}\")\n",
    "\n",
    "  # exit early if no substantive drop in loss over last 5 epochs\n",
    "  if exit_early:\n",
    "    print(\"Exiting early due to stable training loss\")\n",
    "    break\n",
    "\n",
    "model.train(False)\n",
    "torch.save(model.state_dict(), f\"{VITALDB_CACHE}/{VITAL_MODELS}/{experimentName}.model\")\n",
    "\n",
    "# validation loop\n",
    "#valid_loss = eval_model(model, val_loader)\n",
    "\n",
    "# test loop\n",
    "#test_loss = eval_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6bCcZNuxmz"
   },
   "source": [
    "# Results (Planned results for Draft submission)\n",
    "\n",
    "When we complete our experiments, we will build comparison tables that compare a set of measures for each experiment performed. The full set of experiments and measures are listed below.\n",
    "\n",
    "## Experiments\n",
    "\n",
    " * ABP only\n",
    " * ECG only\n",
    " * EEG only\n",
    " * ABP + ECG\n",
    " * ABP + EEG\n",
    " * ECG + EEG\n",
    " * ABP + ECG + EEG\n",
    "\n",
    "Note: each experiment will be repeated with the following time-to-IOH-event durations:\n",
    " * 3 minutes\n",
    " * 5 minutes\n",
    " * 10 minutes\n",
    " * 15 minutes\n",
    "\n",
    "Note: the above list of experiments will be performed if there is sufficient time and gpu capability to complete that before the submission deadline. Should we experience any constraints on this front, we will reduce our experimental coverage to the following 4 core experiments that are necessary to measure the hypotheses included at the head of this report:\n",
    " * ABP only @ 3 minutes\n",
    " * ABP + ECG @ 3 minutes\n",
    " * ABP + EEG @ 3 minutes\n",
    " * ABP + ECG + EEG @ 3 minutes\n",
    "\n",
    "For additional details please review the \"Planned Actions\" in the Discussion section of this report.\n",
    "\n",
    "## Measures\n",
    "\n",
    " * AUROC\n",
    " * AUPRC\n",
    " * Sensitivity\n",
    " * Specificity\n",
    " * Threshold\n",
    " * Loss Shrinkage\n",
    "\n",
    "[ TODO for final report - collect data for all measures listed above. ]\n",
    "\n",
    "[ TODO for final report - generate ROC and PRC plots for each experiment ]\n",
    "\n",
    "We are collecting a broad set of measures across each experiment in order to perform a comprehensive comparison of all measures listed across all comparable experiments executed in the original paper. However, our key experimental results will be focused on a subset of these results that address the main experiments defined at the beginning of this notebook.\n",
    "\n",
    "The key experimental result measures will be as follows:\n",
    "\n",
    "* For 3 minutes ahead of the predicted IOH event:\n",
    "  * compare AUROC and AUPRC for ABP only vs ABP+ECG\n",
    "  * compare AUROC and AUPRC for ABP only vs ABP+EEG\n",
    "  * compare AUROC and AUPRC for ABP only vs ABP+ECG+EEG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjW9bCkouv8O"
   },
   "outputs": [],
   "source": [
    "# calculate AUROC, AUPRC, sensitivity, specificity, thresold\n",
    "def getMeasures(model):\n",
    "    auroc = None\n",
    "    auprc = None\n",
    "    sensitivity = None\n",
    "    specificity = None\n",
    "    threshold = None\n",
    "    loss_shrinkage = None\n",
    "    \n",
    "    return (auroc, auprc, sensitivity, specificity, threshold, loss_shrinkage)\n",
    "\n",
    "abp3 = getMeasures(\"abp 3 minute\")\n",
    "abpEcg3 = getMeasures(\"abp+Ecg 3 minute\")\n",
    "abpEeg3 = getMeasures(\"abp+Eeg 3 minute\")\n",
    "abpEcgEeg3 = getMeasures(\"abp+Ecg+Eeg 3 minute\")\n",
    "\n",
    "\n",
    "# TODO for final report - generate plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EAWAy_LwHlV"
   },
   "source": [
    "## Model comparison\n",
    "\n",
    "The following table is Table 3 from the original paper which presents the measured values for each signal combination across each of the four temporal predictive categories:\n",
    "\n",
    "![Table 3 from original paper](<https://github.com/abarrie2/cs598-dlh-project/blob/main/img/table_3_measures.PNG?raw=true>)\n",
    "\n",
    "We have not yet completed the execution of the experiments necessary to determine our reproduced model performance in order determine whether our results are accurately representing those of the original paper. These details are expected to be included in the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOdhGrbwwG71"
   },
   "outputs": [],
   "source": [
    "# compare you model with others\n",
    "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper\n",
    "\n",
    "# TODO for final report - embed tabular comparison of our results with those listed in Table 3 from the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "### Feasibility of reproduction\n",
    "Our assessment is that this paper will be reproducible. The outstanding risk is that each experiment can take up to 7 hours to run on hardware within the team (i.e., 7h to run ~70 epochs on a desktop with AMD Ryzen 7 3800X 8-core CPU w/ RTX 2070 SUPER GPU and 32GB RAM). There are a total of 28 experiments (7 different combinations of signal inputs, 4 different time horizons for each combination). Should our team find it not possible to complete the necessary experiments across all of the experiments represented in Table 3 of our selected paper, we will reduce the number of experiments to focus solely on the ones directly related to our hypotheses described in the beginning of this notebook (i.e., reduce the number of combinations of interest to 4: ABP alone, ABP+EEG, ABP+ECG, ABP+ECG+EEG). This will result in a new total of 16 experiments to run.\n",
    "\n",
    "### Planned ablations\n",
    "Our proposal included a collection of potential ablations to be investigated:\n",
    "\n",
    "* Remove ResNet skip connection\n",
    "* Reduce # of residual blocks from 12 to 6\n",
    "* Reduce # of residual blocks from 12 to 1\n",
    "* Eliminate dropout from residual block\n",
    "* Max pooling configuration\n",
    "  * smaller size/stride\n",
    "  * eliminate max pooling\n",
    "\n",
    "Given the amount of time required to conduct each experiment, our team intends to choose only a small number of ablations from this set. Further, we only intend to perform ablation analysis against the best performing signal combination and time horizon from the reproduction experiments. In order words, we intend to perform ablation analysis against the following training combinations, and only against the models trained with data measured 3 minutes prior to an IOH event:\n",
    "  * ABP alone\n",
    "  * ABP + ECG\n",
    "  * ABP + EEG\n",
    "  * ABP + ECG + EEG\n",
    "\n",
    "Time and GPU resource permitting, we will complete a broader range of experiments. For additional details, please see the section below titled \"Plans for next phase\".\n",
    "\n",
    "### Nature of reproduced results\n",
    "Our team intends to address the manner in which the experimental results align with the published results in the paper in the final submission of this report. The amount of time required to complete model training and result analysis during the preparation of the Draft notebook was not sufficient to compelte a large number of experiments.\n",
    "\n",
    "### What was easy? What was difficult?\n",
    "The difficult aspect of the preparation of this draft involved the data preprocessing.\n",
    " * First, the source data is unlabelled, so our team was responsible for implementing analysis methods for identifying positive (IOH event occurred) and negative (IOH event did not occur) by running a lookahead analysis of our input training set.\n",
    " * Second, the volume of raw data is in excess of 90GB. A non-trivial amount of compute was required to minify the input data to only include the data tracks of interest to our experiments (i.e., ABP, ECG, and EEG tracks).\n",
    " * Third, our team found it difficult to trace back to the definition of the jSQI signal quality index referenced in the paper. Multiple references through multiple papers needed to be traversed to understand which variant of the quality index \n",
    "   * The only available source code related to the signal quality index as referenced by our paper in [4]. Source code was not directly linked from the paper, but the GitHub repository for the corresponding author for reference [4] did result in the identification of MATLAB source code for the signal quality index as described in the referenced paper. That code is available here: https://github.com/cliffordlab/PhysioNet-Cardiovascular-Signal-Toolbox/tree/master/Tools/BP_Tools\n",
    "   * Our team had insufficient time to port this signal quality index to Python for use in our investigation, or to setup a MATLAB environment in which to assess our source data using the above MATLAB functions, but we expect to complete this as part of our final report.\n",
    "\n",
    "### Suggestions to paper author\n",
    "The most notable suggestion would be to correct the hyperparameters published in Supplemental Table 1. Specifically, the output size for residual blocks 11 and 12 for the ECG and ABP data sets was 496x6. This is a typo, and shuold read 469x6. This typo became apparent when operating the size down operation within Residual Block 11 and recognizing the tensor dimensions were misaligned.\n",
    "\n",
    "Additionally, more explicit references to the signal quality index assessment tools should be added. Our team could not find a reference to the MATLAB source code as described in reference [3], and had to manually discover the GitHub profile for the lab of the corresponding author of reference [3] in order to find MATLAB source that corresponded to the metrics described therein.\n",
    "\n",
    "### Plans for next phase\n",
    "Our team plans to accomplish the following goals in service of preparing the Final Report:\n",
    " * Implement the jSQI filter to remove any training data with aberrent signal quality per the threshold defined in our original paper.\n",
    " * Execute the following experiments:\n",
    "   * Measure predictive quality of the model trained solely with ABP data at 3 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ABP+ECG data at 3 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ABP+EEG data at 3 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ABP+ECG+EEG data at 3 minutes prior to IOH events.\n",
    " * Gather our measures for these experiments and perform a comparison against the published results from our selected paper and determine whether or not we are succesfully reproducing the results outlined in the paper.\n",
    " * Ablation analysis:\n",
    "   * Execute the following ablation experiments:\n",
    "     * Repeat the four experiments described above while reducing the numnber of residual blocks in the model from 12 to 6.\n",
    " * Time- and/or GPU-resource permitting, we will complete the remaining 24 experiments as described in the paper:\n",
    "   * Measure predictive quality of the model trained solely with ABP data at 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ABP+ECG data at 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ABP+EEG data at 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ABP+ECG+EEG data at 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained solely with ECG data at 3, 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained solely with EEG data at 3, 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Measure predictive quality of the model trained with ECG+EEG data at 3, 5, 10, and 15 minutes prior to IOH events.\n",
    "   * Additional ablation experiments:\n",
    "     * For the four core experiments (ABP, ABP+ECG, ABP+EEG, ABP+ECG+EEG each trained on event data occurring 3 minutes prior to IOH events), perform the following ablations:\n",
    "       * Repeat experiment while eliminating dropout from every residual block\n",
    "       * Repeat experiment while removing the skip connection from every residual block\n",
    "       * Repeat the four experiments described above while reducing the numnber of residual blocks in the model from 12 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "1. Jo Y-Y, Jang J-H, Kwon J-m, Lee H-C, Jung C-W, Byun S, et al. “Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study.” PLoS ONE, (2022) 17(8): e0272055 https://doi.org/10.1371/journal.pone.0272055\n",
    "2. Hatib, Feras, Zhongping J, Buddi S, Lee C, Settels J, Sibert K, Rhinehart J, Cannesson M “Machine-learning Algorithm to Predict Hypotension Based on High-fidelity Arterial Pressure Waveform Analysis” Anesthesiology (2018) 129:4 https://doi.org/10.1097/ALN.0000000000002300\n",
    "3. Bao, X., Kumar, S.S., Shah, N.J. et al. \"AcumenTM hypotension prediction index guidance for prevention and treatment of hypotension in noncardiac surgery: a prospective, single-arm, multicenter trial.\" Perioperative Medicine (2024) 13:13 https://doi.org/10.1186/s13741-024-00369-9\n",
    "4. Li Q., Mark R.G. & Clifford G.D. \"Artificial arterial blood pressure artifact models and an evaluation of a robust blood pressure and heart rate estimator.\" BioMed Eng OnLine. (2009) 8:13. pmid:19586547 https://doi.org/10.1186/1475-925X-8-13"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
