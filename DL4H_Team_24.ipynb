{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/abarrie2/cs598-dlh-project/blob/main/DL4H_Team_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LICENSING NOTICE\n",
    "\n",
    "Note that all users who use Vital DB, an open biosignal dataset, must agree to the Data Use Agreement below. If you do not agree, please close this window. The Data Use Agreement is available here:\n",
    "https://vitaldb.net/dataset/#h.vcpgs1yemdb5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the development version of the project code\n",
    "\n",
    "For the Project Draft submission see the DL4H_Team_24_Project_Draft.ipynb notebook in the project repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project repository\n",
    "\n",
    "The project repository can be found at: https://github.com/abarrie2/cs598-dlh-project\n",
    "\n",
    "## Project video\n",
    "\n",
    "The project video can be found at: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This project aims to reproduce findings from the paper titled \"Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study\" by Jo Y-Y et al. (2022) [1]. This study introduces a deep learning model that predicts intraoperative hypotension (IOH) events before they occur, utilizing a combination of arterial blood pressure (ABP), electroencephalogram (EEG), and electrocardiogram (ECG) signals.\n",
    "\n",
    "\n",
    "## Background of the Problem\n",
    "\n",
    "Intraoperative hypotension (IOH) is a common and significant surgical complication defined by a mean arterial pressure drop below 65 mmHg. It is associated with increased risks of myocardial infarction, acute kidney injury, and heightened postoperative mortality. Effective prediction and timely intervention can substantially enhance patient outcomes.\n",
    "\n",
    "### Evolution of IOH Prediction\n",
    "\n",
    "Initial attempts to predict IOH primarily used arterial blood pressure (ABP) waveforms. A foundational study by Hatib F et al. (2018) titled \"Machine-learning Algorithm to Predict Hypotension Based on High-fidelity Arterial Pressure Waveform Analysis\" [2] showed that machine learning could forecast IOH events using ABP with reasonable accuracy. This finding spurred further research into utilizing various physiological signals for IOH prediction.\n",
    "\n",
    "Subsequent advancements included the development of the Acumenâ„¢ hypotension prediction index, which was studied in \"AcumenTM hypotension prediction index guidance for prevention and treatment of hypotension in noncardiac surgery: a prospective, single-arm, multicenter trial\" by Bao X et al. (2024) [3]. This trial integrated a hypotension prediction index into blood pressure monitoring equipment, demonstrating its effectiveness in reducing the number and duration of IOH events during surgeries. Further study is needed to determine whether this resultant reduction in IOH events transalates into improved postoperative patient outcomes.\n",
    "\n",
    "\n",
    "### Current Study\n",
    "\n",
    "Building on these advancements, the paper by Jo Y-Y et al. (2022) proposes a deep learning approach that enhances prediction accuracy by incorporating EEG and ECG signals along with ABP. This multi-modal method, evaluated over prediction windows of 3, 5, 10, and 15 minutes, aims to provide a comprehensive physiological profile that could predict IOH more accurately and earlier. Their results indicate that the combination of ABP and EEG significantly improves performance metrics such as AUROC and AUPRC, outperforming models that use fewer signals or different combinations.\n",
    "\n",
    "Our project seeks to reproduce and verify Jo Y-Y et al.'s results to assess whether this integrated approach can indeed improve IOH prediction accuracy, thereby potentially enhancing surgical safety and patient outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "## Scope of Reproducibility:\n",
    "\n",
    "The original paper investigated the following hypotheses:\n",
    "\n",
    "1.   Hypothesis 1: A model using ABP and ECG will outperform a model using ABP alone in predicting IOH.\n",
    "2.   Hypothesis 2: A model using ABP and EEG will outperform a model using ABP alone in predicting IOH.\n",
    "3.   Hypothesis 3: A model using ABP, EEG, and ECG will outperform a model using ABP alone in predicting IOH.\n",
    "\n",
    "Results were compared using AUROC and AUPRC scores. Based on the results described in the original paper, we expect that Hypothesis 2 will be confirmed, and that Hypotheses 1 and 3 will not be confirmed.\n",
    "\n",
    "In order to perform the corresponding experiments, we will implement a CNN-based model that can be configured to train and infer using the following four model variations:\n",
    "\n",
    "1.   ABP data alone\n",
    "2.   ABP and ECG data\n",
    "3.   ABP and EEG data\n",
    "4.   ABP, ECG, and EEG data\n",
    "\n",
    "We will measure the performance of these configurations using the same AUROC and AUPRC metrics as used in the original paper. To test hypothesis 1 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 2. To test hypothesis 2 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 3. To test hypothesis 3 we will compare the AUROC and AUPRC measures between model variation 1 and model variation 4. For all of the above measures and experiment combinations, we will operate multiple experiments where the time-to-IOH event prediction will use the following prediction windows:\n",
    "\n",
    "1. 3 minutes before event\n",
    "2. 5 minutes before event\n",
    "3. 10 minutes before event\n",
    "4. 15 minutes before event\n",
    "\n",
    "From the original paper, the predictive power of ABP, ECG and ABP + ECG models at 3-, 5-, 10- and 15-minute prediction windows:\n",
    "![Predictive power of ABP, ECG and ABP + ECG models at 3-, 5-, 10- and 15-minute prediction windows](https://journals.plos.org/plosone/article/figure/image?download&size=large&id=10.1371/journal.pone.0272055.g004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications made for demo mode\n",
    "\n",
    "In order to demonstrate the functioning of the code in a short (ie, <8 minute limit) the following options and modifications were used:\n",
    "\n",
    "1. `MAX_CASES` was set to 20. The total number of cases to be used in the full training set is 3296, but the smaller numbers allows demonstration of each section of the pipeline.\n",
    "2. `vitaldb_cache` is prepopulated in Google Colab. The cache file is approx. 800MB and contains the raw and mini-fied copies of the source dataset and is downloaded from Google Drive. This is much faster than using the `vitaldb` API, but is again only a fraction of the data. The full dataset can be downloaded with the API or prepopulated by following the instructions in the \"Bulk Data Download\" section below.\n",
    "3. `max_epochs` is set to 6. With the small dataset, training is fast and shows the decreasing training and validation losses. In the full model run, `max_epochs` will be set to 100. In both cases early stopping is enabled and will stop training if the validation losses stop decreasing for five consecutive epochs.\n",
    "4. Only the \"ABP + EEG\" combination will be run. In the final report, additional combinations will be run, as discussed later.\n",
    "5. Only the 3-minute prediction window will be run. In the final report, additional prediction windows (5, 10 and 15 minutes) will be run, as discussed later.\n",
    "6. No ablations are run in the demo. These will be completed for the final report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methodology section is composed of the following subsections: Environment, Data and Model.\n",
    "\n",
    "- **Environment**: This section describes the setup of the environment, including the installation of necessary libraries and the configuration of the runtime environment.\n",
    "- **Data**: This section describes the dataset used in the study, including its collection and preprocessing.\n",
    "    - **Data Collection**: This section describes the process of downloading the dataset from VitalDB and populating the local data cache.\n",
    "    - **Data Preprocessing**: This section describes the preprocessing steps applied to the dataset, including data selection, data cleaning, and feature extraction.\n",
    "- **Model**: This section describes the deep learning model used in the study, including its implementation, training, and evaluation.\n",
    "    - **Model Implementation**: This section describes the implementation of the deep learning model, including the architecture, loss function, and optimization algorithm.\n",
    "    - **Model Training**: This section describes the training process, including the training loop, hyperparameters, and training strategy.\n",
    "    - **Model Evaluation**: This section describes the evaluation process, including the metrics used, the evaluation strategy, and the results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "### Create environment\n",
    "\n",
    "The environment setup differs based on whether you are running the code on a local machine or on Google Colab. The following sections provide instructions for setting up the environment in each case.\n",
    "\n",
    "#### Local machine\n",
    "\n",
    "Create `conda` environment for the project using the `environment.yml` file:\n",
    "\n",
    "```bash\n",
    "conda env create --prefix .envs/dlh-team24 -f environment.yml\n",
    "```\n",
    "\n",
    "Activate the environment with:\n",
    "```bash\n",
    "conda activate .envs/dlh-team24\n",
    "```\n",
    "\n",
    "This environment specifies Python 3.12.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "\n",
    "The following code snippet installs the required packages and downloads the necessary files in a Google Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu61Jp1xrnKk"
   },
   "outputs": [],
   "source": [
    "# Google Colab environments have a `/content` directory. Use this as a proxy for running Colab-only code\n",
    "COLAB_ENV = \"google.colab\" in str(get_ipython())\n",
    "if COLAB_ENV:\n",
    "    #install vitaldb\n",
    "    %pip install vitaldb\n",
    "\n",
    "    # Executing in Colab therefore download cached preprocessed data.\n",
    "    # TODO: Integrate this with the setup local cache data section below.\n",
    "    # Check for file existence before overwriting.\n",
    "    import gdown\n",
    "    gdown.download(id=\"15b5Nfhgj3McSO2GmkVUKkhSSxQXX14hJ\", output=\"vitaldb_cache.tgz\")\n",
    "    !tar -zxf vitaldb_cache.tgz\n",
    "\n",
    "    # Download sqi_filter.csv from github repo\n",
    "    !wget https://raw.githubusercontent.com/abarrie2/cs598-dlh-project/main/sqi_filter.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other required packages are already installed in the Google Colab environment. As of May 5, 2024, Google Colab uses Python 3.10.12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import uuid\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter, spectrogram\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import vitaldb\n",
    "import h5py\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a timer to measure notebook runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_time_start = timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seeds to generate consistent results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def reset_random_state():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(RANDOM_SEED)\n",
    "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_SEED)\n",
    "    \n",
    "reset_random_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device to GPU or MPS if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if (torch.backends.mps.is_available() and torch.backends.mps.is_built()) else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define class to print to console and simultaneously save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForkedStdout:\n",
    "    def __init__(self, file_path):\n",
    "        self.file = open(file_path, 'w')\n",
    "        self.stdout = sys.stdout\n",
    "\n",
    "    def write(self, message):\n",
    "        self.stdout.write(message)\n",
    "        self.file.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        self.stdout.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def __enter__(self):\n",
    "        sys.stdout = self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout = self.stdout\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "##  Data\n",
    "\n",
    "### Data Description\n",
    "\n",
    "#### Source\n",
    "\n",
    "Data for this project is sourced from the open biosignal VitalDB dataset as described in \"VitalDB, a high-fidelity multi-parameter vital signs database in surgical patients\" by Lee H-C et al. (2022) [4], which contains perioperative vital signs and numerical data from 6,388 cases of non-cardiac (general, thoracic, urological, and gynecological) surgery patients who underwent routine or emergency surgery at Seoul National University Hospital between 2016 and 2017. The dataset includes ABP, ECG, and EEG signals, as well as other physiological data. The dataset is available through an [API](https://vitaldb.net/dataset/?query=api) and [Python library](https://vitaldb.net/dataset/?query=lib), and at PhysioNet: https://physionet.org/content/vitaldb/1.0.0/\n",
    "\n",
    "#### Statistics\n",
    "\n",
    "Characteristics of the dataset:\n",
    "| Characteristic        | Value                       | Details                |\n",
    "|-----------------------|-----------------------------|------------------------|\n",
    "| Total number of cases | 6,388                       |                        |\n",
    "| Sex (male)            | 3,243 (50.8%)               |                        |\n",
    "| Age (years)           | 59                          | Range: 48-68           |\n",
    "| Height (cm)           | 162                         | Range: 156-169         |\n",
    "| Weight (kg)           | 61                          | Range: 53-69           |\n",
    "| Tram-Rac 4A tracks    | 6,355 (99.5%)               | Sampling rate: 500Hz   |\n",
    "| BIS Vista tracks      | 5,566 (87.1%)               | Sampling rate: 128Hz   |\n",
    "| Case duration (min)   | 189                         | Range: 27-1041         |\n",
    "\n",
    "Labels are only known after processing the data. In the original paper, there were an average of 1.6 IOH events per case and 5.7 non-events per case so we expect approximately 10,221 IOH events and 364,116 non-events in the dataset.\n",
    "\n",
    "#### Data Processing\n",
    "\n",
    "Data will be processed as follows:\n",
    "1. Load the dataset from VitalDB, or from a local cache if previously downloaded.\n",
    "2. Apply the inclusion and exclusion selection criteria to filter the dataset according to surgery metadata.\n",
    "3. Generate a minified dataset by discarding all tracks except ABP, ECG, and EEG.\n",
    "4. Preprocess the data by applying band-pass and z-score normalization to the ECG and EEG signals, and filtering out ABP signals below a Signal Quality Index (SQI) threshold.\n",
    "5. Generate event and non-event samples by extracting 60-second segments around IOH events and non-events.\n",
    "6. Split the dataset into training, validation, and test sets with a 6:1:3 ratio, ensuring that samples from a single case are not split across different sets to avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Local Data Caches\n",
    "\n",
    "VitalDB data is static, so local copies can be stored and reused to avoid expensive downloads and to speed up data processing.\n",
    "\n",
    "The default directory defined below is in the project `.gitignore` file. If this is modified, the new directory should also be added to the project `.gitignore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VITALDB_CACHE = './vitaldb_cache'\n",
    "VITAL_ALL = f\"{VITALDB_CACHE}/vital_all\"\n",
    "VITAL_MINI = f\"{VITALDB_CACHE}/vital_mini\"\n",
    "VITAL_METADATA = f\"{VITALDB_CACHE}/metadata\"\n",
    "VITAL_MODELS = f\"{VITALDB_CACHE}/models\"\n",
    "VITAL_RUNS = f\"{VITALDB_CACHE}/runs\"\n",
    "VITAL_PREPROCESS_SCRATCH = f\"{VITALDB_CACHE}/data_scratch\"\n",
    "VITAL_EXTRACTED_SEGMENTS = f\"{VITALDB_CACHE}/segments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_CACHE = None\n",
    "SEGMENT_CACHE = None\n",
    "\n",
    "# when USE_MEMORY_CACHING is enabled, track data will be persisted in an in-memory cache. Not useful once we have already pre-extracted all event segments\n",
    "# DON'T USE: Stores items in memory that are later not used. Causes OOM on segment extraction.\n",
    "USE_MEMORY_CACHING = False\n",
    "\n",
    "# When RESET_CACHE is set to True, it will ensure the TRACK_CACHE is disposed and recreated when we do dataset initialization.\n",
    "# Use as a shortcut to wiping cache rather than restarting kernel\n",
    "RESET_CACHE = False\n",
    "\n",
    "PREDICTION_WINDOW = 3\n",
    "#PREDICTION_WINDOW = 'ALL'\n",
    "\n",
    "ALL_PREDICTION_WINDOWS = [3, 5, 10, 15]\n",
    "\n",
    "# Maximum number of cases of interest for which to download data.\n",
    "# Set to a small value (ex: 20) for demo purposes, else set to None to disable and download and process all.\n",
    "MAX_CASES = None\n",
    "#MAX_CASES = 300\n",
    "\n",
    "# Preloading Cases: when true, all matched cases will have the _mini tracks extracted and put into in-mem dict\n",
    "PRELOADING_CASES = False\n",
    "PRELOADING_SEGMENTS = True\n",
    "# Perform Data Preprocessing: do we want to take the raw vital file and extract segments of interest for training?\n",
    "PERFORM_DATA_PREPROCESSING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(VITALDB_CACHE):\n",
    "  os.mkdir(VITALDB_CACHE)\n",
    "if not os.path.exists(VITAL_ALL):\n",
    "  os.mkdir(VITAL_ALL)\n",
    "if not os.path.exists(VITAL_MINI):\n",
    "  os.mkdir(VITAL_MINI)\n",
    "if not os.path.exists(VITAL_METADATA):\n",
    "  os.mkdir(VITAL_METADATA)\n",
    "if not os.path.exists(VITAL_MODELS):\n",
    "  os.mkdir(VITAL_MODELS)\n",
    "if not os.path.exists(VITAL_RUNS):\n",
    "  os.mkdir(VITAL_RUNS)\n",
    "if not os.path.exists(VITAL_PREPROCESS_SCRATCH):\n",
    "  os.mkdir(VITAL_PREPROCESS_SCRATCH)\n",
    "if not os.path.exists(VITAL_EXTRACTED_SEGMENTS):\n",
    "  os.mkdir(VITAL_EXTRACTED_SEGMENTS)\n",
    "\n",
    "print(os.listdir(VITALDB_CACHE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk Data Download\n",
    "\n",
    "**This step is not required, but will significantly speed up downstream processing and avoid a high volume of API requests to the VitalDB web site.**\n",
    "\n",
    "**Note:** The dataset is slightly different depending on whether it is downloaded from the API or from Physionet. In almost all cases, the relevant tracks are identical between the two, but this is not always true.\n",
    "\n",
    "The cache population code checks if the `.vital` files are locally available, and can be populated by calling the vitaldb API or by manually prepopulating the cache (recommended)\n",
    "\n",
    "- Manually downloaded the dataset from the following site: https://physionet.org/content/vitaldb/1.0.0/\n",
    "    - Download the [zip file](https://physionet.org/static/published-projects/vitaldb/vitaldb-a-high-fidelity-multi-parameter-vital-signs-database-in-surgical-patients-1.0.0.zip) in a browser, or\n",
    "    - Use `wget -r -N -c -np https://physionet.org/files/vitaldb/1.0.0/` to download the files in a terminal\n",
    "- Move the contents of `vital_files` into the `${VITAL_ALL}` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pandas DataFrame for the specified dataset.\n",
    "#   One of 'cases', 'labs', or 'trks'\n",
    "# If the file exists locally, create and return the DataFrame.\n",
    "# Else, download and cache the csv first, then return the DataFrame.\n",
    "def vitaldb_dataframe_loader(dataset_name):\n",
    "    if dataset_name not in ['cases', 'labs', 'trks']:\n",
    "        raise ValueError(f'Invalid dataset name: {dataset_name}')\n",
    "    file_path = f'{VITAL_METADATA}/{dataset_name}.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f'{dataset_name}.csv exists locally.')\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        print(f'downloading {dataset_name} and storing in the local cache for future reuse.')\n",
    "        df = pd.read_csv(f'https://api.vitaldb.net/{dataset_name}')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "#### Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = vitaldb_dataframe_loader('cases')\n",
    "cases = cases.set_index('caseid')\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks = vitaldb_dataframe_loader('trks')\n",
    "trks = trks.set_index('caseid')\n",
    "trks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('tname').count().sort_values(by='tid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hemodynamic Parameters Reference\n",
    "https://vitaldb.net/dataset/?query=overview#h.f7d712ycdpk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNUADC/ART**\n",
    "\n",
    "arterial blood pressure waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ART, Arterial pressure wave, W/500, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ART')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNUADC/ECG_II**\n",
    "\n",
    "electrocardiogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ECG_II, ECG lead II wave, W/500, mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ECG_II')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIS/EEG1_WAV**\n",
    "\n",
    "electroencephalogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "BIS/EEG1_WAV, EEG wave from channel 1, W/128, uV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('BIS/EEG1_WAV')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cases of Interest\n",
    "\n",
    "These are the subset of case ids for which modelling and analysis will be performed based upon inclusion criteria and waveform data availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACK NAMES is used for metadata analysis via API\n",
    "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']\n",
    "TRACK_SRATES = [500, 500, 128]\n",
    "# EXTRACTION TRACK NAMES adds the EVENT track which is only used when doing actual file i/o\n",
    "EXTRACTION_TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV', 'EVENT']\n",
    "EXTRACTION_TRACK_SRATES = [500, 500, 128, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the paper, select cases which meet the following criteria:\n",
    "\n",
    "For patients, the inclusion criteria were as follows:\n",
    "1. adults (age >= 18)\n",
    "2. administered general anaesthesia\n",
    "3. undergone non-cardiac surgery. \n",
    "\n",
    "For waveform data, the inclusion criteria were as follows:\n",
    "1. no missing monitoring for ABP, ECG, and EEG waveforms\n",
    "2. no cases containing false events or non-events due to poor signal quality (checked in second stage of data preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult\n",
    "inclusion_1 = cases.loc[cases['age'] >= 18].index\n",
    "print(f'{len(cases)-len(inclusion_1)} cases excluded, {len(inclusion_1)} remaining due to age criteria')\n",
    "\n",
    "# General Anesthesia\n",
    "inclusion_2 = cases.loc[cases['ane_type'] == 'General'].index\n",
    "print(f'{len(cases)-len(inclusion_2)} cases excluded, {len(inclusion_2)} remaining due to anesthesia criteria')\n",
    "\n",
    "# Non-cardiac surgery\n",
    "inclusion_3 = cases.loc[\n",
    "    ~cases['opname'].str.contains(\"cardiac\", case=False)\n",
    "    & ~cases['opname'].str.contains(\"aneurysmal\", case=False)\n",
    "].index\n",
    "print(f'{len(cases)-len(inclusion_3)} cases excluded, {len(inclusion_3)} remaining due to non-cardiac surgery criteria')\n",
    "\n",
    "# ABP, ECG, EEG waveforms\n",
    "inclusion_4 = trks.loc[trks['tname'].isin(TRACK_NAMES)].index.value_counts()\n",
    "inclusion_4 = inclusion_4[inclusion_4 == len(TRACK_NAMES)].index\n",
    "print(f'{len(cases)-len(inclusion_4)} cases excluded, {len(inclusion_4)} remaining due to missing waveform data')\n",
    "\n",
    "# SQI filter\n",
    "# NOTE: this depends on a sqi_filter.csv generated by external processing\n",
    "inclusion_5 = pd.read_csv('sqi_filter.csv', header=None, names=['caseid','sqi']).set_index('caseid').index\n",
    "print(f'{len(cases)-len(inclusion_5)} cases excluded, {len(inclusion_5)} remaining due to SQI threshold not being met')\n",
    "\n",
    "# Only include cases with known good waveforms.\n",
    "exclusion_6 = pd.read_csv('malformed_tracks_filter.csv', header=None, names=['caseid']).set_index('caseid').index\n",
    "inclusion_6 = cases.index.difference(exclusion_6)\n",
    "print(f'{len(cases)-len(inclusion_6)} cases excluded, {len(inclusion_6)} remaining due to malformed waveforms')\n",
    "\n",
    "cases_of_interest_idx = inclusion_1 \\\n",
    "    .intersection(inclusion_2) \\\n",
    "    .intersection(inclusion_3) \\\n",
    "    .intersection(inclusion_4) \\\n",
    "    .intersection(inclusion_5) \\\n",
    "    .intersection(inclusion_6)\n",
    "\n",
    "cases_of_interest = cases.loc[cases_of_interest_idx]\n",
    "\n",
    "print()\n",
    "print(f'{cases_of_interest_idx.shape[0]} out of {cases.shape[0]} total cases remaining after exclusions applied')\n",
    "\n",
    "# Trim cases of interest to MAX_CASES\n",
    "if MAX_CASES:\n",
    "    cases_of_interest_idx = cases_of_interest_idx[:MAX_CASES]\n",
    "print(f'{cases_of_interest_idx.shape[0]} cases of interest selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the original paper, the authors used an SQI measure they called jSQI but which appears to be jSQI + wSQI. We were not able to implement the same filter, so the inclusion of `sqi_filter.csv` simulates the inclusion of this filter. By not excluding cases where the SQI is below the threshold set by the authors, our dataset is noisier than that used by the original authors which will impact performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracks of Interest\n",
    "\n",
    "These are the subset of tracks (waveforms) for the cases of interest identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single case maps to one or more waveform tracks. Select only the tracks required for analysis.\n",
    "trks_of_interest = trks.loc[cases_of_interest_idx][trks.loc[cases_of_interest_idx]['tname'].isin(TRACK_NAMES)]\n",
    "trks_of_interest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest_idx = trks_of_interest.set_index('tid').index\n",
    "trks_of_interest_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tracks Cache for Local Processing\n",
    "\n",
    "Tracks data are large and therefore expensive to download every time used.\n",
    "By default, the `.vital` file format stores all tracks for each case internally. Since only select tracks per case are required, each `.vital` file can be further reduced by discarding the unused tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the full vital file dataset is available for cases of interest.\n",
    "count_downloaded = 0\n",
    "count_present = 0\n",
    "\n",
    "#for i, idx in enumerate(cases.index):\n",
    "for idx in cases_of_interest_idx:\n",
    "    full_path = f'{VITAL_ALL}/{idx:04d}.vital'\n",
    "    if not os.path.isfile(full_path):\n",
    "        print(f'Missing vital file: {full_path}')\n",
    "        # Download and save the file.\n",
    "        vf = vitaldb.VitalFile(idx)\n",
    "        vf.to_vital(full_path)\n",
    "        count_downloaded += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files downloaded:      {count_downloaded}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Mini Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the minified `.vital` files and check that all of the required data tracks are present. The Vital API does not throw an error when you request a track that does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vital files to \"mini\" versions including only the subset of tracks defined in TRACK_NAMES above.\n",
    "# Only perform conversion for the cases of interest.\n",
    "# NOTE: If this cell is interrupted, it can be restarted and will continue where it left off.\n",
    "count_minified = 0\n",
    "count_present = 0\n",
    "count_missing_tracks = 0\n",
    "count_not_fixable = 0\n",
    "\n",
    "# If set to true, local mini files are checked for all tracks even if the mini file is already present.\n",
    "FORCE_VALIDATE = False\n",
    "\n",
    "for idx in cases_of_interest_idx:\n",
    "    full_path = f'{VITAL_ALL}/{idx:04d}.vital'\n",
    "    mini_path = f'{VITAL_MINI}/{idx:04d}_mini.vital'\n",
    "\n",
    "    if FORCE_VALIDATE or not os.path.isfile(mini_path):\n",
    "        print(f'Creating mini vital file: {idx}')\n",
    "        vf = vitaldb.VitalFile(full_path, EXTRACTION_TRACK_NAMES)\n",
    "        \n",
    "        if len(vf.get_track_names()) != 4:\n",
    "            print(f'Missing track in vital file: {idx}, {set(EXTRACTION_TRACK_NAMES).difference(set(vf.get_track_names()))}')\n",
    "            count_missing_tracks += 1\n",
    "            \n",
    "            # Attempt to download from VitalDB directly and see if missing tracks are present.\n",
    "            vf = vitaldb.VitalFile(idx, EXTRACTION_TRACK_NAMES)\n",
    "            \n",
    "            if len(vf.get_track_names()) != 4:\n",
    "                print(f'Unable to fix missing tracks: {idx}')\n",
    "                count_not_fixable += 1\n",
    "                continue\n",
    "                \n",
    "            if vf.get_track_samples(EXTRACTION_TRACK_NAMES[0], 1/EXTRACTION_TRACK_SRATES[0]).shape[0] == 0:\n",
    "                print(f'Empty track: {idx}, {EXTRACTION_TRACK_NAMES[0]}')\n",
    "                count_not_fixable += 1\n",
    "                continue\n",
    "                \n",
    "            if vf.get_track_samples(EXTRACTION_TRACK_NAMES[1], 1/EXTRACTION_TRACK_SRATES[1]).shape[0] == 0:\n",
    "                print(f'Empty track: {idx}, {EXTRACTION_TRACK_NAMES[1]}')\n",
    "                count_not_fixable += 1\n",
    "                continue\n",
    "                \n",
    "            if vf.get_track_samples(EXTRACTION_TRACK_NAMES[2], 1/EXTRACTION_TRACK_SRATES[2]).shape[0] == 0:\n",
    "                print(f'Empty track: {idx}, {EXTRACTION_TRACK_NAMES[2]}')\n",
    "                count_not_fixable += 1\n",
    "                continue\n",
    "\n",
    "            if vf.get_track_samples(EXTRACTION_TRACK_NAMES[3], 1/EXTRACTION_TRACK_SRATES[3]).shape[0] == 0:\n",
    "                print(f'Empty track: {idx}, {EXTRACTION_TRACK_NAMES[3]}')\n",
    "                count_not_fixable += 1\n",
    "                continue\n",
    "\n",
    "        vf.to_vital(mini_path)\n",
    "        count_minified += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files minified:        {count_minified}')\n",
    "print(f'Count of vital files already present: {count_present}')\n",
    "print(f'Count of vital files missing tracks:  {count_missing_tracks}')\n",
    "print(f'Count of vital files not fixable:     {count_not_fixable}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering\n",
    "\n",
    "As in the original paper, preprocessing characteristics are different for each of the three signal categories:\n",
    " * ABP: no preprocessing, use as-is\n",
    " * ECG: apply a 1-40Hz bandpass filter, then perform Z-score normalization\n",
    " * EEG: apply a 0.5-50Hz bandpass filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`apply_bandpass_filter()` implements the bandpass filter using scipy.signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "    y = lfilter(b, a, np.nan_to_num(data))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`apply_zscore_normalization()` implements the Z-score normalization using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_zscore_normalization(signal):\n",
    "    mean = np.nanmean(signal)\n",
    "    std = np.nanstd(signal)\n",
    "    return (signal - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering demonstration\n",
    "\n",
    "Demonstrate effects of the filters with pre/post filtering waveforms on a sample case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseidx = 1\n",
    "file_path = f\"{VITAL_MINI}/{caseidx:04d}_mini.vital\"\n",
    "vf = vitaldb.VitalFile(file_path, TRACK_NAMES)\n",
    "\n",
    "originalAbp = None\n",
    "filteredAbp = None\n",
    "originalEcg = None\n",
    "filteredEcg = None\n",
    "originalEeg = None\n",
    "filteredEeg = None\n",
    "\n",
    "ABP_TRACK_NAME = \"SNUADC/ART\"\n",
    "ECG_TRACK_NAME = \"SNUADC/ECG_II\"\n",
    "EEG_TRACK_NAME = \"BIS/EEG1_WAV\"\n",
    "\n",
    "for i, (track_name, rate) in enumerate(zip(TRACK_NAMES, TRACK_SRATES)):\n",
    "    # Get samples for this track\n",
    "    track_samples = vf.get_track_samples(track_name, 1/rate)\n",
    "    #track_samples, _ = vf.get_samples(track_name, 1/rate)\n",
    "    print(f\"Track {track_name} @ {rate}Hz shape {len(track_samples)}\")\n",
    "\n",
    "    if track_name == ABP_TRACK_NAME:\n",
    "        # ABP waveforms are used without further pre-processing\n",
    "        originalAbp = track_samples\n",
    "        filteredAbp = track_samples\n",
    "    elif track_name == ECG_TRACK_NAME:\n",
    "        originalEcg = track_samples\n",
    "        # ECG waveforms are band-pass filtered between 1 and 40 Hz, and Z-score normalized\n",
    "        # first apply bandpass filter\n",
    "        filteredEcg = apply_bandpass_filter(track_samples, 1, 40, rate)\n",
    "        # then do z-score normalization\n",
    "        filteredEcg = apply_zscore_normalization(filteredEcg)\n",
    "    elif track_name == EEG_TRACK_NAME:\n",
    "        # EEG waveforms are band-pass filtered between 0.5 and 50 Hz\n",
    "        originalEeg = track_samples\n",
    "        filteredEeg = apply_bandpass_filter(track_samples, 0.5, 50, rate, 2)\n",
    "\n",
    "def plotSignal(data, title):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plotSignal(originalAbp, \"Original ABP\")\n",
    "plotSignal(originalAbp, \"Unfiltered ABP\")\n",
    "plotSignal(originalEcg, \"Original ECG\")\n",
    "plotSignal(filteredEcg, \"Filtered ECG\")\n",
    "plotSignal(originalEeg, \"Original EEG\")\n",
    "plotSignal(filteredEeg, \"Filtered EEG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data preprocessing\n",
    "\n",
    "This section performs the actual data preprocessing laid out earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data tracks\n",
    "ABP_TRACK_NAME = \"SNUADC/ART\"\n",
    "ECG_TRACK_NAME = \"SNUADC/ECG_II\"\n",
    "EEG_TRACK_NAME = \"BIS/EEG1_WAV\"\n",
    "EVENT_TRACK_NAME = \"EVENT\"\n",
    "MINI_FILE_FOLDER = VITAL_MINI\n",
    "CACHE_FILE_FOLDER = VITAL_PREPROCESS_SCRATCH\n",
    "\n",
    "if RESET_CACHE:\n",
    "    TRACK_CACHE = None\n",
    "    SEGMENT_CACHE = None\n",
    "\n",
    "if TRACK_CACHE is None:\n",
    "    TRACK_CACHE = {}\n",
    "    SEGMENT_CACHE = {}\n",
    "\n",
    "def get_track_data(case, print_when_file_loaded = False):\n",
    "    parsedFile = None\n",
    "    abp = None\n",
    "    eeg = None\n",
    "    ecg = None\n",
    "    events = None\n",
    "\n",
    "    for i, (track_name, rate) in enumerate(zip(EXTRACTION_TRACK_NAMES, EXTRACTION_TRACK_SRATES)):\n",
    "        # use integer case id and track name, delimited by pipe, as cache key\n",
    "        cache_label = f\"{case}|{track_name}\"\n",
    "        \n",
    "        if cache_label not in TRACK_CACHE:\n",
    "            if parsedFile is None:\n",
    "                file_path = f\"{MINI_FILE_FOLDER}/{case:04d}_mini.vital\"\n",
    "                if print_when_file_loaded:\n",
    "                    print(f\"[{datetime.now()}] Loading vital file {file_path}\")\n",
    "                parsedFile = vitaldb.VitalFile(file_path, EXTRACTION_TRACK_NAMES)\n",
    "            \n",
    "            dataset = np.array(parsedFile.get_track_samples(track_name, 1/rate))\n",
    "            \n",
    "            if track_name == ABP_TRACK_NAME:\n",
    "                # no filtering for ABP\n",
    "                abp = dataset\n",
    "                abp = pd.DataFrame(abp).ffill(axis=0).bfill(axis=0)[0].values\n",
    "                if USE_MEMORY_CACHING:\n",
    "                    TRACK_CACHE[cache_label] = abp\n",
    "            elif track_name == ECG_TRACK_NAME:\n",
    "                ecg = dataset\n",
    "                # apply ECG filtering: first bandpass then do z-score normalization\n",
    "                ecg = pd.DataFrame(ecg).ffill(axis=0).bfill(axis=0)[0].values\n",
    "                ecg = apply_bandpass_filter(ecg, 1, 40, rate, 2)\n",
    "                ecg = apply_zscore_normalization(ecg)\n",
    "                \n",
    "                if USE_MEMORY_CACHING:\n",
    "                    TRACK_CACHE[cache_label] = ecg\n",
    "            elif track_name == EEG_TRACK_NAME:\n",
    "                eeg = dataset\n",
    "                eeg = pd.DataFrame(eeg).ffill(axis=0).bfill(axis=0)[0].values\n",
    "                # apply EEG filtering: bandpass only\n",
    "                eeg = apply_bandpass_filter(eeg, 0.5, 50, rate, 2)\n",
    "                if USE_MEMORY_CACHING:\n",
    "                    TRACK_CACHE[cache_label] = eeg\n",
    "            elif track_name == EVENT_TRACK_NAME:\n",
    "                events = dataset\n",
    "                if USE_MEMORY_CACHING:\n",
    "                    TRACK_CACHE[cache_label] = events\n",
    "        else:\n",
    "            # cache hit, pull from cache\n",
    "            if track_name == ABP_TRACK_NAME:\n",
    "                abp = TRACK_CACHE[cache_label]\n",
    "            elif track_name == ECG_TRACK_NAME:\n",
    "                ecg = TRACK_CACHE[cache_label]\n",
    "            elif track_name == EEG_TRACK_NAME:\n",
    "                eeg = TRACK_CACHE[cache_label]\n",
    "            elif track_name == EVENT_TRACK_NAME:\n",
    "                events = TRACK_CACHE[cache_label]\n",
    "\n",
    "    return (abp, ecg, eeg, events)\n",
    "\n",
    "# ABP waveforms are used without further pre-processing\n",
    "# ECG waveforms are band-pass filtered between 1 and 40 Hz, and Z-score normalized\n",
    "# EEG waveforms are band-pass filtered between 0.5 and 50 Hz\n",
    "if PRELOADING_CASES:\n",
    "    # determine disk cache file label\n",
    "    maxlabel = \"ALL\"\n",
    "    if MAX_CASES is not None:\n",
    "        maxlabel = str(MAX_CASES)\n",
    "    picklefile = f\"{CACHE_FILE_FOLDER}/{PREDICTION_WINDOW}_minutes_MAX{maxlabel}.trackcache\"\n",
    "\n",
    "    for track in tqdm(cases_of_interest_idx):\n",
    "        # getting track data will cause a cache-check and fill when missing\n",
    "        # will also apply appropriate filtering per track\n",
    "        get_track_data(track, False)\n",
    "    \n",
    "    print(f\"Generated track cache, {len(TRACK_CACHE)} records generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed data is stored in `.h5` files. Define a loader to read this data and return a tuple with the waveform data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_data(file_path):\n",
    "    abp = None\n",
    "    eeg = None\n",
    "    ecg = None\n",
    "\n",
    "    if USE_MEMORY_CACHING:\n",
    "        if file_path in SEGMENT_CACHE:\n",
    "            (abp, ecg, eeg) = SEGMENT_CACHE[file_path]\n",
    "            return (abp, ecg, eeg)\n",
    "\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            abp = np.array(f['abp'])\n",
    "            ecg = np.array(f['ecg'])\n",
    "            eeg = np.array(f['eeg'])\n",
    "        \n",
    "        abp = np.array(abp)\n",
    "        eeg = np.array(eeg)\n",
    "        ecg = np.array(ecg)\n",
    "\n",
    "        if len(abp) > 30000:\n",
    "            abp = abp[:30000]\n",
    "        elif len(abp) < 30000:\n",
    "            abp = np.resize(abp, (30000))\n",
    "\n",
    "        if len(ecg) > 30000:\n",
    "            ecg = ecg[:30000]\n",
    "        elif len(ecg) < 30000:\n",
    "            ecg = np.resize(ecg, (30000))\n",
    "\n",
    "        if len(eeg) > 7680:\n",
    "            eeg = eeg[:7680]\n",
    "        elif len(eeg) < 7680:\n",
    "            eeg = np.resize(eeg, (7680))\n",
    "\n",
    "        if USE_MEMORY_CACHING:\n",
    "            SEGMENT_CACHE[file_path] = (abp, ecg, eeg)\n",
    "    except:\n",
    "        abp = None\n",
    "        ecg = None\n",
    "        eeg = None\n",
    "\n",
    "    return (abp, ecg, eeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.vital` files contain timeseries information before and after the surgery starts, and include a label start where significant events can be indicated. Define a function to read from this track and extract surgery start and end times so that data can be extracted from this period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurgeryBoundariesInSeconds(event, debug=False):\n",
    "    eventIndices = np.argwhere(event==event)\n",
    "    # we are looking for the last index where the string contains 'start\n",
    "    lastStart = 0\n",
    "    firstFinish = len(event)-1\n",
    "    \n",
    "    # find last start\n",
    "    for idx in eventIndices:\n",
    "        if 'started' in event[idx[0]]:\n",
    "            if debug:\n",
    "                print(event[idx[0]])\n",
    "                print(idx[0])\n",
    "            lastStart = idx[0]\n",
    "    \n",
    "    # find first finish\n",
    "    for idx in eventIndices:\n",
    "        if 'finish' in event[idx[0]]:\n",
    "            if debug:\n",
    "                print(event[idx[0]])\n",
    "                print(idx[0])\n",
    "\n",
    "            firstFinish = idx[0]\n",
    "            break\n",
    "    \n",
    "    if debug:\n",
    "        print(f'lastStart, firstFinish: {lastStart}, {firstFinish}')\n",
    "    return (lastStart, firstFinish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to check if there are extracted segments for this case. If they are not, they will need to be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areCaseSegmentsCached(caseid):\n",
    "    seg_folder = f\"{VITAL_EXTRACTED_SEGMENTS}/{caseid:04d}\"\n",
    "    return os.path.exists(seg_folder) and len(os.listdir(seg_folder)) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a basic signal quality check function for ABP data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAbpSegmentValidNumpy(samples, debug=False):\n",
    "    valid = True\n",
    "    if np.isnan(samples).mean() > 0.1:\n",
    "        valid = False\n",
    "        if debug:\n",
    "            print(f\">10% NaN\")\n",
    "    elif (samples > 200).any():\n",
    "        valid = False\n",
    "        if debug:\n",
    "            print(f\"Presence of BP > 200\")\n",
    "    elif (samples < 30).any():\n",
    "        valid = False\n",
    "        if debug:\n",
    "            print(f\"Presence of BP < 30\")\n",
    "    elif np.max(samples) - np.min(samples) < 30:\n",
    "        if debug:\n",
    "            print(f\"Max - Min test < 30\")\n",
    "        valid = False\n",
    "    elif (np.abs(np.diff(samples)) > 30).any():  # abrupt change -> noise\n",
    "        if debug:\n",
    "            print(f\"Abrupt change (noise)\")\n",
    "        valid = False\n",
    "    \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the ABP data extracted for a case is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAbpSegmentValid(vf, debug=False):\n",
    "    ABP_ECG_SRATE_HZ = 500\n",
    "    ABP_TRACK_NAME = \"SNUADC/ART\"\n",
    "\n",
    "    samples = np.array(vf.get_track_samples(ABP_TRACK_NAME, 1/ABP_ECG_SRATE_HZ))\n",
    "    return isAbpSegmentValidNumpy(samples, debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save extracted segments to disk. Use an `.h5` format for efficient packing and playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCaseSegments(caseid, positiveSegments, negativeSegments, compresslevel=9, debug=False, forceWrite=False):\n",
    "    if len(positiveSegments) == 0 and len(negativeSegments) == 0:\n",
    "        # exit early if no events found\n",
    "        print(f'{caseid}: exit early, no segments to save')\n",
    "        return\n",
    "\n",
    "    # event composition\n",
    "    # predictiveSegmentStart in seconds, predictiveSegmentEnd in seconds, predWindow (0 for negative), abp, ecg, eeg)\n",
    "    # 0start, 1end, 2predwindow, 3abp, 4ecg, 5eeg\n",
    "\n",
    "    seg_folder = f\"{VITAL_EXTRACTED_SEGMENTS}/{caseid:04d}\"\n",
    "    if not os.path.exists(seg_folder):\n",
    "        # if directory needs to be created, then there are no cached segments\n",
    "        os.mkdir(seg_folder)\n",
    "    else:\n",
    "        if not forceWrite:\n",
    "            # exit early if folder already exists, case already produced\n",
    "            return\n",
    "\n",
    "    # prior to writing files out, clear existing files\n",
    "    for filename in os.listdir(seg_folder):\n",
    "        file_path = os.path.join(seg_folder, filename)\n",
    "        if debug:\n",
    "            print(f'deleting: {file_path}')\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    \n",
    "    count_pos_saved = 0\n",
    "    for i in range(0, len(positiveSegments)):\n",
    "        event = positiveSegments[i]\n",
    "        startIndex = event[0]\n",
    "        endIndex = event[1]\n",
    "        predWindow = event[2]\n",
    "        abp = event[3]\n",
    "        #ecg = event[4]\n",
    "        #eeg = event[5]\n",
    "\n",
    "        seg_filename = f\"{caseid:04d}_{startIndex}_{predWindow:02d}_True.h5\"\n",
    "        seg_fullpath = f\"{seg_folder}/{seg_filename}\"\n",
    "        if isAbpSegmentValidNumpy(abp, debug):\n",
    "            count_pos_saved += 1\n",
    "\n",
    "            abp = abp.tolist()\n",
    "            ecg = event[4].tolist()\n",
    "            eeg = event[5].tolist()\n",
    "        \n",
    "            f = h5py.File(seg_fullpath, \"w\")\n",
    "            f.create_dataset('abp', data=abp, compression=\"gzip\", compression_opts=compresslevel)\n",
    "            f.create_dataset('ecg', data=ecg, compression=\"gzip\", compression_opts=compresslevel)\n",
    "            f.create_dataset('eeg', data=eeg, compression=\"gzip\", compression_opts=compresslevel)\n",
    "            \n",
    "            f.flush()\n",
    "            f.close()\n",
    "            f = None\n",
    "\n",
    "            abp = None\n",
    "            ecg = None\n",
    "            eeg = None\n",
    "\n",
    "            # f.create_dataset('label', data=[1], compression=\"gzip\", compression_opts=compresslevel)\n",
    "            # f.create_dataset('pred_window', data=[event[2]], compression=\"gzip\", compression_opts=compresslevel)\n",
    "            # f.create_dataset('caseid', data=[caseid], compression=\"gzip\", compression_opts=compresslevel)\n",
    "        elif debug:\n",
    "            print(f\"{caseid:04d} {predWindow:02d}min {startIndex} starttime = ignored, segment validity issues\")\n",
    "\n",
    "    count_neg_saved = 0\n",
    "    for i in range(0, len(negativeSegments)):\n",
    "        event = negativeSegments[i]\n",
    "        startIndex = event[0]\n",
    "        endIndex = event[1]\n",
    "        predWindow = event[2]\n",
    "        abp = event[3]\n",
    "        #ecg = event[4]\n",
    "        #eeg = event[5]\n",
    "\n",
    "        seg_filename = f\"{caseid:04d}_{startIndex}_0_False.h5\"\n",
    "        seg_fullpath = f\"{seg_folder}/{seg_filename}\"\n",
    "        if isAbpSegmentValidNumpy(abp, debug):\n",
    "            count_neg_saved += 1\n",
    "\n",
    "            abp = abp.tolist()\n",
    "            ecg = event[4].tolist()\n",
    "            eeg = event[5].tolist()\n",
    "            \n",
    "            f = h5py.File(seg_fullpath, \"w\")\n",
    "            f.create_dataset('abp', data=abp, compression=\"gzip\", compression_opts=compresslevel)\n",
    "            f.create_dataset('ecg', data=ecg, compression=\"gzip\", compression_opts=compresslevel)\n",
    "            f.create_dataset('eeg', data=eeg, compression=\"gzip\", compression_opts=compresslevel)\n",
    "            \n",
    "            f.flush()\n",
    "            f.close()\n",
    "            f = None\n",
    "\n",
    "            abp = None\n",
    "            ecg = None\n",
    "            eeg = None\n",
    "\n",
    "            # f.create_dataset('label', data=[0], compression=\"gzip\", compression_opts=compresslevel)\n",
    "            # f.create_dataset('pred_window', data=[0], compression=\"gzip\", compression_opts=compresslevel)\n",
    "            # f.create_dataset('caseid', data=[caseid], compression=\"gzip\", compression_opts=compresslevel)\n",
    "        elif debug:\n",
    "            print(f\"{caseid:04d} CleanWindow {startIndex} starttime = ignored, segment validity issues\")\n",
    "            \n",
    "    if count_neg_saved == 0 and count_pos_saved == 0:\n",
    "        print(f'{caseid}: nothing saved, all segments filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method is adapted from the preprocessing block of reference [6] (https://github.com/vitaldb/examples/blob/master/hypotension_art.ipynb)\n",
    "\n",
    "The approach first finds an interoperative hypotensive event in the ABP waveform. It then backtracks to earlier in the waveform to extract a 60 second segment representing the waveform feature to use as model input. The figure below shows an example of this approach and is reproduced from the VitalDB example notebook referenced above.\n",
    "\n",
    "![Feature segment extraction](<https://github.com/abarrie2/cs598-dlh-project/blob/main/img/segment_extraction.png?raw=true>)\n",
    "\n",
    "**Generate hypotensive events**\n",
    "\n",
    "Hypotensive events are defined as a 1-minute interval with sustained ABP of less than 65 mmHg\n",
    "**Note:** Hypotensive events should be at least 20 minutes apart to minimize potential residual effects from previous events\n",
    "\n",
    "**Generate hypotension non-events**\n",
    "\n",
    "To sample non-events, 30-minute segments where the ABP was above 75 mmHG were selected, and then three one-minute samples of each waveform were obtained from the middle of the segment both occur in extract_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(\n",
    "    cases_of_interest_idx,\n",
    "    debug=False,\n",
    "    checkCache=True,\n",
    "    forceWrite=False,\n",
    "    returnSegments=False,\n",
    "    skipInvalidCleanEvents=False,\n",
    "    skipInvalidIohEvents=False,\n",
    "):\n",
    "    # Sampling rate for ABP and ECG, Hz. These rates should be the same. Default = 500\n",
    "    ABP_ECG_SRATE_HZ = 500\n",
    "\n",
    "    # Sampling rate for EEG. Default = 128\n",
    "    EEG_SRATE_HZ = 128\n",
    "\n",
    "    # Final dataset for training and testing the model.\n",
    "    positiveSegmentsMap = {}\n",
    "    negativeSegmentsMap = {}\n",
    "    iohEventsMap = {}\n",
    "    cleanEventsMap = {}\n",
    "\n",
    "    # Process each case and extract segments. For each segment identify presence of an event in the label zone.\n",
    "    count_cases = len(cases_of_interest_idx)\n",
    "\n",
    "    #for case_count, caseid in tqdm(enumerate(cases_of_interest_idx), total=count_cases):\n",
    "    for case_count, caseid in enumerate(cases_of_interest_idx):\n",
    "        if debug:\n",
    "            print(f'Loading case: {caseid:04d}, ({case_count + 1} of {count_cases})')\n",
    "\n",
    "        if checkCache and areCaseSegmentsCached(caseid):\n",
    "            if debug:\n",
    "                print(f'Skipping case: {caseid:04d}, already cached')\n",
    "            # skip records we've already cached\n",
    "            continue\n",
    "\n",
    "        # read the arterial waveform\n",
    "        (abp, ecg, eeg, event) = get_track_data(caseid)\n",
    "        if debug:\n",
    "            print(f'Length of {TRACK_NAMES[0]}:       {abp.shape[0]}')\n",
    "            print(f'Length of {TRACK_NAMES[1]}:    {ecg.shape[0]}')\n",
    "            print(f'Length of {TRACK_NAMES[2]}:     {eeg.shape[0]}')\n",
    "\n",
    "        (startInSeconds, endInSeconds) = getSurgeryBoundariesInSeconds(event)\n",
    "        if debug:\n",
    "            print(f\"Event markers indicate that surgery begins at {startInSeconds}s and ends at {endInSeconds}s.\")\n",
    "\n",
    "        #track_length_seconds = int(len(abp) / ABP_ECG_SRATE_HZ)\n",
    "        track_length_seconds = endInSeconds\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Processing case {caseid} with length {track_length_seconds}s\")\n",
    "\n",
    "        \n",
    "        # check if the ABP segment in the surgery window is valid\n",
    "        if debug:\n",
    "            isSurgerySegmentValid = \\\n",
    "                isAbpSegmentValidNumpy(abp[startInSeconds * ABP_ECG_SRATE_HZ:endInSeconds * ABP_ECG_SRATE_HZ])\n",
    "            print(f'{caseid}: surgery segment valid: {isSurgerySegmentValid}')\n",
    "        \n",
    "        iohEvents = []\n",
    "        cleanEvents = []\n",
    "        i = 0\n",
    "        started = False\n",
    "        eofReached = False\n",
    "        trackStartIndex = None\n",
    "\n",
    "        # set i pointer (which operates in seconds) to start marker for surgery\n",
    "        i = startInSeconds\n",
    "\n",
    "        # FIRST PASS\n",
    "        # in the first forward pass, we are going to identify the start/end boundaries of all IOH events within the case\n",
    "        ioh_events_valid = []\n",
    "        \n",
    "        while i < track_length_seconds - 60 and i < endInSeconds:\n",
    "            segmentStart = None\n",
    "            segmentEnd = None\n",
    "            segFound = False\n",
    "\n",
    "            # look forward one minute\n",
    "            abpSeg = abp[i * ABP_ECG_SRATE_HZ:(i + 60) * ABP_ECG_SRATE_HZ]\n",
    "\n",
    "            # roll forward until we hit a one minute window where mean ABP >= 65 so we know leads are connected and it's tracking\n",
    "            if not started:\n",
    "                if np.nanmean(abpSeg) >= 65:\n",
    "                    started = True\n",
    "                    trackStartIndex = i\n",
    "            # if we're started and mean abp for the window is <65, we are starting a new IOH event\n",
    "            elif np.nanmean(abpSeg) < 65:\n",
    "                segmentStart = i\n",
    "                # now seek forward to find end of event, perpetually checking the lats minute of the IOH event\n",
    "                for j in range(i + 60, track_length_seconds):\n",
    "                    # look backward one minute\n",
    "                    abpSegForward = abp[(j - 60) * ABP_ECG_SRATE_HZ:j * ABP_ECG_SRATE_HZ]\n",
    "                    if np.nanmean(abpSegForward) >= 65:\n",
    "                        segmentEnd = j - 1\n",
    "                        break\n",
    "                if segmentEnd is None:\n",
    "                    eofReached = True\n",
    "                else:\n",
    "                    # otherwise, end of the IOH segment has been reached, record it\n",
    "                    iohEvents.append((segmentStart, segmentEnd))\n",
    "                    segFound = True\n",
    "                    \n",
    "                    if skipInvalidIohEvents:\n",
    "                        isIohSegmentValid = isAbpSegmentValidNumpy(abpSeg)\n",
    "                        ioh_events_valid.append(isIohSegmentValid)\n",
    "                        if debug:\n",
    "                            print(f'{caseid}: ioh segment valid: {isIohSegmentValid}, {segmentStart}, {segmentEnd}, {t_abp.shape}')\n",
    "                    else:\n",
    "                        ioh_events_valid.append(True)\n",
    "\n",
    "            i += 1\n",
    "            if not started:\n",
    "                continue\n",
    "            elif eofReached:\n",
    "                break\n",
    "            elif segFound:\n",
    "                i = segmentEnd + 1\n",
    "\n",
    "        # SECOND PASS\n",
    "        # in the second forward pass, we are going to identify the start/end boundaries of all non-overlapping 30 minute \"clean\" windows\n",
    "        # reuse the 'start of signal' index from our first pass\n",
    "        if trackStartIndex is None:\n",
    "            trackStartIndex = startInSeconds\n",
    "        i = trackStartIndex\n",
    "        eofReached = False\n",
    "\n",
    "        clean_events_valid = []\n",
    "        \n",
    "        while i < track_length_seconds - 1800 and i < endInSeconds:\n",
    "            segmentStart = None\n",
    "            segmentEnd = None\n",
    "            segFound = False\n",
    "\n",
    "            startIndex = i\n",
    "            endIndex = i + 1800\n",
    "\n",
    "            # check to see if this 30 minute window overlaps any IOH events, if so ffwd to end of latest overlapping IOH\n",
    "            overlapFound = False\n",
    "            latestEnd = None\n",
    "            for event in iohEvents:\n",
    "                # case 1: starts during an event\n",
    "                if startIndex >= event[0] and startIndex < event[1]:\n",
    "                    latestEnd = event[1]\n",
    "                    overlapFound = True\n",
    "                # case 2: ends during an event\n",
    "                elif endIndex >= event[0] and endIndex < event[1]:\n",
    "                    latestEnd = event[1]\n",
    "                    overlapFound = True\n",
    "                # case 3: event occurs entirely inside of the window\n",
    "                elif startIndex < event[0] and endIndex > event[1]:\n",
    "                    latestEnd = event[1]\n",
    "                    overlapFound = True\n",
    "\n",
    "            # FFWD if we found an overlap\n",
    "            if overlapFound:\n",
    "                i = latestEnd + 1\n",
    "                continue\n",
    "\n",
    "            # look forward 30 minutes\n",
    "            abpSeg = abp[startIndex * ABP_ECG_SRATE_HZ:endIndex * ABP_ECG_SRATE_HZ]\n",
    "\n",
    "            # if we're started and mean abp for the window is >= 75, we are starting a new clean event\n",
    "            if np.nanmean(abpSeg) >= 75:\n",
    "                overlapFound = False\n",
    "                latestEnd = None\n",
    "                for event in iohEvents:\n",
    "                    # case 1: starts during an event\n",
    "                    if startIndex >= event[0] and startIndex < event[1]:\n",
    "                        latestEnd = event[1]\n",
    "                        overlapFound = True\n",
    "                    # case 2: ends during an event\n",
    "                    elif endIndex >= event[0] and endIndex < event[1]:\n",
    "                        latestEnd = event[1]\n",
    "                        overlapFound = True\n",
    "                    # case 3: event occurs entirely inside of the window\n",
    "                    elif startIndex < event[0] and endIndex > event[1]:\n",
    "                        latestEnd = event[1]\n",
    "                        overlapFound = True\n",
    "\n",
    "                if not overlapFound:\n",
    "                    segFound = True\n",
    "                    segmentEnd = endIndex\n",
    "                    cleanEvents.append((startIndex, endIndex))\n",
    "                    \n",
    "                    if skipInvalidCleanEvents:\n",
    "                        isCleanSegmentValid = isAbpSegmentValidNumpy(abpSeg)\n",
    "                        clean_events_valid.append(isCleanSegmentValid)\n",
    "                        if debug:\n",
    "                            print(f'{caseid}: clean segment valid: {isCleanSegmentValid}, {startIndex}, {endIndex}, {abpSeg.shape}')\n",
    "                    else:\n",
    "                        clean_events_valid.append(True)\n",
    "\n",
    "            i += 10\n",
    "            if segFound:\n",
    "                i = segmentEnd + 1\n",
    "\n",
    "        if debug:\n",
    "            print(f\"IOH Events for case {caseid}: {iohEvents}\")\n",
    "            print(f\"Clean Events for case {caseid}: {cleanEvents}\")\n",
    "\n",
    "        positiveSegments = []\n",
    "        negativeSegments = []\n",
    "\n",
    "        # THIRD PASS\n",
    "        # in the third pass, we will use the collections of ioh event windows to generate our actual extracted segments based on our prediction window (positive labels)\n",
    "        for i in range(0, len(iohEvents)):\n",
    "            # Don't extract segments from invalid IOH event windows.\n",
    "            if not ioh_events_valid[i]:\n",
    "                continue\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Checking event {iohEvents[i]}\")\n",
    "            # we want to review current event boundaries, as well as previous event boundaries if available\n",
    "            event = iohEvents[i]\n",
    "            previousEvent = None\n",
    "            if i > 0:\n",
    "                previousEvent = iohEvents[i - 1]\n",
    "\n",
    "            for predWindow in ALL_PREDICTION_WINDOWS:\n",
    "                if debug:\n",
    "                    print(f\"Checking event {iohEvents[i]} for pred {predWindow}\")\n",
    "                iohEventStart = event[0]\n",
    "                predictiveSegmentEnd = event[0] - (predWindow*60)\n",
    "                predictiveSegmentStart = predictiveSegmentEnd - 60\n",
    "\n",
    "                if (predictiveSegmentStart < 0):\n",
    "                    # don't rewind before the beginning of the track\n",
    "                    if debug:\n",
    "                        print(f\"Checking event {iohEvents[i]} for pred {predWindow} - exit, before beginning\")\n",
    "                    continue\n",
    "                elif (predictiveSegmentStart < trackStartIndex):\n",
    "                    # don't rewind before the beginning of signal in track\n",
    "                    if debug:\n",
    "                        print(f\"Checking event {iohEvents[i]} for pred {predWindow} - exit, before track start\")\n",
    "                    continue\n",
    "                elif previousEvent is not None:\n",
    "                    # does this event window come before or during the previous event?\n",
    "                    overlapFound = False\n",
    "                    # case 1: starts during an event\n",
    "                    if predictiveSegmentStart >= previousEvent[0] and predictiveSegmentStart < previousEvent[1]:\n",
    "                        overlapFound = True\n",
    "                    # case 2: ends during an event\n",
    "                    elif iohEventStart >= previousEvent[0] and iohEventStart < previousEvent[1]:\n",
    "                        overlapFound = True\n",
    "                    # case 3: event occurs entirely inside of the window\n",
    "                    elif predictiveSegmentStart < previousEvent[0] and iohEventStart > previousEvent[1]:\n",
    "                        overlapFound = True\n",
    "                    # do not extract a case if we overlap witha nother IOH\n",
    "                    if overlapFound:\n",
    "                        if debug:\n",
    "                            print(f\"Checking event {iohEvents[i]} for pred {predWindow} - exit, overlap with earlier segment\")\n",
    "                        continue\n",
    "\n",
    "                # track the positive segment\n",
    "                positiveSegments.append((predictiveSegmentStart, predictiveSegmentEnd, predWindow,\n",
    "                    abp[predictiveSegmentStart*ABP_ECG_SRATE_HZ:predictiveSegmentEnd*ABP_ECG_SRATE_HZ],\n",
    "                    ecg[predictiveSegmentStart*ABP_ECG_SRATE_HZ:predictiveSegmentEnd*ABP_ECG_SRATE_HZ],\n",
    "                    eeg[predictiveSegmentStart*EEG_SRATE_HZ:predictiveSegmentEnd*EEG_SRATE_HZ]))\n",
    "\n",
    "        # FOURTH PASS\n",
    "        # in the fourth and final pass, we will use the collections of clean event windows to generate our actual extracted segments based (negative labels)\n",
    "        for i in range(0, len(cleanEvents)):\n",
    "            # Don't extract segments from invalid clean event windows.\n",
    "            if not clean_events_valid[i]:\n",
    "                continue\n",
    "            \n",
    "            # everything will be 30 minutes long at least\n",
    "            event = cleanEvents[i]\n",
    "            # choose sample 1 @ 10 minutes\n",
    "            # choose sample 2 @ 15 minutes\n",
    "            # choose sample 3 @ 20 minutes\n",
    "            timeAtTen = event[0] + 600\n",
    "            timeAtFifteen = event[0] + 900\n",
    "            timeAtTwenty = event[0] + 1200\n",
    "\n",
    "            negativeSegments.append((timeAtTen, timeAtTen + 60, 0,\n",
    "                                   abp[timeAtTen*ABP_ECG_SRATE_HZ:(timeAtTen + 60)*ABP_ECG_SRATE_HZ],\n",
    "                                   ecg[timeAtTen*ABP_ECG_SRATE_HZ:(timeAtTen + 60)*ABP_ECG_SRATE_HZ],\n",
    "                                   eeg[timeAtTen*EEG_SRATE_HZ:(timeAtTen + 60)*EEG_SRATE_HZ]))\n",
    "            negativeSegments.append((timeAtFifteen, timeAtFifteen + 60, 0,\n",
    "                                   abp[timeAtFifteen*ABP_ECG_SRATE_HZ:(timeAtFifteen + 60)*ABP_ECG_SRATE_HZ],\n",
    "                                   ecg[timeAtFifteen*ABP_ECG_SRATE_HZ:(timeAtFifteen + 60)*ABP_ECG_SRATE_HZ],\n",
    "                                   eeg[timeAtFifteen*EEG_SRATE_HZ:(timeAtFifteen + 60)*EEG_SRATE_HZ]))\n",
    "            negativeSegments.append((timeAtTwenty, timeAtTwenty + 60, 0,\n",
    "                                   abp[timeAtTwenty*ABP_ECG_SRATE_HZ:(timeAtTwenty + 60)*ABP_ECG_SRATE_HZ],\n",
    "                                   ecg[timeAtTwenty*ABP_ECG_SRATE_HZ:(timeAtTwenty + 60)*ABP_ECG_SRATE_HZ],\n",
    "                                   eeg[timeAtTwenty*EEG_SRATE_HZ:(timeAtTwenty + 60)*EEG_SRATE_HZ]))\n",
    "\n",
    "        if returnSegments:\n",
    "            positiveSegmentsMap[caseid] = positiveSegments\n",
    "            negativeSegmentsMap[caseid] = negativeSegments\n",
    "            iohEventsMap[caseid] = iohEvents\n",
    "            cleanEventsMap[caseid] = cleanEvents\n",
    "        \n",
    "        saveCaseSegments(caseid, positiveSegments, negativeSegments, 9, debug=debug, forceWrite=forceWrite)\n",
    "\n",
    "        #if debug:\n",
    "        print(f'{caseid}: positiveSegments: {len(positiveSegments)}, negativeSegments: {len(negativeSegments)}')\n",
    "\n",
    "    return positiveSegmentsMap, negativeSegmentsMap, iohEventsMap, cleanEventsMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Extraction - Generage Segments Needed For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that all needed segments are in place for the cases that are being used. If data is already stored on disk this method returns immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_EXTRACT=True\n",
    "SKIP_INVALID_CLEAN_EVENTS=True\n",
    "SKIP_INVALID_IOH_EVENTS=True\n",
    "\n",
    "if MANUAL_EXTRACT:\n",
    "    mycoi = cases_of_interest_idx\n",
    "    #mycoi = cases_of_interest_idx[:2800]\n",
    "    #mycoi = [1]\n",
    "\n",
    "    cnt = 0\n",
    "    mod = 0\n",
    "    for ci in mycoi:\n",
    "        cnt += 1\n",
    "        if mod % 100 == 0:\n",
    "            print(f'count processed: {mod}, current case index: {ci}')\n",
    "        try:\n",
    "            p, n, i, c = extract_segments([ci], debug=False, checkCache=True, \n",
    "                                          forceWrite=True, returnSegments=False, \n",
    "                                          skipInvalidCleanEvents=SKIP_INVALID_CLEAN_EVENTS,\n",
    "                                          skipInvalidIohEvents=SKIP_INVALID_IOH_EVENTS)\n",
    "            p = None\n",
    "            n = None\n",
    "            i = None\n",
    "            c = None\n",
    "        except:\n",
    "            print(f'error on extract segment: {ci}')\n",
    "        mod += 1\n",
    "    print(f'extracted: {cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track and Segment Validity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAbp(case_id_to_check, plot_invalid_only=False):\n",
    "        vf_path = f'{VITAL_MINI}/{case_id_to_check:04d}_mini.vital'\n",
    "        \n",
    "        if not os.path.isfile(vf_path):\n",
    "              return\n",
    "        \n",
    "        vf = vitaldb.VitalFile(vf_path)\n",
    "        abp = vf.to_numpy(TRACK_NAMES[0], 1/500)\n",
    "        \n",
    "        print(f'Case {case_id_to_check}')\n",
    "        print(f'ABP Shape: {abp.shape}')\n",
    "\n",
    "        print(f'nanmin: {np.nanmin(abp)}')\n",
    "        print(f'nanmean: {np.nanmean(abp)}')\n",
    "        print(f'nanmax: {np.nanmax(abp)}')\n",
    "        \n",
    "        is_valid = isAbpSegmentValidNumpy(abp, debug=True)\n",
    "        print(f'valid: {is_valid}')\n",
    "\n",
    "        if plot_invalid_only and is_valid:\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt_color = 'C0' if is_valid else 'red'\n",
    "        plt.plot(abp, plt_color)\n",
    "        plt.title(f'ABP - Entire Track - Case {case_id_to_check} - {abp.shape[0] / 500} seconds')\n",
    "        plt.axhline(y = 65, color = 'maroon', linestyle = '--')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSegments(segmentsMap, case_id_to_check, print_label, normalize=False):\n",
    "    for (x1, x2, r, abp, ecg, eeg) in segmentsMap[case_id_to_check]:\n",
    "        print(f'{print_label}: Case {case_id_to_check}')\n",
    "        print(f'lookback window: {r} min')\n",
    "        print(f'start time: {x1}')\n",
    "        print(f'end time: {x2}')\n",
    "        print(f'length: {x2 - x1} sec')\n",
    "        \n",
    "        print(f'ABP Shape: {abp.shape}')\n",
    "        print(f'ECG Shape: {ecg.shape}')\n",
    "        print(f'EEG Shape: {eeg.shape}')\n",
    "\n",
    "        print(f'nanmin: {np.nanmin(abp)}')\n",
    "        print(f'nanmean: {np.nanmean(abp)}')\n",
    "        print(f'nanmax: {np.nanmax(abp)}')\n",
    "        \n",
    "        is_valid = isAbpSegmentValidNumpy(abp, debug=True)\n",
    "        print(f'valid: {is_valid}')\n",
    "\n",
    "        # ABP normalization\n",
    "        x_abp = np.copy(abp)\n",
    "        if normalize:\n",
    "            x_abp -= 65\n",
    "            x_abp /= 65\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt_color = 'C0' if is_valid else 'red'\n",
    "        plt.plot(x_abp, plt_color)\n",
    "        plt.title('ABP')\n",
    "        plt.axhline(y = 65, color = 'maroon', linestyle = '--')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(ecg, 'teal')\n",
    "        plt.title('ECG')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(eeg, 'indigo')\n",
    "        plt.title('EEG')\n",
    "        plt.show()\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEvents(abp_raw, eventsMap, case_id_to_check, print_label, normalize=False):\n",
    "    for (x1, x2) in eventsMap[case_id_to_check]:\n",
    "        print(f'{print_label}: Case {case_id_to_check}')\n",
    "        print(f'start time: {x1}')\n",
    "        print(f'end time: {x2}')\n",
    "        print(f'length: {x2 - x1} sec')\n",
    "\n",
    "        abp = abp_raw[x1*500:x2*500]\n",
    "        print(f'ABP Shape: {abp.shape}')\n",
    "\n",
    "        print(f'nanmin: {np.nanmin(abp)}')\n",
    "        print(f'nanmean: {np.nanmean(abp)}')\n",
    "        print(f'nanmax: {np.nanmax(abp)}')\n",
    "        \n",
    "        is_valid = isAbpSegmentValidNumpy(abp, debug=True)\n",
    "        print(f'valid: {is_valid}')\n",
    "\n",
    "        # ABP normalization\n",
    "        x_abp = np.copy(abp)\n",
    "        if normalize:\n",
    "            x_abp -= 65\n",
    "            x_abp /= 65\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt_color = 'C0' if is_valid else 'red'\n",
    "        plt.plot(x_abp, plt_color)\n",
    "        plt.title('ABP')\n",
    "        plt.axhline(y = 65, color = 'maroon', linestyle = '--')\n",
    "        plt.show()\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, seconds=60):\n",
    "    w = seconds * 500\n",
    "    return np.convolve(np.squeeze(x), np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAbpOverlay(\n",
    "    case_id_to_check,\n",
    "    positiveSegmentsMap,\n",
    "    negativeSegmentsMap,\n",
    "    iohEventsMap,\n",
    "    cleanEventsMap,\n",
    "    movingAverage=False\n",
    "):\n",
    "    def overlay_segments(plt, segmentsMap, color, linestyle, positive=False):\n",
    "        for (x1, x2, r, abp, ecg, eeg) in segmentsMap:\n",
    "            sx1 = x1*500\n",
    "            sx2 = x2*500\n",
    "            mycolor = color\n",
    "            if positive:\n",
    "                if r == 3:\n",
    "                    mycolor = 'red'\n",
    "                elif r == 5:\n",
    "                    mycolor = 'crimson'\n",
    "                elif r == 10:\n",
    "                    mycolor = 'tomato'\n",
    "                else:\n",
    "                    mycolor = 'salmon'\n",
    "            plt.axvline(x = sx1, color = mycolor, linestyle = linestyle)\n",
    "            plt.axvline(x = sx2, color = mycolor, linestyle = linestyle)\n",
    "            plt.axvspan(sx1, sx2, facecolor = mycolor, alpha = 0.1)\n",
    "\n",
    "    def overlay_events(plt, abp, eventsMap, opstart, opend, color, linestyle):\n",
    "        for (x1, x2) in eventsMap:\n",
    "            sx1 = x1*500\n",
    "            sx2 = x2*500\n",
    "            # only plot valid events\n",
    "            if isAbpSegmentValidNumpy(abp[sx1:sx2]):\n",
    "                # that are within the operating start and end times\n",
    "                if sx1 >= opstart and sx2 <= opend:\n",
    "                    plt.axvline(x = sx1, color = color, linestyle = linestyle)\n",
    "                    plt.axvline(x = sx2, color = color, linestyle = linestyle)\n",
    "                    plt.axvspan(sx1, sx2, facecolor = color, alpha = 0.1)\n",
    "\n",
    "    vf_path = f'{VITAL_MINI}/{case_id_to_check:04d}_mini.vital'\n",
    "\n",
    "    if not os.path.isfile(vf_path):\n",
    "          return\n",
    "\n",
    "    vf = vitaldb.VitalFile(vf_path)\n",
    "    abp = vf.to_numpy(TRACK_NAMES[0], 1/500)\n",
    "\n",
    "    print(f'Case {case_id_to_check}')\n",
    "    print(f'ABP Shape: {abp.shape}')\n",
    "\n",
    "    print(f'nanmin: {np.nanmin(abp)}')\n",
    "    print(f'nanmean: {np.nanmean(abp)}')\n",
    "    print(f'nanmax: {np.nanmax(abp)}')\n",
    "\n",
    "    #is_valid = isAbpSegmentValidNumpy(abp, debug=True)\n",
    "    #print(f'valid: {is_valid}')\n",
    "\n",
    "    plt.figure(figsize=(24, 8))\n",
    "    plt_color = 'C0' #if is_valid else 'red'\n",
    "    plt.plot(abp, plt_color)\n",
    "    plt.title(f'ABP - Entire Track - Case {case_id_to_check} - {abp.shape[0] / 500} seconds')\n",
    "    plt.axhline(y = 65, color = 'maroon', linestyle = '--')\n",
    "\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html#linestyles\n",
    "    \n",
    "    opstart = cases.loc[case_id_to_check]['opstart'].item() * 500\n",
    "    plt.axvline(x = opstart, color = 'black', linestyle = '--', linewidth=2)\n",
    "    plt.text(opstart - 600000, -200, f'Operation Start', fontsize=15)\n",
    "    \n",
    "    opend = cases.loc[case_id_to_check]['opend'].item() * 500\n",
    "    plt.axvline(x = opend, color = 'black', linestyle = '--', linewidth=2)\n",
    "    plt.text(opend + 50000, -200, r'Operation End', fontsize=15)\n",
    "    \n",
    "    overlay_segments(plt, positiveSegmentsMap[case_id_to_check], 'crimson', (0, (1, 1)), positive=True)\n",
    "    \n",
    "    overlay_segments(plt, negativeSegmentsMap[case_id_to_check], 'teal', (0, (1, 1)))\n",
    "\n",
    "    overlay_events(plt, abp, iohEventsMap[case_id_to_check], opstart, opend, 'brown', '-')\n",
    "    \n",
    "    overlay_events(plt, abp, cleanEventsMap[case_id_to_check], opstart, opend, 'teal', '-')\n",
    "    \n",
    "    abp_mov_avg = None\n",
    "    if movingAverage:\n",
    "        abp_mov_avg = moving_average(abp[opstart:(opend + 60*500)])\n",
    "        myx = np.arange(opstart, opstart + len(abp_mov_avg), 1)\n",
    "        plt.plot(myx, abp_mov_avg, 'red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reality Check All Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global flag to control creating track and segment plots.\n",
    "# These plots are expensive to create, but very interesting.\n",
    "# Disable when training in bulk to speed up notebook processing.\n",
    "PERFORM_TRACK_VALIDITY_CHECKS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all ABPs are well formed. Fast load and scan of the raw track data for ABP.\n",
    "DISPLAY_REALITY_CHECK_ABP=True\n",
    "DISPLAY_REALITY_CHECK_ABP_FIRST_ONLY=True\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS and DISPLAY_REALITY_CHECK_ABP:\n",
    "    for case_id_to_check in cases_of_interest_idx:\n",
    "        printAbp(case_id_to_check, plot_invalid_only=False)\n",
    "        \n",
    "        if DISPLAY_REALITY_CHECK_ABP_FIRST_ONLY:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Malformed Vital Files - Missing One Or More Tracks\n",
    "\n",
    "Cases which were found to be missing one or more data tracks are stored in `malformed_tracks_filter.csv`. These can be analyzed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are Vital Files removed because of malformed ABP waveforms.\n",
    "DISPLAY_MALFORMED_ABP=True\n",
    "DISPLAY_MALFORMED_ABP_FIRST_ONLY=True\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS and DISPLAY_MALFORMED_ABP:\n",
    "    malformed_case_ids = pd.read_csv('malformed_tracks_filter.csv', header=None, names=['caseid']).set_index('caseid').index\n",
    "\n",
    "    for case_id_to_check in malformed_case_ids:\n",
    "        printAbp(case_id_to_check)\n",
    "        \n",
    "        if DISPLAY_MALFORMED_ABP_FIRST_ONLY:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Cases With No Segments Saved\n",
    "\n",
    "Cases which were found to not result in any extracted segments can be analyzed below to better understand why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_NO_SEGMENTS_CASES=True\n",
    "DISPLAY_NO_SEGMENTS_CASES_FIRST_ONLY=True\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS and DISPLAY_NO_SEGMENTS_CASES:\n",
    "    no_segments_case_ids = [3413, 3476, 3533, 3992, 4328, 4648, 4703, 4733, 5130, 5501, 5693, 5908]\n",
    "\n",
    "    for case_id_to_check in no_segments_case_ids:\n",
    "        printAbp(case_id_to_check)\n",
    "        \n",
    "        if DISPLAY_NO_SEGMENTS_CASES_FIRST_ONLY:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Case For Segment Extraction Validation\n",
    "\n",
    "Generate segment data for one or more cases. Perform a deep analysis of event and segment quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is always set so that if this section of checks is skipped, the model prediction plots will match.\n",
    "my_cases_of_interest_idx = [84, 198, 60, 16, 27]\n",
    "\n",
    "# Note: By default, match extract segments processing block above.\n",
    "# However, regenerate data real time to allow seeing impacts on segment extraction.\n",
    "# This is why both checkCache and forceWrite are false by default.\n",
    "positiveSegmentsMap, negativeSegmentsMap, iohEventsMap, cleanEventsMap = None, None, None, None\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    positiveSegmentsMap, negativeSegmentsMap, iohEventsMap, cleanEventsMap = \\\n",
    "        extract_segments(my_cases_of_interest_idx, debug=False,\n",
    "                         checkCache=False, forceWrite=False, returnSegments=True,\n",
    "                         skipInvalidCleanEvents=SKIP_INVALID_CLEAN_EVENTS,\n",
    "                         skipInvalidIohEvents=SKIP_INVALID_IOH_EVENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific case to perform detailed low level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_to_check = my_cases_of_interest_idx[0]\n",
    "print(case_id_to_check)\n",
    "print()\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    print((\n",
    "        len(positiveSegmentsMap[case_id_to_check]),\n",
    "        len(negativeSegmentsMap[case_id_to_check]),\n",
    "        len(iohEventsMap[case_id_to_check]),\n",
    "        len(cleanEventsMap[case_id_to_check])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    printAbp(case_id_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Events for Case - IOH Events\n",
    "Used to define the range in front of which positive segments will be extracted. Positive samples happen in front of this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_abp = None\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    tmp_vf_path = f'{VITAL_MINI}/{case_id_to_check:04d}_mini.vital'\n",
    "    tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "    tmp_abp = tmp_vf.to_numpy(TRACK_NAMES[0], 1/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    printEvents(tmp_abp, iohEventsMap, case_id_to_check, 'IOH Event Segment', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Events for Case - Non-IOH Events\n",
    "Used to define the range from in which negative segments will be extracted. Negative samples happen within this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    printEvents(tmp_abp, cleanEventsMap, case_id_to_check, 'Clean Event Segment', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Segments for Case - IOH Events Predicted Using These\n",
    "One minute regions sampled and used for training the model for \"positive\" events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    printSegments(positiveSegmentsMap, case_id_to_check, 'Positive Segment - IOH Event', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Segments for Case - Non-IOH Events Predicted Using These\n",
    "One minute regions sampled and used for training the model for \"negative\" events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERFORM_TRACK_VALIDITY_CHECKS:\n",
    "    printSegments(negativeSegmentsMap, case_id_to_check, 'Negative Segment - Non-Event', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay Plot of All Events and Segments Extracted\n",
    "For each of the cases in `my_cases_of_interest_idx` overlay the results of event and segment extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_OVERLAY_CHECK_ABP=True\n",
    "DISPLAY_OVERLAY_CHECK_ABP_FIRST_ONLY=True\n",
    "\n",
    "if PERFORM_TRACK_VALIDITY_CHECKS and DISPLAY_OVERLAY_CHECK_ABP:\n",
    "    for case_id_to_check in my_cases_of_interest_idx:\n",
    "        printAbpOverlay(case_id_to_check, positiveSegmentsMap, \n",
    "                        negativeSegmentsMap, iohEventsMap, cleanEventsMap, movingAverage=False)\n",
    "        \n",
    "        if DISPLAY_OVERLAY_CHECK_ABP_FIRST_ONLY:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory cleanup\n",
    "del tmp_abp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When case segments are stored to disk, the filename is intentionally constructed so that its metadata can be easily reconstructed. The format is as follows: `{case}_{startX}_{predWindow}_{label}.h5`, where `{case}` is the case ID, `{startX}` is the start index of the segment, in seconds, from the start of the `.vital` track, `{predWindow}` is the prediction window, which can be 3, 5, 10 or 15 minutes, and `{label}` is the label indicator of whether the segment is associated with a hypotensive event (`label=1`) or not (`label=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_attributes_from_filename(file_path):\n",
    "    pieces = os.path.basename(file_path).split('_')\n",
    "    case = int(pieces[0])\n",
    "    startX = int(pieces[1])\n",
    "    predWindow = int(pieces[2])\n",
    "    label = pieces[3].replace('.h5', '')\n",
    "    return (case, startX, predWindow, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_negative_samples = 0\n",
    "count_positive_samples = 0\n",
    "\n",
    "samples = []\n",
    "\n",
    "seg_folder = f\"{VITAL_EXTRACTED_SEGMENTS}\"\n",
    "filenames = [y for x in os.walk(seg_folder) for y in glob(os.path.join(x[0], '*.h5'))]\n",
    "\n",
    "for filename in filenames:\n",
    "    (case, start_x, pred_window, label) = get_segment_attributes_from_filename(filename)\n",
    "    \n",
    "    # only load cases for cases of interest; this folder could have segments for hundreds of cases\n",
    "    if case not in cases_of_interest_idx:\n",
    "        continue\n",
    "\n",
    "    if pred_window == 0 or pred_window == PREDICTION_WINDOW or PREDICTION_WINDOW == 'ALL':\n",
    "        #print((case, start_x, pred_window, label))\n",
    "        if label == 'True':\n",
    "            count_positive_samples += 1\n",
    "        else:\n",
    "            count_negative_samples += 1\n",
    "        sample = (filename, label)\n",
    "        samples.append(sample)\n",
    "\n",
    "print()\n",
    "print(f\"samples loaded:         {len(samples):5} \")\n",
    "print(f'count negative samples: {count_negative_samples:5}')\n",
    "print(f'count positive samples: {count_positive_samples:5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by cases\n",
    "sample_cases = defaultdict(lambda: []) \n",
    "\n",
    "for fn, _ in samples:\n",
    "    (case, start_x, pred_window, label) = get_segment_attributes_from_filename(fn)\n",
    "    sample_cases[case].append((fn, label))\n",
    "\n",
    "# understand any missing cases of interest\n",
    "sample_cases_idx = pd.Index(sample_cases.keys())\n",
    "missing_case_ids = cases_of_interest_idx.difference(sample_cases_idx)\n",
    "print(f'cases with no samples: {missing_case_ids.shape[0]}')\n",
    "print(f'    {missing_case_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training, validation, and test sets\n",
    "\n",
    "Use 6:1:3 ratio and prevent samples from a single case from being split across different sets\n",
    "\n",
    "**Note:** number of samples at each time point is not the same, because the first event can occur before the 3/5/10/15 minute mark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target sizes\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.1\n",
    "test_ratio = 1 - train_ratio - val_ratio # ensure ratios sum to 1\n",
    "\n",
    "# Split samples into train and other\n",
    "sample_cases_train, sample_cases_other = train_test_split(list(sample_cases.keys()), test_size=(1 - train_ratio), random_state=RANDOM_SEED)\n",
    "\n",
    "# Split other into val and test\n",
    "sample_cases_val, sample_cases_test = train_test_split(sample_cases_other, test_size=(test_ratio / (1 - train_ratio)), random_state=RANDOM_SEED)\n",
    "\n",
    "# Check how many samples are in each set\n",
    "print(f'Train/Val/Test Summary by Cases')\n",
    "print(f\"Train cases:  {len(sample_cases_train):5}, ({len(sample_cases_train) / len(sample_cases):.2%})\")\n",
    "print(f\"Val cases:    {len(sample_cases_val):5}, ({len(sample_cases_val) / len(sample_cases):.2%})\")\n",
    "print(f\"Test cases:   {len(sample_cases_test):5}, ({len(sample_cases_test) / len(sample_cases):.2%})\")\n",
    "print(f\"Total cases:  {(len(sample_cases_train) + len(sample_cases_val) + len(sample_cases_test)):5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the cases have been split according to the desired ratio, assign all of the segments for each case into the target (train, validation, test) set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cases_train = set(sample_cases_train)\n",
    "sample_cases_val = set(sample_cases_val)\n",
    "sample_cases_test = set(sample_cases_test)\n",
    "\n",
    "samples_train = []\n",
    "samples_val = []\n",
    "samples_test = []\n",
    "\n",
    "for cid, segs in sample_cases.items():\n",
    "    if cid in sample_cases_train:\n",
    "        for seg in segs:\n",
    "            samples_train.append(seg)\n",
    "    if cid in sample_cases_val:\n",
    "        for seg in segs:\n",
    "            samples_val.append(seg)\n",
    "    if cid in sample_cases_test:\n",
    "        for seg in segs:\n",
    "            samples_test.append(seg)\n",
    "            \n",
    "# Check how many samples are in each set\n",
    "print(f'Train/Val/Test Summary by Events')\n",
    "print(f\"Train events:  {len(samples_train):5}, ({len(samples_train) / len(samples):.2%})\")\n",
    "print(f\"Val events:    {len(samples_val):5}, ({len(samples_val) / len(samples):.2%})\")\n",
    "print(f\"Test events:   {len(samples_test):5}, ({len(samples_test) / len(samples):.2%})\")\n",
    "print(f\"Total events:  {(len(samples_train) + len(samples_val) + len(samples_test)):5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate train/val/test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the label distribution in each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_ALL_CASE_SPLIT_DETAILS = False\n",
    "\n",
    "case_to_sample_distribution = defaultdict(lambda: {'train': [0, 0], 'val': [0, 0], 'test': [0, 0]})\n",
    "\n",
    "def populate_case_to_sample_distribution(mysamples, idx):\n",
    "    neg = 0\n",
    "    pos = 0\n",
    "    \n",
    "    for fn, _ in mysamples:\n",
    "        (case, start_x, pred_window, label) = get_segment_attributes_from_filename(fn)\n",
    "        slot = 0 if label == 'False' else 1\n",
    "        case_to_sample_distribution[case][idx][slot] += 1\n",
    "        if slot == 0:\n",
    "            neg += 1\n",
    "        else:\n",
    "            pos += 1\n",
    "                \n",
    "    return (neg, pos)\n",
    "\n",
    "train_neg, train_pos = populate_case_to_sample_distribution(samples_train, 'train')\n",
    "val_neg, val_pos     = populate_case_to_sample_distribution(samples_val,   'val')\n",
    "test_neg, test_pos   = populate_case_to_sample_distribution(samples_test,  'test')\n",
    "\n",
    "print(f'Total Cases Present: {len(case_to_sample_distribution):5}')\n",
    "print()\n",
    "\n",
    "train_tot = train_pos + train_neg\n",
    "val_tot = val_pos + val_neg\n",
    "test_tot = test_pos + test_neg\n",
    "print(f'Train: P: {train_pos:5} ({(train_pos/train_tot):.2}), N: {train_neg:5} ({(train_neg/train_tot):.2})')\n",
    "print(f'Val:   P: {val_pos:5} ({(val_pos/val_tot):.2}), N: {val_neg:5} ({(val_neg/val_tot):.2})')\n",
    "print(f'Test:  P: {test_pos:5} ({(test_pos/test_tot):.2}), N: {test_neg:5}  ({(test_neg/test_tot):.2})')\n",
    "print()\n",
    "\n",
    "total_pos = train_pos + val_pos + test_pos\n",
    "total_neg = train_neg + val_neg + test_neg\n",
    "total = total_pos + total_neg\n",
    "print(f'P/N Ratio: {(total_pos)}:{(total_neg)}')\n",
    "print(f'P Percent: {(total_pos/total):.2}')\n",
    "print(f'N Percent: {(total_neg/total):.2}')\n",
    "print()\n",
    "\n",
    "if PRINT_ALL_CASE_SPLIT_DETAILS:\n",
    "    for ci in sorted(case_to_sample_distribution.keys()):\n",
    "        print(f'{ci}: {case_to_sample_distribution[ci]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that no data has leaked between test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_leakage(full_data, train_data, val_data, test_data):\n",
    "    # Convert to sets for easier operations\n",
    "    full_data_set = set(full_data)\n",
    "    train_data_set = set(train_data)\n",
    "    val_data_set = set(val_data)\n",
    "    test_data_set = set(test_data)\n",
    "\n",
    "    # Check if train, val, test are subsets of full_data\n",
    "    if not train_data_set.issubset(full_data_set):\n",
    "        return \"Train data has leakage\"\n",
    "    if not val_data_set.issubset(full_data_set):\n",
    "        return \"Validation data has leakage\"\n",
    "    if not test_data_set.issubset(full_data_set):\n",
    "        return \"Test data has leakage\"\n",
    "\n",
    "    # Check if train, val, test are disjoint\n",
    "    if train_data_set & val_data_set:\n",
    "        return \"Train and validation data are not disjoint\"\n",
    "    if train_data_set & test_data_set:\n",
    "        return \"Train and test data are not disjoint\"\n",
    "    if val_data_set & test_data_set:\n",
    "        return \"Validation and test data are not disjoint\"\n",
    "\n",
    "    return \"No data leakage detected\"\n",
    "\n",
    "print(check_data_leakage(list(sample_cases.keys()), sample_cases_train, sample_cases_val, sample_cases_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom `vitalDataset` class derived from `Dataset` to be used by the data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vitalDataset class\n",
    "class vitalDataset(Dataset):\n",
    "    def __init__(self, samples, normalize_abp=False):\n",
    "        self.samples = samples\n",
    "        self.normalize_abp = normalize_abp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get metadata for this event\n",
    "        segment = self.samples[idx]\n",
    "\n",
    "        file_path = segment[0]\n",
    "        label = (segment[1] == \"True\" or segment[1] == \"True.vital\")\n",
    "\n",
    "        (abp, ecg, eeg) = get_segment_data(file_path)\n",
    "\n",
    "        if abp is None or eeg is None or ecg is None:\n",
    "            return (np.zeros(30000), np.zeros(30000), np.zeros(7680), 0)\n",
    "        \n",
    "        if self.normalize_abp:\n",
    "            abp -= 65\n",
    "            abp /= 65\n",
    "\n",
    "        return abp, ecg, eeg, label\n",
    "\n",
    "NORMALIZE_ABP = False\n",
    "\n",
    "train_dataset = vitalDataset(samples_train, NORMALIZE_ABP)\n",
    "val_dataset = vitalDataset(samples_val, NORMALIZE_ABP)\n",
    "test_dataset = vitalDataset(samples_test, NORMALIZE_ABP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/val/test Splits Summary Statistics\n",
    "\n",
    "Analyze the mean value distribution across each dataset in order to study and verify that their characteristics are in line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nan_means(mydataset):\n",
    "    xs = np.zeros(len(mydataset))\n",
    "    ys = np.zeros(len(mydataset), dtype=int)\n",
    "\n",
    "    for i, (abp, ecg, eeg, y) in enumerate(iter(mydataset)):\n",
    "        xs[i] = np.nanmean(abp)\n",
    "        ys[i] = int(y)\n",
    "\n",
    "    return pd.DataFrame({'abp_nanmean': xs, 'label': ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nan_means_summaries(tr, va, te, group='all'):\n",
    "    if group == 'all':\n",
    "        return pd.DataFrame({\n",
    "            'train': tr.describe()['abp_nanmean'],\n",
    "            'validation': va.describe()['abp_nanmean'],\n",
    "            'test': te.describe()['abp_nanmean']\n",
    "        })\n",
    "    \n",
    "    mytr = tr.reset_index()\n",
    "    myva = va.reset_index()\n",
    "    myte = te.reset_index()\n",
    "    \n",
    "    label_flag = True if group == 'positive' else False\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'train':      mytr[mytr['label'] == label_flag].describe()['abp_nanmean'],\n",
    "        'validation': myva[myva['label'] == label_flag].describe()['abp_nanmean'],\n",
    "        'test':       myte[myte['label'] == label_flag].describe()['abp_nanmean']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nan_means(df, plot_label):\n",
    "    mydf = df.reset_index()\n",
    "\n",
    "    maxCases = 'ALL' if MAX_CASES is None else MAX_CASES\n",
    "    plot_title = f'{plot_label} - ABP nanmean Values, {PREDICTION_WINDOW} Minutes, {maxCases} Cases'\n",
    "    \n",
    "    ax = mydf[mydf['label'] == False].plot.scatter(\n",
    "        x='index', y='abp_nanmean', color='DarkBlue', label='Negative', \n",
    "        title=plot_title, figsize=(16,9))\n",
    "\n",
    "    negative_median = mydf[mydf['label'] == False]['abp_nanmean'].median()\n",
    "    ax.axhline(y=negative_median, color='DarkBlue', linestyle='--', label='Negative Median')\n",
    "    \n",
    "    mydf[mydf['label'] == True].plot.scatter(\n",
    "        x='index', y='abp_nanmean', color='DarkOrange', label='Positive', ax=ax);\n",
    "    \n",
    "    positive_median = mydf[mydf['label'] == True]['abp_nanmean'].median()\n",
    "    ax.axhline(y=positive_median, color='DarkOrange', linestyle='--', label='Positive Median')\n",
    "    \n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nan_means_hist(df):\n",
    "    df.plot.hist(column=['abp_nanmean'], by='label', bins=50, figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abp_nanmeans = generate_nan_means(train_dataset)\n",
    "val_abp_nanmeans = generate_nan_means(val_dataset)\n",
    "test_abp_nanmeans = generate_nan_means(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABP Nanmean Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_nan_means_summaries(train_abp_nanmeans, val_abp_nanmeans, test_abp_nanmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_nan_means_summaries(train_abp_nanmeans, val_abp_nanmeans, test_abp_nanmeans, group='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_nan_means_summaries(train_abp_nanmeans, val_abp_nanmeans, test_abp_nanmeans, group='negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABP Nanmean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nan_means_hist(train_abp_nanmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nan_means_hist(val_abp_nanmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nan_means_hist(test_abp_nanmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABP Nanmean Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nan_means(train_abp_nanmeans, 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nan_means(val_abp_nanmeans, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nan_means(test_abp_nanmeans, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory cleanup\n",
    "del train_abp_nanmeans\n",
    "del val_abp_nanmeans\n",
    "del test_abp_nanmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Studies\n",
    "\n",
    "Check if data can be easily classified using non-deep learning methods. Create a balanced sample of IOH and non-IOH events and use a simple classifier to see if the data can be easily separated. Datasets which can be easily separated by non-deep learning methods should also be easily classified by deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CLASSIFICATION_SAMPLES = 250\n",
    "MAX_SAMPLE_SIZE = 1600\n",
    "classification_sample_size = MAX_SAMPLE_SIZE if len(samples) >= MAX_SAMPLE_SIZE else len(samples)\n",
    "\n",
    "classification_samples = random.sample(samples, classification_sample_size)\n",
    "\n",
    "positive_samples = []\n",
    "negative_samples = []\n",
    "\n",
    "for sample in classification_samples:\n",
    "    (sampleAbp, sampleEcg, sampleEeg) = get_segment_data(sample[0])\n",
    "    \n",
    "    if sample[1] == \"True\":\n",
    "        positive_samples.append([sample[0], True, sampleAbp, sampleEcg, sampleEeg])\n",
    "    else:\n",
    "        negative_samples.append([sample[0], False, sampleAbp, sampleEcg, sampleEeg])\n",
    "\n",
    "positive_samples = pd.DataFrame(positive_samples, columns=[\"file_path\", \"segment_label\", \"segment_abp\", \"segment_ecg\", \"segment_eeg\"])\n",
    "negative_samples = pd.DataFrame(negative_samples, columns=[\"file_path\", \"segment_label\", \"segment_abp\", \"segment_ecg\", \"segment_eeg\"])\n",
    "\n",
    "total_to_sample_pos = MAX_CLASSIFICATION_SAMPLES if len(positive_samples) >= MAX_CLASSIFICATION_SAMPLES else len(positive_samples)\n",
    "total_to_sample_neg = MAX_CLASSIFICATION_SAMPLES if len(negative_samples) >= MAX_CLASSIFICATION_SAMPLES else len(negative_samples)\n",
    "\n",
    "# Select up to 150 random samples where segment_label is True\n",
    "positive_samples = positive_samples.sample(total_to_sample_pos, random_state=RANDOM_SEED)\n",
    "# Select up to 150 random samples where segment_label is False\n",
    "negative_samples = negative_samples.sample(total_to_sample_neg, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f'positive_samples: {len(positive_samples)}')\n",
    "print(f'negative_samples: {len(negative_samples)}')\n",
    "\n",
    "# Combine the positive and negative samples\n",
    "samples_balanced = pd.concat([positive_samples, negative_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to build data for study. Each waveform field can be enabled or disabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(samples, use_abp, use_ecg, use_eeg):\n",
    "    # Create X and y, using data from `samples_balanced` and the `use_abp`, `use_ecg`, and `use_eeg` variables\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(samples)):\n",
    "        row = samples.iloc[i]\n",
    "        sample = np.array([])\n",
    "        if use_abp:\n",
    "            if len(row['segment_abp']) != 30000:\n",
    "                print(len(row['segment_abp']))\n",
    "            sample = np.append(sample, row['segment_abp'])\n",
    "        if use_ecg:\n",
    "            if len(row['segment_ecg']) != 30000:\n",
    "                print(len(row['segment_ecg']))\n",
    "            sample = np.append(sample, row['segment_ecg'])\n",
    "        if use_eeg:\n",
    "            if len(row['segment_eeg']) != 7680:\n",
    "                print(len(row['segment_eeg']))\n",
    "            sample = np.append(sample, row['segment_eeg'])\n",
    "        X.append(sample)\n",
    "        # Convert the label from boolean to 0 or 1\n",
    "        y.append(int(row['segment_label']))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "\n",
    "Define KNN run. This is configurable to enable or disable different data channels so that we can study them individually or together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 20\n",
    "\n",
    "def run_knn(samples, use_abp, use_ecg, use_eeg):\n",
    "    # Get samples\n",
    "    X,y = get_x_y(samples, use_abp, use_ecg, use_eeg)\n",
    "\n",
    "    # Split samples into train and val\n",
    "    knn_X_train, knn_X_test, knn_y_train, knn_y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(knn_X_train)\n",
    "\n",
    "    knn_X_train = scaler.transform(knn_X_train)\n",
    "    knn_X_test = scaler.transform(knn_X_test)\n",
    "\n",
    "    # Initialize the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS)\n",
    "\n",
    "    # Train the KNN classifier\n",
    "    knn.fit(knn_X_train, knn_y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    knn_y_pred = knn.predict(knn_X_test)\n",
    "\n",
    "    # Evaluate the KNN classifier\n",
    "    print(f\"ABP: {use_abp}, ECG: {use_ecg}, EEG: {use_eeg}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(knn_y_test, knn_y_pred)}\")\n",
    "    print(f\"Classification report:\\n{classification_report(knn_y_test, knn_y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study each waveform independently, then ABP+EEG (which had best results in paper), and ABP+ECG+EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_knn(samples_balanced, use_abp=True, use_ecg=False, use_eeg=False)\n",
    "run_knn(samples_balanced, use_abp=False, use_ecg=True, use_eeg=False)\n",
    "run_knn(samples_balanced, use_abp=False, use_ecg=False, use_eeg=True)\n",
    "run_knn(samples_balanced, use_abp=True, use_ecg=False, use_eeg=True)\n",
    "run_knn(samples_balanced, use_abp=True, use_ecg=True, use_eeg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data above, the ABP and ABP+EEG data are somewhat predictive based on the macro average F1-score, the ECG and EEG data are weakly predictive, and ABP+ECG+EEG data somewhat less predictive than either of ABP or ABP+EEG.\n",
    "\n",
    "Models based on ABP data alone, or ABP+EEG data are expected to train well with good performance. The other signals appear to mostly add noise and are not strongly predictive. This agrees with the results from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE\n",
    "\n",
    "Define t-SNE run. This is configurable to enable or disable different data channels so that we can study them individually or together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tsne(samples, use_abp, use_ecg, use_eeg):\n",
    "    # Get samples\n",
    "    X,y = get_x_y(samples, use_abp, use_ecg, use_eeg)\n",
    "    \n",
    "    # Convert X and y to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Run t-SNE on the samples\n",
    "    tsne = TSNE(n_components=len(np.unique(y)), random_state=RANDOM_SEED)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    \n",
    "    # Create a scatter plot of the t-SNE representation\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.title(f\"use_abp={use_abp}, use_ecg={use_ecg}, use_eeg={use_eeg}\")\n",
    "    for i, label in enumerate(set(y)):\n",
    "        plt.scatter(X_tsne[y == label, 0], X_tsne[y == label, 1], label=label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study each waveform independently, then ABP+EEG (which had best results in paper), and ABP+ECG+EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tsne(samples_balanced, use_abp=True, use_ecg=False, use_eeg=False)\n",
    "run_tsne(samples_balanced, use_abp=False, use_ecg=True, use_eeg=False)\n",
    "run_tsne(samples_balanced, use_abp=False, use_ecg=False, use_eeg=True)\n",
    "run_tsne(samples_balanced, use_abp=True, use_ecg=False, use_eeg=True)\n",
    "run_tsne(samples_balanced, use_abp=True, use_ecg=True, use_eeg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plots above, it appears that ABP alone, ABP+EEG and ABP+ECG+EEG are somewhat separable, though with outliers, and should be trainable by our model. The ECG and EEG data are not readily separable from the other data. This agrees with the results from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory cleanup\n",
    "del samples_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Model\n",
    "\n",
    "The model implementation is based on the CNN architecture described in Jo Y-Y et al. (2022). It is designed to handle 1, 2, or 3 biosignal waveforms simultaneously, allowing for flexible model configurations based on different combinations of physiological data:\n",
    " * ABP alone\n",
    " * EEG alone\n",
    " * ECG alone\n",
    " * ABP + EEG\n",
    " * ABP + ECG\n",
    " * EEG + ECG\n",
    " * ABP + EEG + ECG\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The architecture, as depicted in Figure 2 from the original paper, utilizes a ResNet-based approach tailored for time-series data from different physiological signals. The model architecture is adapted to handle varying input signal frequencies, with specific hyperparameters for each signal type, particularly EEG, due to its distinct characteristics compared to ABP and ECG. A diagram of the model architecture is shown below:\n",
    "\n",
    "![Architecture of the hypotension risk prediction model using multiple waveforms](https://journals.plos.org/plosone/article/figure/image?download&size=large&id=10.1371/journal.pone.0272055.g002)\n",
    "\n",
    "Each input signal is processed through a sequence of 12 7-layer residual blocks, followed by a flattening process and a linear transformation to produce a 32-dimensional feature vector per signal type. These vectors are then concatenated (if multiple signals are used) and passed through two additional linear layers to produce a single output vector, representing the IOH index. A threshold is determined experimentally in order to minimize the differene between the sensitivity and specificity and is applied to this index to perform binary classification for predicting IOH events.\n",
    "\n",
    "The hyperparameters for the residual blocks are specified in Supplemental Table 1 from the original paper and vary for different signal type.\n",
    "\n",
    "A forward pass through the model passes through 85 layers before concatenation, followed by two more linear layers and finally a sigmoid activation layer to produce the prediction measure.\n",
    "\n",
    "### Residual Block Definition\n",
    "\n",
    "Each residual block consists of the following seven layers:\n",
    " \n",
    " * Batch normalization\n",
    " * ReLU\n",
    " * Dropout (0.5)\n",
    " * 1D convolution\n",
    " * Batch normalization\n",
    " * ReLU\n",
    " * 1D convolution\n",
    "\n",
    "Skip connections are included to aid in gradient flow during training, with optional 1D convolution in the skip connection to align dimensions.\n",
    "\n",
    "#### Residual Block Hyperparameters\n",
    "\n",
    "The hyperparameters are detailed in Supplemental Table 1 of the original paper. A screenshot of these hyperparameters is provided for reference below:\n",
    "\n",
    "![Supplemental Table 1 from original paper](<https://github.com/abarrie2/cs598-dlh-project/blob/main/img/table_1_hyperparameters.png?raw=true>)\n",
    "\n",
    "**Note**: Please be aware of a transcription error in the original paper's Supplemental Table 1 for the ECG+ABP configuration in Residual Blocks 11 and 12, where the output size should be 469 * 6 instead of the reported 496 * 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBdVZoTvsSFV"
   },
   "outputs": [],
   "source": [
    "# Define the residual block which is implemented for each biosignal path\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, size_down: bool = False, ignoreSkipConnection: bool = False) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.ignoreSkipConnection = ignoreSkipConnection\n",
    "\n",
    "        # calculate the appropriate padding required to ensure expected sequence lengths out of each residual block\n",
    "        padding = int((((stride-1)*in_features)-stride+kernel_size)/2)\n",
    "\n",
    "        self.size_down = size_down\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "        \n",
    "        self.residualConv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "\n",
    "        # unclear where in sequence this should take place. Size down expressed in Supplemental table S1\n",
    "        if self.size_down:\n",
    "            pool_padding = (1 if (in_features % 2 > 0) else 0)\n",
    "            self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding = pool_padding)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        if self.size_down:\n",
    "            out = self.downsample(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if not self.ignoreSkipConnection:\n",
    "          if out.shape != identity.shape:\n",
    "              # run the residual through a convolution when necessary\n",
    "              identity = self.residualConv(identity)\n",
    "\n",
    "              outlen = np.prod(out.shape)\n",
    "              idlen = np.prod(identity.shape)\n",
    "              # downsample when required\n",
    "              if idlen > outlen:\n",
    "                  identity = self.downsample(identity)\n",
    "              # match dimensions\n",
    "              identity = identity.reshape(out.shape)\n",
    "\n",
    "          # add the residual       \n",
    "          out += identity\n",
    "\n",
    "        return  out\n",
    "\n",
    "# Define the parameterizable model\n",
    "class HypotensionCNN(nn.Module):\n",
    "    def __init__(self, useAbp: bool = True, useEeg: bool = False, useEcg: bool = False, device: str = \"cpu\", nResiduals: int = 12, ignoreSkipConnection: bool = False, useSigmoid: bool = True) -> None:\n",
    "        assert useAbp or useEeg or useEcg, \"At least one data track must be used\"\n",
    "        assert nResiduals > 0 and nResiduals <= 12, \"Number of residual blocks must be between 1 and 12\"\n",
    "        super(HypotensionCNN, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.useAbp = useAbp\n",
    "        self.useEeg = useEeg\n",
    "        self.useEcg = useEcg\n",
    "        self.nResiduals = nResiduals\n",
    "        self.useSigmoid = useSigmoid\n",
    "\n",
    "        # Size of the concatenated output from the residual blocks\n",
    "        concatSize = 0\n",
    "\n",
    "        if useAbp:\n",
    "          self.abpBlocks = []\n",
    "          self.abpMultipliers = [1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 6, 6]\n",
    "          self.abpSizes = [30000, 15000, 15000, 7500, 7500, 3750, 3750, 1875, 1875, 938, 938, 469, 469]\n",
    "          for i in range(self.nResiduals):\n",
    "            downsample = i % 2 == 0\n",
    "            self.abpBlocks.append(ResidualBlock(self.abpSizes[i], self.abpSizes[i+1], self.abpMultipliers[i], self.abpMultipliers[i+1], 15 if i < 6 else 7, 1, downsample, ignoreSkipConnection))\n",
    "          self.abpResiduals = nn.Sequential(*self.abpBlocks)\n",
    "          self.abpFc = nn.Linear(self.abpMultipliers[self.nResiduals] * self.abpSizes[self.nResiduals], 32)\n",
    "          concatSize += 32\n",
    "        \n",
    "        if useEcg:\n",
    "          self.ecgBlocks = []\n",
    "          self.ecgMultipliers = [1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 6, 6]\n",
    "          self.ecgSizes = [30000, 15000, 15000, 7500, 7500, 3750, 3750, 1875, 1875, 938, 938, 469, 469]\n",
    "\n",
    "          for i in range(self.nResiduals):\n",
    "            downsample = i % 2 == 0\n",
    "            self.ecgBlocks.append(ResidualBlock(self.ecgSizes[i], self.ecgSizes[i+1], self.ecgMultipliers[i], self.ecgMultipliers[i+1], 15 if i < 6 else 7, 1, downsample, ignoreSkipConnection))\n",
    "          self.ecgResiduals = nn.Sequential(*self.ecgBlocks)\n",
    "          self.ecgFc = nn.Linear(self.ecgMultipliers[self.nResiduals] * self.ecgSizes[self.nResiduals], 32)\n",
    "          concatSize += 32\n",
    "\n",
    "        if useEeg:\n",
    "          self.eegBlocks = []\n",
    "          self.eegMultipliers = [1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 6, 6]\n",
    "          self.eegSizes = [7680, 3840, 3840, 1920, 1920, 960, 960, 480, 480, 240, 240, 120, 120]\n",
    "\n",
    "          for i in range(self.nResiduals):\n",
    "            downsample = i % 2 == 0\n",
    "            self.eegBlocks.append(ResidualBlock(self.eegSizes[i], self.eegSizes[i+1], self.eegMultipliers[i], self.eegMultipliers[i+1], 7 if i < 6 else 3, 1, downsample, ignoreSkipConnection))\n",
    "          self.eegResiduals = nn.Sequential(*self.eegBlocks)\n",
    "          self.eegFc = nn.Linear(self.eegMultipliers[self.nResiduals] * self.eegSizes[self.nResiduals], 32)\n",
    "          concatSize += 32\n",
    "\n",
    "        # The fullLinear1 layer accepts the outputs of the concatenation of the ResidualBlocks from each biosignal path\n",
    "        self.fullLinear1 = nn.Linear(concatSize, 16)\n",
    "        self.fullLinear2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, abp: torch.Tensor, eeg: torch.Tensor, ecg: torch.Tensor) -> torch.Tensor:\n",
    "        batchSize = len(abp)\n",
    "\n",
    "        # conditionally operate ABP, EEG, and ECG networks\n",
    "        tensors = []\n",
    "        if self.useAbp:\n",
    "          self.abpResiduals.to(self.device)\n",
    "          abp = self.abpResiduals(abp)\n",
    "          totalLen = np.prod(abp.shape)\n",
    "          abp = torch.reshape(abp, (batchSize, int(totalLen / batchSize)))\n",
    "          abp = self.abpFc(abp)\n",
    "          tensors.append(abp)\n",
    "\n",
    "        if self.useEeg:\n",
    "          self.eegResiduals.to(self.device)\n",
    "          eeg = self.eegResiduals(eeg)\n",
    "          totalLen = np.prod(eeg.shape)\n",
    "          eeg = torch.reshape(eeg, (batchSize, int(totalLen / batchSize)))\n",
    "          eeg = self.eegFc(eeg)\n",
    "          tensors.append(eeg)\n",
    "        \n",
    "        if self.useEcg:\n",
    "          self.ecgResiduals.to(self.device)\n",
    "          ecg = self.ecgResiduals(ecg)\n",
    "          totalLen = np.prod(ecg.shape)\n",
    "          ecg = torch.reshape(ecg, (batchSize, int(totalLen / batchSize)))\n",
    "          ecg = self.ecgFc(ecg)\n",
    "          tensors.append(ecg)\n",
    "\n",
    "        # concatenate the tensors along dimension 1 if there's more than one, otherwise use the single tensor\n",
    "        merged = torch.cat(tensors, dim=1) if len(tensors) > 1 else tensors[0]\n",
    "\n",
    "        totalLen = np.prod(merged.shape)\n",
    "        merged = torch.reshape(merged, (batchSize, int(totalLen / batchSize)))\n",
    "        out = self.fullLinear1(merged)\n",
    "        out = self.fullLinear2(out)\n",
    "        # Skip the final model sigmoid when using BCEWithLogitsLoss loss function\n",
    "        if self.useSigmoid:\n",
    "            out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The training loop is highly parameterizable, and all aspects can be configured. The original paper uses binary cross entropy as the loss function with Adam as the optimizer, a learning rate of 0.0001, and with training configured to run for up to 100 epochs, with early stopping implemented if no improvement in loss is observed over five consecutive epochs. Our models were run with the same parameters, but longer patience values to account for the noisier and smaller dataset that we had access to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to train the model for one epoch. Collect the losses so the mean can be reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_one_iter(model, device, loss_func, optimizer, train_loader):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for abp, ecg, eeg, label in tqdm(train_loader):\n",
    "        batch = len(abp)\n",
    "        abp = abp.reshape(batch, 1, -1).type(torch.FloatTensor).to(device)\n",
    "        ecg = ecg.reshape(batch, 1, -1).type(torch.FloatTensor).to(device)\n",
    "        eeg = eeg.reshape(batch, 1, -1).type(torch.FloatTensor).to(device)\n",
    "        label = label.type(torch.float).reshape(batch, 1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        mdl = model(abp, eeg, ecg)\n",
    "        loss = loss_func(torch.nan_to_num(mdl), label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.cpu().data.numpy())\n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using the the provided loss function. This is typically called on the validation dataset at each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loss_func, val_loader):\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    for abp, ecg, eeg, label in tqdm(val_loader):\n",
    "        batch = len(abp)\n",
    "\n",
    "        abp = abp.reshape(batch, 1, -1).type(torch.FloatTensor).to(device)\n",
    "        ecg = ecg.reshape(batch, 1, -1).type(torch.FloatTensor).to(device)\n",
    "        eeg = eeg.reshape(batch, 1, -1).type(torch.FloatTensor).to(device)\n",
    "        label = label.type(torch.float).reshape(batch, 1).to(device)\n",
    "\n",
    "        mdl = model(abp, eeg, ecg)\n",
    "        loss = loss_func(torch.nan_to_num(mdl), label)\n",
    "        val_losses.append(loss.cpu().data.numpy())\n",
    "    return np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot the training and validation losses from the entire training run and indicate at which epoch the validation loss was minimized. This is typically `patience` epochs before the end of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses, best_epoch, experimentName):\n",
    "    print()\n",
    "    print(f'Plot Validation and Loss Values from Training')\n",
    "    print(f'  Epoch with best Validation Loss:  {best_epoch:3}, {val_losses[best_epoch]:.4}')\n",
    "\n",
    "    # Create x-axis values for epochs\n",
    "    epochs = range(0, len(train_losses))\n",
    "\n",
    "    plt.figure(figsize=(16, 9))\n",
    "\n",
    "    # Plot the training and validation losses\n",
    "    plt.plot(epochs, train_losses, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'r', label='Validation Loss')\n",
    "\n",
    "    # Add a vertical bar at the best_epoch\n",
    "    plt.axvline(x=best_epoch, color='g', linestyle='--', label='Best Epoch')\n",
    "\n",
    "    # Shade everything to the right of the best_epoch a light red\n",
    "    plt.axvspan(best_epoch, max(epochs), facecolor='r', alpha=0.1)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(experimentName)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Save plot to disk\n",
    "    plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_losses.png'))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the complete performance metric profile of a model. As in the original paper, the threshold is found as the argmin of the &Delta;(sensitivity, specificity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, device, dataloader, loss_func, print_detailed: bool = False):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for abp, ecg, eeg, label in tqdm(dataloader):\n",
    "            batch = len(abp)\n",
    "    \n",
    "            abp = torch.nan_to_num(abp.reshape(batch, 1, -1)).type(torch.FloatTensor).to(device)\n",
    "            ecg = torch.nan_to_num(ecg.reshape(batch, 1, -1)).type(torch.FloatTensor).to(device)\n",
    "            eeg = torch.nan_to_num(eeg.reshape(batch, 1, -1)).type(torch.FloatTensor).to(device)\n",
    "            label = label.type(torch.float).reshape(batch, 1).to(device)\n",
    "   \n",
    "            pred = model(abp, eeg, ecg)\n",
    "            loss = loss_func(pred, label)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_predictions.append(pred.detach().cpu().numpy())\n",
    "            all_labels.append(label.detach().cpu().numpy())\n",
    "\n",
    "    # Flatten the lists\n",
    "    all_predictions = np.concatenate(all_predictions).flatten()\n",
    "    all_labels = np.concatenate(all_labels).flatten()\n",
    "\n",
    "    # Calculate AUROC and AUPRC\n",
    "    # y_true, y_pred\n",
    "    auroc = roc_auc_score(all_labels, all_predictions)\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_predictions)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "    # Determine the optimal threshold, which is argmin(abs(sensitivity - specificity)) per the paper\n",
    "    thresholds = np.linspace(0, 1, 101) # 0 to 1 in 0.01 steps\n",
    "    min_diff = float('inf')\n",
    "    optimal_sensitivity = None\n",
    "    optimal_specificity = None\n",
    "    optimal_threshold = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        all_predictions_binary = (all_predictions > threshold).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_predictions_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        diff = abs(sensitivity - specificity)\n",
    "\n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            optimal_threshold = threshold\n",
    "            optimal_sensitivity = sensitivity\n",
    "            optimal_specificity = specificity\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    # accuracy\n",
    "    predictions_binary = (all_predictions > optimal_threshold).astype(int)\n",
    "    accuracy = np.mean(predictions_binary == all_labels)\n",
    "\n",
    "    if print_detailed:\n",
    "        print(f\"Predictions: {all_predictions}\")\n",
    "        print(f\"Labels: {all_labels}\")\n",
    "    print(f\"Loss: {avg_loss}\")\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    print(f\"Sensitivity: {optimal_sensitivity}\")\n",
    "    print(f\"Specificity: {optimal_specificity}\")\n",
    "    print(f\"Threshold: {optimal_threshold}\")\n",
    "    print(f\"Accuracy:  {accuracy}\")\n",
    "\n",
    "    return all_predictions, all_labels, avg_loss, auroc, auprc, \\\n",
    "        optimal_sensitivity, optimal_specificity, optimal_threshold, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate and print the AUROC and AURPC values for each epoch of a training run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_evals(model, models, device, val_loader, test_loader, loss_func, print_detailed: bool = False):\n",
    "    print()\n",
    "    print(f'Generate AUROC/AUPRC for Each Intermediate Model')\n",
    "    print()\n",
    "    val_aurocs = []\n",
    "    val_auprcs = []\n",
    "    val_accs   = []\n",
    "\n",
    "    test_aurocs = []\n",
    "    test_auprcs = []\n",
    "    test_accs   = []\n",
    "\n",
    "    for mod in models:\n",
    "        model.load_state_dict(torch.load(mod))\n",
    "        #model.train(False)\n",
    "        model.eval()\n",
    "        print(f'Intermediate Model:')\n",
    "        print(f'  {mod}')\n",
    "    \n",
    "        # validation loop\n",
    "        print(\"AUROC/AUPRC on Validation Data\")\n",
    "        all_predictions, all_labels, avg_loss, valid_auroc, valid_auprc, \\\n",
    "        optimal_sensitivity, optimal_specificity, optimal_threshold, valid_accuracy = \\\n",
    "            eval_model(model, device, val_loader, loss_func, print_detailed)\n",
    "\n",
    "        val_aurocs.append(valid_auroc)\n",
    "        val_auprcs.append(valid_auprc)\n",
    "        val_accs.append(valid_accuracy)\n",
    "        print()\n",
    "    \n",
    "        # test loop\n",
    "        print(\"AUROC/AUPRC on Test Data\")\n",
    "        all_predictions, all_labels, avg_loss, test_auroc, test_auprc, \\\n",
    "        optimal_sensitivity, optimal_specificity, optimal_threshold, test_accuracy = \\\n",
    "            eval_model(model, device, test_loader, loss_func, print_detailed)\n",
    "\n",
    "        test_aurocs.append(test_auroc)\n",
    "        test_auprcs.append(test_auprc)\n",
    "        test_accs.append(test_accuracy)\n",
    "        print()\n",
    "    \n",
    "    return val_aurocs, val_auprcs, val_accs, test_aurocs, test_auprcs, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot the AUROC, AUPRC and accuracy at each epoch and print the parameters for the best epoch on validation loss, AUROC and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auroc_auprc(val_losses, val_aurocs, val_auprcs, val_accs, \n",
    "                                      test_aurocs, test_auprcs, test_accs, all_models, best_epoch, experimentName):\n",
    "    print()\n",
    "    print(f'Plot AUROC/AUPRC for Each Intermediate Model')\n",
    "    \n",
    "    # Create x-axis values for epochs\n",
    "    epochs = range(0, len(val_aurocs))\n",
    "\n",
    "    # Find model with highest AUROC\n",
    "    np_test_aurocs = np.array(test_aurocs)\n",
    "    test_auroc_idx = np.argmax(np_test_aurocs)\n",
    "    test_accs_idx  = np.argmax(test_accs)\n",
    "\n",
    "    print(f'  Epoch with best Validation Loss:     {best_epoch:3}, {val_losses[best_epoch]:.4}')\n",
    "    print(f'  Epoch with best model Test AUROC:    {test_auroc_idx:3}, {np_test_aurocs[test_auroc_idx]:.4}')\n",
    "    print(f'  Epoch with best model Test Accuracy: {test_accs_idx:3}, {test_accs[test_accs_idx]:.4}')\n",
    "    print()\n",
    "\n",
    "    plt.figure(figsize=(16, 9))\n",
    "\n",
    "    # Plots\n",
    "    plt.plot(epochs, val_aurocs, 'C0', label='AUROC - Validation')\n",
    "    plt.plot(epochs, test_aurocs, 'C1', label='AUROC - Test')\n",
    "\n",
    "    plt.plot(epochs, val_auprcs, 'C2', label='AUPRC - Validation')\n",
    "    plt.plot(epochs, test_auprcs, 'C3', label='AUPRC - Test')\n",
    "    \n",
    "    plt.plot(epochs, val_accs, 'C4', label='Accuracy - Validation')\n",
    "    plt.plot(epochs, test_accs, 'C5', label='Accuracy - Test')\n",
    "\n",
    "    # Add vertical bars\n",
    "    plt.axvline(x=best_epoch, color='g', linestyle='--', label='Best Epoch - Validation Loss')\n",
    "    plt.axvline(x=test_auroc_idx, color='maroon', linestyle='--', label='Best Epoch - Test AUROC')\n",
    "    plt.axvline(x=test_accs_idx, color='violet', linestyle='--', label='Best Epoch - Test Accuracy')\n",
    "\n",
    "    # Shade everything to the right of the best_model a light red\n",
    "    plt.axvspan(test_auroc_idx, max(epochs), facecolor='r', alpha=0.1)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('AUROC / AUPRC')\n",
    "    plt.title('Validation and Test AUROC and AUPRC by Model Iteration Across Training')\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(loc='right')\n",
    "\n",
    "    # Save plot to disk\n",
    "    plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_all_stats.png'))\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    return np_test_aurocs, test_auroc_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to make predictions on a given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the model to a given real case to generate predictions\n",
    "def predictionsForModel(case_id_to_check, my_model, my_model_state, device, ready_model=None):\n",
    "    (abp, ecg, eeg, event) = get_track_data(case_id_to_check)\n",
    "    \n",
    "    opstart = cases.loc[case_id_to_check]['opstart'].item()\n",
    "    opend = cases.loc[case_id_to_check]['opend'].item()\n",
    "\n",
    "    abp = abp[opstart*500:opend*500]\n",
    "    ecg = ecg[opstart*500:opend*500]\n",
    "    eeg = eeg[opstart*128:opend*128]\n",
    "    \n",
    "    # number of one minute segments in each track\n",
    "    splits_abp = abp.shape[0] // (60 * 500)\n",
    "    splits_ecg = ecg.shape[0] // (60 * 500)\n",
    "    splits_eeg = eeg.shape[0] // (60 * 128)\n",
    "    \n",
    "    # predict as long as each track has data in the prediction window\n",
    "    splits = np.min([splits_abp, splits_ecg, splits_eeg])\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    the_model = None\n",
    "    \n",
    "    if ready_model is None:\n",
    "        my_model.load_state_dict(torch.load(my_model_state))\n",
    "        my_model.eval()\n",
    "        my_model = my_model.to(device)\n",
    "        the_model = my_model\n",
    "    else:\n",
    "        ready_model.eval()\n",
    "        ready_model = ready_model.to(device)\n",
    "        the_model = ready_model\n",
    "    \n",
    "    for i in range(splits):\n",
    "        t_abp = abp[i*60*500:(i + 1)*60*500]\n",
    "        t_ecg = ecg[i*60*500:(i + 1)*60*500]\n",
    "        t_eeg = eeg[i*60*128:(i + 1)*60*128]\n",
    "    \n",
    "        if len(t_abp) < 30000:\n",
    "            t_abp = np.resize(t_abp, (30000))\n",
    "            \n",
    "        if len(t_ecg) < 30000:\n",
    "            t_ecg = np.resize(t_ecg, (30000))\n",
    "            \n",
    "        if len(t_eeg) < 7680:\n",
    "            t_eeg = np.resize(t_eeg, (7680))\n",
    "            \n",
    "        t_abp = torch.from_numpy(t_abp)\n",
    "        t_ecg = torch.from_numpy(t_ecg)\n",
    "        t_eeg = torch.from_numpy(t_eeg)\n",
    "        \n",
    "        t_abp = torch.nan_to_num(t_abp.reshape(1, 1, -1)).type(torch.FloatTensor).to(device)\n",
    "        t_ecg = torch.nan_to_num(t_ecg.reshape(1, 1, -1)).type(torch.FloatTensor).to(device)\n",
    "        t_eeg = torch.nan_to_num(t_eeg.reshape(1, 1, -1)).type(torch.FloatTensor).to(device)\n",
    "\n",
    "        pred = the_model(t_abp, t_eeg, t_ecg)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(preds).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot the mean ABP and predictions for a case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printModelPrediction(case_id_to_check, preds, experimentName):  \n",
    "    (abp, ecg, eeg, event) = get_track_data(case_id_to_check)\n",
    "    \n",
    "    opstart = cases.loc[case_id_to_check]['opstart'].item()\n",
    "    opend = cases.loc[case_id_to_check]['opend'].item()\n",
    "    minutes = (opend - opstart) / 60\n",
    "    \n",
    "    plt.figure(figsize=(24, 8))\n",
    "    plt.margins(0)\n",
    "    plt.title(f'ABP - Mean Arterial Pressure - Case: {case_id_to_check} - Operating Time: {minutes} minutes')\n",
    "    plt.axhline(y = 65, color = 'maroon', linestyle = '--')\n",
    "    \n",
    "    opstart = opstart * 500\n",
    "    opend = opend * 500\n",
    "    \n",
    "    minute_step = 5\n",
    "    \n",
    "    abp_mov_avg = moving_average(abp[opstart:(opend + 60*500)])\n",
    "    myx = np.arange(opstart, opstart + len(abp_mov_avg), 1)\n",
    "    plt.plot(myx, abp_mov_avg, 'purple')\n",
    "    x_ticks = np.arange(opstart, opend, step=minute_step*30000)\n",
    "    x_labels = [str(i*minute_step) for i in range(len(x_ticks))]\n",
    "    plt.xticks(x_ticks, labels=x_labels)\n",
    "    if experimentName is not None:\n",
    "        plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_{case_id_to_check:04d}_surgery_map.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(24, 8))\n",
    "    plt.margins(0)\n",
    "    plt.title(f'Model Predictions for One Minute Intervals Using {PREDICTION_WINDOW} Minute Prediction Window')\n",
    "    plt.plot(preds)\n",
    "    x_ticks = np.arange(0, len(preds), step=minute_step)\n",
    "    x_labels = [str(i*minute_step) for i in range(len(x_ticks))]\n",
    "    plt.xticks(x_ticks, labels=x_labels)\n",
    "    if experimentName is not None:\n",
    "        plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_{case_id_to_check:04d}_surgery_predictions.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run an experiment, which includes training a model and evaluating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    experimentNamePrefix: str = None,\n",
    "    useAbp: bool = True, \n",
    "    useEeg: bool = False, \n",
    "    useEcg: bool = False, \n",
    "    nResiduals: int = 12, \n",
    "    skip_connection: bool = False, \n",
    "    batch_size: int = 64, \n",
    "    learning_rate: float = 1e-4, \n",
    "    weight_decay: float = 0.0, \n",
    "    pos_weight: float = None,\n",
    "    max_epochs: int = 100, \n",
    "    patience: int = 25, \n",
    "    device: str = \"cpu\"\n",
    "):\n",
    "    reset_random_state()\n",
    "\n",
    "    time_start = timer()\n",
    "\n",
    "    experimentName = \"\"\n",
    "\n",
    "    experimentOptions = [experimentNamePrefix, 'ABP', 'EEG', 'ECG', 'SKIPCONNECTION']\n",
    "    experimentValues = [experimentNamePrefix is not None, useAbp, useEeg, useEcg, skip_connection]\n",
    "    experimentFlags = [name for name, value in zip(experimentOptions, experimentValues) if value]\n",
    "    if experimentFlags:\n",
    "        experimentName = \"_\".join(experimentFlags)\n",
    "\n",
    "    experimentName = f\"{experimentName}_{nResiduals}_RESIDUAL_BLOCKS_{batch_size}_BATCH_SIZE_{learning_rate:.0e}_LEARNING_RATE\"\n",
    "\n",
    "    if weight_decay is not None and weight_decay != 0.0:\n",
    "        experimentName = f\"{experimentName}_{weight_decay:.0e}_WEIGHT_DECAY\"\n",
    "\n",
    "    predictionWindow = 'ALL' if PREDICTION_WINDOW == 'ALL' else f'{PREDICTION_WINDOW:03}'\n",
    "    experimentName = f\"{experimentName}_{predictionWindow}_MINS\"\n",
    "\n",
    "    maxCases = '_ALL' if MAX_CASES is None else f'{MAX_CASES:04}'\n",
    "    experimentName = f\"{experimentName}_{maxCases}_MAX_CASES\"\n",
    "    \n",
    "    # Add unique uuid8 suffix to experiment name\n",
    "    experimentName = f\"{experimentName}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "    # Fork stdout to file and console\n",
    "    with ForkedStdout(os.path.join(VITAL_RUNS, f'{experimentName}.log')):\n",
    "        print(f\"Experiment Setup\")\n",
    "        print(f'  name:              {experimentName}')\n",
    "        print(f'  prediction_window: {predictionWindow}')\n",
    "        print(f'  max_cases:         {maxCases}')\n",
    "        print(f'  use_abp:           {useAbp}')\n",
    "        print(f'  use_eeg:           {useEeg}')\n",
    "        print(f'  use_ecg:           {useEcg}')\n",
    "        print(f'  n_residuals:       {nResiduals}')\n",
    "        print(f'  skip_connection:   {skip_connection}')\n",
    "        print(f'  batch_size:        {batch_size}')\n",
    "        print(f'  learning_rate:     {learning_rate}')\n",
    "        print(f'  weight_decay:      {weight_decay}')\n",
    "        if pos_weight is not None:\n",
    "            print(f'  pos_weight:        {pos_weight}')\n",
    "        print(f'  max_epochs:        {max_epochs}')\n",
    "        print(f'  patience:          {patience}')\n",
    "        print(f'  device:            {device}')\n",
    "        print()\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Disable final sigmoid activation for BCEWithLogitsLoss\n",
    "        model = HypotensionCNN(useAbp, useEeg, useEcg, device, nResiduals, skip_connection, useSigmoid=(pos_weight is None))\n",
    "        model = model.to(device)\n",
    "    \n",
    "        if pos_weight is not None:\n",
    "            # Apply weights to positive class\n",
    "            loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))\n",
    "        else:\n",
    "            loss_func = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    \n",
    "        print(f'Model Architecture')\n",
    "        print(model)\n",
    "        print()\n",
    "\n",
    "        print(f'Training Loop')\n",
    "        # Training loop\n",
    "        best_epoch = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        best_loss = float('inf')\n",
    "        no_improve_epochs = 0\n",
    "        model_path = os.path.join(VITAL_MODELS, f\"{experimentName}.model\")\n",
    "\n",
    "        all_models = []\n",
    "\n",
    "        for i in range(max_epochs):\n",
    "            # Train the model and get the training loss\n",
    "            train_loss = train_model_one_iter(model, device, loss_func, optimizer, train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            # Calculate validate loss\n",
    "            val_loss = evaluate_model(model, loss_func, val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"[{datetime.now()}] Completed epoch {i} with training loss {train_loss:.8f}, validation loss {val_loss:.8f}\")\n",
    "\n",
    "            # Save all intermediary models.\n",
    "            tmp_model_path = os.path.join(VITAL_MODELS, f\"{experimentName}_{i:04d}.model\")\n",
    "            torch.save(model.state_dict(), tmp_model_path)\n",
    "            all_models.append(tmp_model_path)\n",
    "  \n",
    "            # Check if validation loss has improved\n",
    "            if val_loss < best_loss:\n",
    "                best_epoch = i\n",
    "                best_loss = val_loss\n",
    "                no_improve_epochs = 0\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"Validation loss improved to {val_loss:.8f}. Model saved.\")\n",
    "            else:\n",
    "                no_improve_epochs += 1\n",
    "                print(f\"No improvement in validation loss. {no_improve_epochs} epochs without improvement.\")\n",
    "\n",
    "            # exit early if no improvement in loss over last 'patience' epochs\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(\"Early stopping due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "        # Load best model from disk\n",
    "        #print()\n",
    "        #if os.path.exists(model_path):\n",
    "        #    model.load_state_dict(torch.load(model_path))\n",
    "        #    print(f\"Loaded best model from disk from epoch {best_epoch}.\")\n",
    "        #else:\n",
    "        #    print(\"No saved model found for f{experimentName}.\")\n",
    "\n",
    "        #model.train(False)\n",
    "\n",
    "        # Plot the training and validation losses across all training epochs.\n",
    "        plot_losses(train_losses, val_losses, best_epoch, experimentName)\n",
    "\n",
    "        # Generate AUROC/AUPRC for each intermediate model generated across training epochs.\n",
    "        val_aurocs, val_auprcs, val_accs, test_aurocs, test_auprcs, test_accs = \\\n",
    "            print_all_evals(model, all_models, device, val_loader, test_loader, loss_func, print_detailed=False)\n",
    "\n",
    "        # Find model with highest AUROC. Plot AUROC/AUPRC across all epochs.\n",
    "        np_test_aurocs, test_auroc_idx = plot_auroc_auprc(val_losses, val_aurocs, val_auprcs, val_accs, \\\n",
    "                                        test_aurocs, test_auprcs, test_accs, all_models, best_epoch, experimentName)\n",
    "\n",
    "        ## AUROC / AUPRC - Model with Best Validation Loss\n",
    "        best_model_val_loss = all_models[best_epoch]\n",
    "    \n",
    "        print(f'AUROC/AUPRC Plots - Best Model Based on Validation Loss')\n",
    "        print(f'  Epoch with best Validation Loss:  {best_epoch:3}, {val_losses[best_epoch]:.4}')\n",
    "        print(f'  Best Model Based on Validation Loss:')\n",
    "        print(f'    {best_model_val_loss}')\n",
    "        print()\n",
    "        print(f'Generate Stats Based on Test Data')\n",
    "        model.load_state_dict(torch.load(best_model_val_loss))\n",
    "        #model.train(False)\n",
    "        model.eval()\n",
    "    \n",
    "        best_model_val_test_predictions, best_model_val_test_labels, test_loss, \\\n",
    "            best_model_val_test_auroc, best_model_val_test_auprc, test_sensitivity, test_specificity, \\\n",
    "            best_model_val_test_threshold, best_model_val_accuracy = \\\n",
    "                eval_model(model, device, test_loader, loss_func, print_detailed=False)\n",
    "\n",
    "        # y_test, y_pred\n",
    "        display = RocCurveDisplay.from_predictions(\n",
    "            best_model_val_test_labels,\n",
    "            best_model_val_test_predictions,\n",
    "            plot_chance_level=True\n",
    "        )\n",
    "        # Save plot to disk and show\n",
    "        plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_val_auroc.png'))\n",
    "        plt.show()\n",
    "\n",
    "        print(f'best_model_val_test_auroc: {best_model_val_test_auroc}')\n",
    "\n",
    "        # Save best model in its entirety\n",
    "        torch.save(model, os.path.join(VITAL_MODELS, f'{experimentName}_full.model'))\n",
    "\n",
    "        best_model_val_test_predictions_binary = \\\n",
    "        (best_model_val_test_predictions > best_model_val_test_threshold).astype(int)\n",
    "\n",
    "        # y_test, y_pred\n",
    "        display = PrecisionRecallDisplay.from_predictions(\n",
    "            best_model_val_test_labels, \n",
    "            best_model_val_test_predictions_binary,\n",
    "            plot_chance_level=True\n",
    "        )\n",
    "        # Save plot to disk and show\n",
    "        plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_val_auprc.png'))\n",
    "        plt.show()\n",
    "\n",
    "        print(f'best_model_val_test_auprc: {best_model_val_test_auprc}')\n",
    "        print()\n",
    "\n",
    "        ## AUROC / AUPRC - Model with Best AUROC\n",
    "        # Find model with highest AUROC\n",
    "        best_model_auroc = all_models[test_auroc_idx]\n",
    "\n",
    "        print(f'AUROC/AUPRC Plots - Best Model Based on Model AUROC')\n",
    "        print(f'  Epoch with best model Test AUROC: {test_auroc_idx:3}, {np_test_aurocs[test_auroc_idx]:.4}')\n",
    "        print(f'  Best Model Based on Model AUROC:')\n",
    "        print(f'    {best_model_auroc}')\n",
    "        print()\n",
    "        print(f'Generate Stats Based on Test Data')\n",
    "        model.load_state_dict(torch.load(best_model_auroc))\n",
    "        #model.train(False)\n",
    "        model.eval()\n",
    "    \n",
    "        best_model_auroc_test_predictions, best_model_auroc_test_labels, test_loss, \\\n",
    "            best_model_auroc_test_auroc, best_model_auroc_test_auprc, test_sensitivity, test_specificity, \\\n",
    "            best_model_auroc_test_threshold, best_model_auroc_accuracy = \\\n",
    "                eval_model(model, device, test_loader, loss_func, print_detailed=False)\n",
    "\n",
    "        # y_test, y_pred\n",
    "        display = RocCurveDisplay.from_predictions(\n",
    "            best_model_auroc_test_labels,\n",
    "            best_model_auroc_test_predictions,\n",
    "            plot_chance_level=True\n",
    "        )\n",
    "        # Save plot to disk and show\n",
    "        plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_auroc_auroc.png'))\n",
    "        plt.show()\n",
    "\n",
    "        print(f'best_model_auroc_test_auroc: {best_model_auroc_test_auroc}')\n",
    "\n",
    "        best_model_auroc_test_predictions_binary = \\\n",
    "            (best_model_auroc_test_predictions > best_model_auroc_test_threshold).astype(int)\n",
    "\n",
    "        # y_test, y_pred\n",
    "        display = PrecisionRecallDisplay.from_predictions(\n",
    "            best_model_auroc_test_labels, \n",
    "            best_model_auroc_test_predictions_binary,\n",
    "            plot_chance_level=True\n",
    "        )\n",
    "        # Save plot to disk and show\n",
    "        plt.savefig(os.path.join(VITAL_RUNS, f'{experimentName}_auroc_auprc.png'))\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"best_model_auroc_test_auprc: {best_model_auroc_test_auprc}\")\n",
    "        print()\n",
    "        \n",
    "        time_delta = np.round(timer() - time_start, 3)\n",
    "        print(f'Total Processing Time: {time_delta:.4f} sec')\n",
    "        \n",
    "    return (model, best_model_val_loss, best_model_auroc, experimentName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When false, run only the first experiment below and then stop\n",
    "SWEEP_ALL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data tracks\n",
    "\n",
    "Run experiments across the biosignal data track combinations:\n",
    "- ABP\n",
    "- ECG\n",
    "- EEG\n",
    "- ABP+ECG\n",
    "- ABP+EEG\n",
    "- ECG+EEG\n",
    "- ABP+ECG+EEG\n",
    "\n",
    "The first experiment acts as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_EXPERIMENT = True\n",
    "DISPLAY_MODEL_PREDICTION=True\n",
    "DISPLAY_MODEL_PREDICTION_FIRST_ONLY=True\n",
    "\n",
    "MAX_EPOCHS=200\n",
    "PATIENCE=20\n",
    "\n",
    "data_tracks = [\n",
    "    # useAbp, useEeg, useEcg, experiement enable\n",
    "    [True, False, False, True], # ABP only\n",
    "    [False, False, True, SWEEP_ALL], # ECG only\n",
    "    [False, True, False, SWEEP_ALL], # EEG only\n",
    "    [True, False, True, SWEEP_ALL], # ABP + ECG\n",
    "    [True, True, False, SWEEP_ALL], # ABP + EEG\n",
    "    [False, True, True, SWEEP_ALL], # ECG + EEG\n",
    "    [True, True, True, SWEEP_ALL] # ABP + ECG + EEG\n",
    "]\n",
    "\n",
    "if ENABLE_EXPERIMENT:\n",
    "    for (useAbp, useEeg, useEcg, enable) in data_tracks:\n",
    "        if enable:\n",
    "            (model, best_model_val_loss, best_model_auroc, experimentName) = run_experiment(\n",
    "                experimentNamePrefix=None, \n",
    "                useAbp=useAbp, \n",
    "                useEeg=useEeg, \n",
    "                useEcg=useEcg,\n",
    "                nResiduals=12, \n",
    "                skip_connection=False,\n",
    "                batch_size=128,\n",
    "                learning_rate=1e-4,\n",
    "                weight_decay=1e-1,\n",
    "                pos_weight=None,\n",
    "                max_epochs=MAX_EPOCHS,\n",
    "                patience=PATIENCE,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            if DISPLAY_MODEL_PREDICTION:\n",
    "                for case_id_to_check in my_cases_of_interest_idx:\n",
    "                    preds = predictionsForModel(case_id_to_check, model, best_model_val_loss, device)\n",
    "                    printModelPrediction(case_id_to_check, preds, experimentName)\n",
    "\n",
    "                    if DISPLAY_MODEL_PREDICTION_FIRST_ONLY:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size\n",
    "\n",
    "Holding all other parameters fixed, sweep the batch sizes from 16 to 256:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_EXPERIMENT = False\n",
    "DISPLAY_MODEL_PREDICTION=True\n",
    "DISPLAY_MODEL_PREDICTION_FIRST_ONLY=True\n",
    "\n",
    "batch_sizes = [\n",
    "    [16, 32, 64, 128, 256]\n",
    "]\n",
    "\n",
    "if ENABLE_EXPERIMENT:\n",
    "    for batch_size in batch_sizes:\n",
    "        (model, best_model_val_loss, best_model_auroc, experimentName) = run_experiment(\n",
    "            experimentNamePrefix=None, \n",
    "            useAbp=True, \n",
    "            useEeg=False, \n",
    "            useEcg=False,\n",
    "            nResiduals=12, \n",
    "            skip_connection=False,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=0.0,\n",
    "            pos_weight=None,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            patience=PATIENCE,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        if DISPLAY_MODEL_PREDICTION:\n",
    "            for case_id_to_check in my_cases_of_interest_idx:\n",
    "                preds = predictionsForModel(case_id_to_check, model, best_model_val_loss, device)\n",
    "                printModelPrediction(case_id_to_check, preds, experimentName)\n",
    "\n",
    "                if DISPLAY_MODEL_PREDICTION_FIRST_ONLY:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate\n",
    "\n",
    "Holding all other parameters fixed, sweep the learning rate from 1e-2 to 1e-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_EXPERIMENT = False\n",
    "DISPLAY_MODEL_PREDICTION=True\n",
    "DISPLAY_MODEL_PREDICTION_FIRST_ONLY=True\n",
    "\n",
    "learning_rates = [\n",
    "    1e-4, 1e-3, 1e-2\n",
    "]\n",
    "\n",
    "if ENABLE_EXPERIMENT:\n",
    "    for learning_rate in learning_rates:\n",
    "        (model, best_model_val_loss, best_model_auroc, experimentName) = run_experiment(\n",
    "            experimentNamePrefix=None, \n",
    "            useAbp=True, \n",
    "            useEeg=False, \n",
    "            useEcg=False,\n",
    "            nResiduals=12, \n",
    "            skip_connection=False,\n",
    "            batch_size=128,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=0.0,\n",
    "            pos_weight=None,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            patience=PATIENCE,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "        if DISPLAY_MODEL_PREDICTION:\n",
    "            for case_id_to_check in my_cases_of_interest_idx:\n",
    "                preds = predictionsForModel(case_id_to_check, model, best_model_val_loss, device)\n",
    "                printModelPrediction(case_id_to_check, preds, experimentName)\n",
    "\n",
    "                if DISPLAY_MODEL_PREDICTION_FIRST_ONLY:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight decay\n",
    "\n",
    "Holding all other parameters fixed, sweep the weight decay from `1e-3` to `1e0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_EXPERIMENT = False\n",
    "DISPLAY_MODEL_PREDICTION=True\n",
    "DISPLAY_MODEL_PREDICTION_FIRST_ONLY=True\n",
    "\n",
    "weight_decays = [\n",
    "    1e-3, 1e-2, 1e-1, 1e0\n",
    "]\n",
    "\n",
    "if ENABLE_EXPERIMENT:\n",
    "    for weight_decay in weight_decays:\n",
    "        (model, best_model_val_loss, best_model_auroc, experimentName) = run_experiment(\n",
    "            experimentNamePrefix=None, \n",
    "            useAbp=True, \n",
    "            useEeg=False, \n",
    "            useEcg=False,\n",
    "            nResiduals=12, \n",
    "            skip_connection=False,\n",
    "            batch_size=128,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=weight_decay,\n",
    "            pos_weight=None,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            patience=PATIENCE,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "        if DISPLAY_MODEL_PREDICTION:\n",
    "            for case_id_to_check in my_cases_of_interest_idx:\n",
    "                preds = predictionsForModel(case_id_to_check, model, best_model_val_loss, device)\n",
    "                printModelPrediction(case_id_to_check, preds, experimentName)\n",
    "\n",
    "                if DISPLAY_MODEL_PREDICTION_FIRST_ONLY:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label balance\n",
    "\n",
    "Holding all other parameters fixed, sweep the `pos_weight` in `BCEWithLogitsLoss` from `2` to `4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_EXPERIMENT = False\n",
    "DISPLAY_MODEL_PREDICTION=True\n",
    "DISPLAY_MODEL_PREDICTION_FIRST_ONLY=True\n",
    "\n",
    "pos_weights = [\n",
    "    2.0, 4.0\n",
    "]\n",
    "\n",
    "if ENABLE_EXPERIMENT:\n",
    "    for pos_weight in pos_weights:\n",
    "        (model, best_model_val_loss, best_model_auroc, experimentName) = run_experiment(\n",
    "            experimentNamePrefix=None, \n",
    "            useAbp=True, \n",
    "            useEeg=False, \n",
    "            useEcg=False,\n",
    "            nResiduals=12, \n",
    "            skip_connection=False,\n",
    "            batch_size=128,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=0.0,\n",
    "            pos_weight=pos_weight,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            patience=PATIENCE,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "        if DISPLAY_MODEL_PREDICTION:\n",
    "            for case_id_to_check in my_cases_of_interest_idx:\n",
    "                preds = predictionsForModel(case_id_to_check, model, best_model_val_loss, device)\n",
    "                printModelPrediction(case_id_to_check, preds, experimentName)\n",
    "\n",
    "                if DISPLAY_MODEL_PREDICTION_FIRST_ONLY:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablations\n",
    "\n",
    "Holding all other parameters fixed, perform ablations on the following parameters:\n",
    "- Number of Residual Blocks (6, 1)\n",
    "- Skip Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_EXPERIMENT = False\n",
    "DISPLAY_MODEL_PREDICTION=True\n",
    "DISPLAY_MODEL_PREDICTION_FIRST_ONLY=True\n",
    "\n",
    "ablations = [\n",
    "    # nResiduals, skip_connection\n",
    "    [6, False],\n",
    "    [1, False],\n",
    "    [12, True]\n",
    "]\n",
    "\n",
    "if ENABLE_EXPERIMENT:\n",
    "    for (nResiduals, skip_connection) in ablations:\n",
    "        (model, best_model_val_loss, best_model_auroc, experimentName) = run_experiment(\n",
    "            experimentNamePrefix=None, \n",
    "            useAbp=True, \n",
    "            useEeg=False, \n",
    "            useEcg=False,\n",
    "            nResiduals=nResiduals, \n",
    "            skip_connection=skip_connection,\n",
    "            batch_size=128,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=0.0,\n",
    "            pos_weight=None,\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            patience=PATIENCE,\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "        if DISPLAY_MODEL_PREDICTION:\n",
    "            for case_id_to_check in my_cases_of_interest_idx:\n",
    "                preds = predictionsForModel(case_id_to_check, model, best_model_val_loss, device)\n",
    "                printModelPrediction(case_id_to_check, preds, experimentName)\n",
    "\n",
    "                if DISPLAY_MODEL_PREDICTION_FIRST_ONLY:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Metric description\n",
    "\n",
    "As in the original paper, model performance will be evaluated on the following metrics:\n",
    "\n",
    "- **AUROC**: Area Under Receiver Operating Curve. This is a measure of the model's ability to distinguish between positive and negative classes. The curve is generated by plotting the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings, and the area under this curve is calculated. Higher values are indicative of better model performance.\n",
    "- **AUPRC**: Area Under Precision Recall Curve. This is a measure of the model's ability to balance precision and recall. The curve is generated by plotting precision against recall at various threshold settings, and the area under this curve is calculated. Higher values are indicative of better model performance.\n",
    "- **Sensitivity**: The proportion of true positive cases that are correctly identified by the model, as a fraction of all true cases. Higher values are indicative of better model performance.\n",
    "- **Specificity**: The proportion of true negative cases that are correctly identified by the model, as a fraction of all true negative cases. Higher values are indicative of better model performance.\n",
    "- **Threshold**: This is not strictly an evaluation metric, but is reported as the threshold value which minimizes the difference between the sensitivity and specificity.\n",
    "\n",
    "### Model evaluation\n",
    "\n",
    "Calculate performance metrics on pre-trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_VALIDATION = True\n",
    "\n",
    "validate_models = [\n",
    "    # prediction window, useAbp, useEeg, useEcg, model path\n",
    "    # 3-minute models\n",
    "    [3, os.path.join('pretrained', 'abp_3min_f386500f.model')],\n",
    "    [3, os.path.join('pretrained', 'ecg_3min_9888ba74.model')],\n",
    "    [3, os.path.join('pretrained', 'eeg_3min_6e41ecbf.model')],\n",
    "    [3, os.path.join('pretrained', 'abp_ecg_3min_4c033450.model')],\n",
    "    [3, os.path.join('pretrained', 'abp_eeg_3min_a25c1edf.model')],\n",
    "    [3, os.path.join('pretrained', 'eeg_ecg_3min_24df69ca.model')],\n",
    "    [3, os.path.join('pretrained', 'abp_eeg_ecg_3min_bea05a31.model')],\n",
    "    # 5-minute models\n",
    "    [5, os.path.join('pretrained', 'abp_5min_f4919819.model')],\n",
    "    [5, os.path.join('pretrained', 'ecg_5min_f5345149.model')],\n",
    "    [5, os.path.join('pretrained', 'eeg_5min_8970a5eb.model')],\n",
    "    [5, os.path.join('pretrained', 'abp_ecg_5min_6306c305.model')],\n",
    "    [5, os.path.join('pretrained', 'abp_eeg_5min_482fd843.model')],\n",
    "    [5, os.path.join('pretrained', 'eeg_ecg_5min_3885bb9f.model')],\n",
    "    [5, os.path.join('pretrained', 'abp_eeg_ecg_5min_5ab3f8eb.model')],\n",
    "    # 10-minute models\n",
    "    [10, os.path.join('pretrained', 'abp_10min_7661baf5.model')],\n",
    "    [10, os.path.join('pretrained', 'ecg_10min_49dc88bd.model')],\n",
    "    [10, os.path.join('pretrained', 'eeg_10min_90d4cdb5.model')],\n",
    "    [10, os.path.join('pretrained', 'abp_ecg_10min_009ed9f2.model')],\n",
    "    [10, os.path.join('pretrained', 'abp_eeg_10min_ff7c129d.model')],\n",
    "    [10, os.path.join('pretrained', 'eeg_ecg_10min_e34ef1f5.model')],\n",
    "    [10, os.path.join('pretrained', 'abp_eeg_ecg_10min_198d1d84.model')],\n",
    "    # 15-minute models\n",
    "    [15, os.path.join('pretrained', 'abp_15min_61321b51.model')],\n",
    "    [15, os.path.join('pretrained', 'ecg_15min_3ac4acf1.model')],\n",
    "    [15, os.path.join('pretrained', 'eeg_15min_acd313eb.model')],\n",
    "    [15, os.path.join('pretrained', 'abp_ecg_15min_ad0d8b9b.model')],\n",
    "    [15, os.path.join('pretrained', 'abp_eeg_15min_4c527f9b.model')],\n",
    "    [15, os.path.join('pretrained', 'eeg_ecg_15min_2bb1d44d.model')],\n",
    "    [15, os.path.join('pretrained', 'abp_eeg_ecg_15min_10e6e48b.model')],\n",
    "]\n",
    "\n",
    "if ENABLE_VALIDATION:\n",
    "    #test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)\n",
    "    #loss_func = nn.BCELoss()\n",
    "    for pred_window, model_path in validate_models:\n",
    "        if pred_window == PREDICTION_WINDOW:\n",
    "            print()\n",
    "            print(f\"Prediction Window: {pred_window}, Model: {model_path}\")\n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)\n",
    "            loss_func = nn.BCELoss()\n",
    "            model = torch.load(model_path)\n",
    "            eval_model(model, device, test_loader, loss_func, print_detailed = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction\n",
    "\n",
    "Use the model to predict the chance of an IOH event for real cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERFORM_PREDICTIONS = False\n",
    "PERFORM_PREDICTION_FIRST_ONLY = True\n",
    "\n",
    "# NOTE: This is always set so that if earlier checks were enabled, the earlier data will be reused.\n",
    "my_cases_of_interest_idx = [84, 198, 60, 16, 27]\n",
    "\n",
    "if PERFORM_PREDICTIONS:\n",
    "    positiveSegmentsMap, negativeSegmentsMap, iohEventsMap, cleanEventsMap = \\\n",
    "        extract_segments(my_cases_of_interest_idx, debug=False,\n",
    "                         checkCache=False, forceWrite=False, returnSegments=True,\n",
    "                         skipInvalidCleanEvents=SKIP_INVALID_CLEAN_EVENTS,\n",
    "                         skipInvalidIohEvents=SKIP_INVALID_IOH_EVENTS)\n",
    "\n",
    "    for pred_window, model_path in validate_models:\n",
    "        if pred_window == PREDICTION_WINDOW:\n",
    "            for case_id_to_check in my_cases_of_interest_idx:\n",
    "                print()\n",
    "                print(f'Model Predictions - Case {case_id_to_check} for {pred_window} Minute Prediction Window')\n",
    "                print(f'Model: {model_path}')\n",
    "                printAbpOverlay(case_id_to_check, positiveSegmentsMap, \n",
    "                            negativeSegmentsMap, iohEventsMap, cleanEventsMap, movingAverage=False)\n",
    "\n",
    "                ready_model = torch.load(model_path)\n",
    "                preds = predictionsForModel(case_id_to_check, None, None, device, ready_model=ready_model)\n",
    "\n",
    "                printModelPrediction(case_id_to_check, preds, None)\n",
    "\n",
    "                if PERFORM_PREDICTION_FIRST_ONLY:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6bCcZNuxmz"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We were able to run all of the same experiments as the authors of the original paper, though we were not able to fully replicate their results. In addition, were were able to run a few ablation studies to quantify the impact of the number of residual blocks and the skip connection path in the model.\n",
    "\n",
    "Our complete table of experimental results is show below in Table 1:\n",
    "\n",
    "| Waveform              | AUROC        | AUPRC        | Sensitivity  | Specificity  | Threshold |\n",
    "| --------------------- | ------------ | ------------ | ------------ | ------------ | --------- |\n",
    "| **Time to event: 3 min**  |              |              |              |              |           |\n",
    "| ABP                   | 0.8348665138 | 0.6827477064 | 0.7586206897 | 0.7586916743 | 0.24      |\n",
    "| ECG                   | 0.5172308631 | 0.2777976524 | 0.6864623244 | 0.3392040256 | 0.34      |\n",
    "| EEG                   | 0.5765847539 | 0.3108817974 | 0.5504469987 | 0.5562671546 | 0.28      |\n",
    "| ABP + ECG             | **0.8350885234** | 0.6822426973 | **0.7618135377** | 0.7463403477 | 0.23      |\n",
    "| ABP + EEG             | 0.8333041215 | **0.6830001845** | 0.7573435504 | 0.7602927722 | 0.26      |\n",
    "| ECG + EEG             | 0.5634548602 | 0.3061094980 | 0.5932311622 | 0.5166971638 | 0.34      |\n",
    "| ABP + ECG + EEG       | 0.8327256552 | 0.6812673236 | 0.7541507024 | **0.7653247941** | 0.29      |\n",
    "| **Time to event: 5 min**  |              |              |              |              |           |\n",
    "| ABP                   | **0.8001353845** | **0.6089914018** | 0.7172413793 | 0.7268053283 | 0.19      |\n",
    "| ECG                   | 0.5408307613 | 0.2789858266 | **0.9089655172** | 0.0983874737 | 0.30      |\n",
    "| EEG                   | 0.5889406162 | 0.3209396685 | 0.5606896552 | 0.5814442627 | 0.26      |\n",
    "| ABP + ECG             | 0.7980903530 | 0.6008434537 | **0.7234482759** | 0.7120822622 | 0.17      |\n",
    "| ABP + EEG             | 0.7932250526 | 0.6046273056 | 0.7020689655 | **0.7289086235** | 0.22      |\n",
    "| ECG + EEG             | 0.5959877026 | 0.3278444283 | 0.6020689655 | 0.5461556438 | 0.30      |\n",
    "| ABP + ECG + EEG       | 0.7912796254 | 0.6016009768 | 0.7151724138 | 0.7193269455 | 0.25      |\n",
    "| **Time to event: 10 min** |              |              |              |              |           |\n",
    "| ABP                   | 0.7417550791 | **0.4515207123** | 0.6550802139 | **0.7046703297** | 0.18      |\n",
    "| ECG                   | 0.4859654235 | 0.1971933307 | **0.8609625668** | 0.1252289377 | 0.22      |\n",
    "| EEG                   | 0.5929758558 | 0.2583727183 | 0.5695187166 | 0.5592948718 | 0.24      |\n",
    "| ABP + ECG             | 0.7434999641 | 0.4485223920 | **0.7058823529** | 0.6572802198 | 0.17      |\n",
    "| ABP + EEG             | **0.7456936446** | 0.4482909599 | 0.6773618538 | 0.6893315018 | 0.17      |\n",
    "| ECG + EEG             | 0.5900167031 | 0.2531979287 | 0.5989304813 | 0.5283882784 | 0.23      |\n",
    "| ABP + ECG + EEG       | 0.7433881478 | 0.4513591475 | 0.6951871658 | 0.6668956044 | 0.16      |\n",
    "| **Time to event: 15 min** |              |              |              |              |           |\n",
    "| ABP                   | 0.7350525214 | 0.3629148943 | 0.6534772182 | **0.6929577465** | 0.14      |\n",
    "| ECG                   | 0.4958383997 | 0.1685094385 | 0.3944844125 | 0.6157276995 | 0.22      |\n",
    "| EEG                   | 0.5681875626 | 0.1976809641 | 0.5935251799 | 0.5009389671 | 0.21      |\n",
    "| ABP + ECG             | **0.7377326308** | **0.3649217753** | 0.6642685851 | 0.6786384977 | 0.15      |\n",
    "| ABP + EEG             | 0.7364418324 | 0.3626843809 | 0.6678657074 | 0.6732394366 | 0.15      |\n",
    "| ECG + EEG             | 0.5763017755 | 0.2000958414 | 0.5071942446 | 0.6140845070 | 0.18      |\n",
    "| ABP + ECG + EEG       | 0.7344424460 | 0.3624089403 | **0.6906474820** | 0.6593896714 | 0.15      |\n",
    "\n",
    "Table 1: Area under the Receiver-operating Characteristic Curve, Area under the Precision-Recall Curve, Sensitivity, and Specificity of the model in predicting intraoperative hypotension\n",
    "\n",
    "For comparison, the results in the original paper are shown below as Table 2:\n",
    "![Area under the Receiver-operating Characteristic Curve, Area under the Precision-Recall Curve, Sensitivity, and Specificity of the model in predicting intraoperative hypotension](https://journals.plos.org/plosone/article/figure/image?download&size=large&id=10.1371/journal.pone.0272055.t003)\n",
    "Table 2: Area under the Receiver-operating Characteristic Curve, Area under the Precision-Recall Curve, Sensitivity, and Specificity of the model in predicting intraoperative hypotension in the original paper\n",
    "\n",
    "### Hypotheses\n",
    "\n",
    "The original paper investigated the following hypotheses:\n",
    "\n",
    "1.   Hypothesis 1: A model using ABP and ECG will outperform a model using ABP alone in predicting IOH.\n",
    "2.   Hypothesis 2: A model using ABP and EEG will outperform a model using ABP alone in predicting IOH.\n",
    "3.   Hypothesis 3: A model using ABP, EEG, and ECG will outperform a model using ABP alone in predicting IOH.\n",
    "\n",
    "As seen in the results in Table 1, our results were very noisy and unable to prove or disprove any of the three hypotheses. The results were not consistent across the prediction windows or metrics, and the performance was not as high as in the original paper. \n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "We performed a hyperparameter search across batch size, learning rate, weight decay, and label balancing. The results are shown below in Table 3:\n",
    "\n",
    "| Hyperparameter | Search range          | Optimum value  |\n",
    "| -------------- | --------------------- | -------------- |\n",
    "| Batch size     | 16, 32, 64, 128, 256  | 128            |\n",
    "| Learning rate  | 1e-4, 1e-3, 1e-2      | 1e-4           |\n",
    "| Weight decay   | 1e-3, 1e-2, 1e-1, 1e0 | 1-e1           |\n",
    "| Label balance  | 1.0, 2.0, 4.0         | 1.0 (disabled) |\n",
    "\n",
    "Table 3: Hyperparameter search ranges and optimum values\n",
    "\n",
    "The experimental data supporting these results can be found in [Supplemental Table 1 - Hyperparameter exploration](https://raw.githubusercontent.com/abarrie2/cs598-dlh-project/main/Supplemental%20Table%201%20Hyperparameter%20exploration.xlsx).\n",
    "\n",
    "### Ablation Study\n",
    "\n",
    "We performed an ablation study of the number of residual blocks and presence of skip connections. The original model configuration was found to have better performance than the ablated models, showing that the original model features contribute positively to the model performance and their removal results in a qualitatively worse result.\n",
    "\n",
    "The experimental data supporting these results can be found in [Supplemental Table 2 - Ablation study](https://raw.githubusercontent.com/abarrie2/cs598-dlh-project/main/Supplemental%20Table%202%20Ablation%20study.xlsx)\n",
    "\n",
    "### Computational requirements\n",
    "\n",
    "Training and evaluation was run on three different machines as shown in Table 4 below:\n",
    "\n",
    "| Machine     | Processor         | System RAM | GPU            | GPU RAM            | Device |\n",
    "| ----------- | ----------------- | ---------- | -------------- | ------------------ | ------ |\n",
    "| Macbook Pro | M1                | 32 GB      | Integrated     | Shared with system | mps    |\n",
    "| Macbook Pro | M3 Pro            | 36 GB      | Integrated     | Shared with system | mps    |\n",
    "| Desktop PC  | AMD Ryzen 7 3800X | 32 GB      | GTX 2070 Super | 8 GB               | cuda   |\n",
    "\n",
    "Table 4: Specifications of machines used in training and evaluation\n",
    "\n",
    "Typical runtime on a Macbook Pro is on the order of 2-3 minutes per epoch, and a typical experiment runs for 20-60 epochs. Including post-training evaluations, a typical experiment takes 90-360 minutes.\n",
    "\n",
    "We estimate that we spent a total of 350 GPU hours training across all experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH"
   },
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implications of experimental results\n",
    "\n",
    "### Reproducibility of original paper\n",
    "\n",
    "Although we were not able to achieve the same performance level as the original paper, we were able to perform all of the same experiments and test the hypotheses. The results of our experiments were ultimately consistent with the original paper, or consistent from prediction window to prediction window, or metric to metric, and we were unable to prove or disprove any of the three hypotheses. The hyperparameter search and ablation study results were consistent with the original paper.\n",
    "\n",
    "Using our best models, we were able to generate predictions for cases and then plot the predicted values (probability of an IOH event) and compare it to to mean arterial pressure (MAP) of the raw ABP waveform. The predictions would increase prior to the MAP beginning to drop and decrease as the MAP recovered. For sustained periods of MAP below 65 mmHg the model predictions would become high and remain high for the duration of the IOH event. These results were consistent with similar prediction plots presented in `Figure 3` of the original paper.\n",
    "\n",
    "We believe that the discrepancy in performance between our results and the original paper is mostly due to the differences in datasets and data preprocessing. The original paper used a dataset with 39,600 cases, of which 14,140 met the inclusion and exclusion critera and were used for training. The authors released a much smaller dataset publically with only 6,388 cases, of which 2,763 met the inclusion and exclusion criteria. This smaller dataset provided less data for training and validation, which likely impacted the model's performance.\n",
    "\n",
    "The original paper also used a signal quality index to filter out low-quality data, which we were not able to implement. This likely introduced noise into our dataset, which likely impacted the model's performance.\n",
    "\n",
    "The authors of the original paper also used a different data preprocessing pipeline than we did, and did not precisely document it. This lead us to try various data preprocessing methods to try to match the original paper's results, but we were not able to achieve the same performance levels.\n",
    "\n",
    "## Factors affecting reproducibility\n",
    "\n",
    "### Low difficulty\n",
    "\n",
    "The most straightforward aspects of this project were the data download and the model implementation. Specific areas were we encountered low difficulty:\n",
    "- The data download was straightforward, as the dataset was available through a convenient API through Python library as well as being published to Physionet for download.\n",
    "- The model architecture was generally clearly defined in the original paper with an included architecture diagram. The hyperparameters were provided in a supplemental table. These features made it easy to implement the model in PyTorch.\n",
    "\n",
    "### High difficulty\n",
    "\n",
    "The most difficult aspects of this project all involved the data preprocessing stage. This is the most impactful part of the data pipeline and it was not fully documented in the original paper. Some areas were we encountered difficulty:\n",
    "- The source data is unlabelled, so our team was responsible for implementing analysis methods for identifying positive (IOH event occurred) and negative (IOH event did not occur) by running a lookahead analysis of our input training set. The original paper was not precise on how this was done, so we had to make some assumptions.\n",
    "- The volume of raw data is in excess of 90GB. A non-trivial amount of compute was required to minify the input data to only include the data tracks of interest to our experiments (i.e., ABP, ECG, and EEG tracks).\n",
    "- We found it difficult to trace back to the definition of the \"jSQI\" signal quality index referenced in the paper. Multiple references through multiple papers needed to be traversed to understand which variant of the quality index \n",
    "   - The only available source code related to the signal quality index as referenced by our paper in [5]. Source code was not directly linked from the paper, but the GitHub repository for the corresponding author for reference [5] did result in the identification of MATLAB source code for the signal quality index as described in the referenced paper. That code is available at https://github.com/cliffordlab/PhysioNet-Cardiovascular-Signal-Toolbox/tree/master/Tools/BP_Tools [7]\n",
    "   - Our team had insufficient time to port this signal quality index to Python for use in our investigation, or to setup a MATLAB environment in which to assess our source data using the above MATLAB functions. This is a potential source of noise in our dataset, as the signal quality index was used to filter out low-quality data in the original paper, and we were unable to do the same.\n",
    "\n",
    "### Unknowns\n",
    "\n",
    "One aspect of our results that we were unable to explain was why our threshold values were lower than expected. In the original paper, the threshold is chosen in order to minimize the difference between sensitivity and specificity, and we applied an algorithm to achieve this goal. However, in the original paper, the thresholds were between 0.30 and 0.62 while our results were between 0.14 and 0.34. We posited that this was due to the label imbalance (4 positive labels : 1 negative label) and performed experiments comparing different `pos_weight` values using the `BCEWithLogitsLoss` loss function with the `BCELoss` loss function fro the original paper. However, this did not yield better, or indeed any usable results.\n",
    "\n",
    "## Suggestions to original authors\n",
    "\n",
    "Our main suggestion to the original authors would be to release their code publically and to provide more detailed documentation of the data preprocessing pipeline. This would help future researchers to reproduce the results more accurately. Specifically, the authors should provide more information on how the signal quality index was calculated and used to filter out low-quality data.\n",
    "\n",
    "We would also suggestion correcting the hyperparameters published in Supplemental Table 1. Specifically, the output size for residual blocks 11 and 12 for the ECG and ABP data sets was 496x6. This is a typo, and should read 469x6. This typo became apparent when operating the size down operation within Residual Block 11 and recognizing the tensor dimensions were misaligned.\n",
    "\n",
    "Additionally, more explicit references to the signal quality index assessment tools should be added. Our team could not find a reference to the MATLAB source code as described in reference [3], and had to manually discover the GitHub profile for the lab of the corresponding author of reference [3] in order to find MATLAB source that corresponded to the metrics described therein.\n",
    "\n",
    "## Future work\n",
    "\n",
    "In future work, we would like to implement the signal quality index and use it to filter out low-quality data. We would also like to experiment with additional data preprocessing techniques and pre-filtered datasets such as PulseDB: a cleaned dataset based on MIMIC-III and VitalDB. Further, we would like to experiment with different model architectures and hyperparameters to see if we can improve the model's performance. Finally, we would like to run the models with different seeds to create a model ensemble in order to smooth some of the noise in our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "1. Jo Y-Y, Jang J-H, Kwon J-m, Lee H-C, Jung C-W, Byun S, et al. â€œPredicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study.â€ PLoS ONE, (2022) 17(8): e0272055 https://doi.org/10.1371/journal.pone.0272055\n",
    "2. Hatib, Feras, Zhongping J, Buddi S, Lee C, Settels J, Sibert K, Rhinehart J, Cannesson M â€œMachine-learning Algorithm to Predict Hypotension Based on High-fidelity Arterial Pressure Waveform Analysisâ€ Anesthesiology (2018) 129:4 https://doi.org/10.1097/ALN.0000000000002300\n",
    "3. Bao, X., Kumar, S.S., Shah, N.J. et al. \"AcumenTM hypotension prediction index guidance for prevention and treatment of hypotension in noncardiac surgery: a prospective, single-arm, multicenter trial.\" Perioperative Medicine (2024) 13:13 https://doi.org/10.1186/s13741-024-00369-9\n",
    "4. Lee, HC., Park, Y., Yoon, S.B. et al. VitalDB, a high-fidelity multi-parameter vital signs database in surgical patients. Sci Data 9, 279 (2022). https://doi.org/10.1038/s41597-022-01411-5\n",
    "5. Li Q., Mark R.G. & Clifford G.D. \"Artificial arterial blood pressure artifact models and an evaluation of a robust blood pressure and heart rate estimator.\" BioMed Eng OnLine. (2009) 8:13. pmid:19586547 https://doi.org/10.1186/1475-925X-8-13\n",
    "6. Park H-J, \"VitalDB Python Example Notebooks\" GitHub Repository https://github.com/vitaldb/examples/blob/master/hypotension_art.ipynb\n",
    "7. Vest A, Da Poian G, Li Q, Liu C, Nemati S, Shah A, Clifford GD, \"An Open Source Benchmarked Toolbox for Cardiovascular Waveform and Interval Analysis\", Physiological measurement 39, no. 10 (2018): 105004. DOI:10.5281/zenodo.1243111; 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta = np.round(timer() - global_time_start, 3)\n",
    "print(f'Total Notebook Processing Time: {time_delta:.4f} sec')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
