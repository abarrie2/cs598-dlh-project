{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency installs\n",
    "%pip install vitaldb\n",
    "%pip install torch\n",
    "%pip install numpy\n",
    "%pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_trks = pd.read_csv('https://api.vitaldb.net/trks')  # read track list\n",
    "df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # read case information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inclusion & exclusion criteria\n",
    "'''\n",
    "caseids = list(\n",
    "    set(df_trks[df_trks['tname'] == 'SNUADC/ART']['caseid']) &\n",
    "    set(df_cases[df_cases['age'] > 18]['caseid']) &\n",
    "    set(df_cases[df_cases['age'] >= 18]['caseid']) & \n",
    "    set(df_cases[df_cases['weight'] >= 30]['caseid']) & \n",
    "    set(df_cases[df_cases['weight'] < 140]['caseid']) & \n",
    "    set(df_cases[df_cases['height'] >= 135]['caseid']) & \n",
    "    set(df_cases[df_cases['height'] < 200]['caseid']) & \n",
    "    set(df_cases[~df_cases['opname'].str.contains(\"transplant\", case=False)]['caseid']) & \n",
    "    set(df_cases[~df_cases['opname'].str.contains(\"aneurysm\", case=False)]['caseid']) & \n",
    "    set(df_cases[~df_cases['opname'].str.contains(\"aorto\", case=False)]['caseid'])& \n",
    "    set(df_cases[df_cases['ane_type'] == 'General']['caseid'])\n",
    ")\n",
    "'''\n",
    "\n",
    "caseids = list(\n",
    "    set(df_trks.loc[df_trks['tname'] == 'SNUADC/ART', 'caseid']) & \n",
    "    set(df_trks.loc[df_trks['tname'] == 'SNUADC/ECG_II', 'caseid']) & \n",
    "    set(df_trks.loc[df_trks['tname'] == 'BIS/EEG1_WAV', 'caseid']) & \n",
    "    set(df_cases.loc[df_cases['age'] > 18, 'caseid']) & \n",
    "    set(df_cases.loc[df_cases['ane_type'] == 'General', 'caseid'])\n",
    ")\n",
    "print(f'{len(caseids)} cases found')\n",
    "\n",
    "print('Total {} cases found'.format(len(caseids)))\n",
    "np.random.shuffle(caseids)  # shuffle caseids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINUTES_AHEAD = 1  # Predict hypotension 1 minutes ahead\n",
    "BATCH_SIZE = 256  # Batch size for learning\n",
    "MAX_CASES = 100  # Maximum number of cases for this example\n",
    "SRATE = 100  # sampling rate for the arterial waveform signal\n",
    "\n",
    "# Final dataset for training and testing the model\n",
    "x = []  # input with shape of (segements, timepoints)\n",
    "y = []  # output with shape of (segments)\n",
    "valid_mask = []  # validity of each segement\n",
    "c = []  # caseid of each segment\n",
    "\n",
    "# maximum number of cases\n",
    "for caseid in caseids:\n",
    "    print(f'loading {caseid}', end='...', flush=True)\n",
    "\n",
    "    # read the arterial waveform\n",
    "    arts = vitaldb.load_case(caseid, ['SNUADC/ART'], 1 / SRATE).flatten()\n",
    "\n",
    "    case_sample = 0\n",
    "    case_event = 0\n",
    "    for i in range(0, len(arts) - SRATE * (20 + (1 + MINUTES_AHEAD) * 60), 10 * SRATE):\n",
    "        segx = arts[i:i + SRATE * 20]\n",
    "        segy = arts[i + SRATE * (20 + MINUTES_AHEAD * 60):i + SRATE * (20 + (MINUTES_AHEAD + 1) * 60)]\n",
    "\n",
    "        # check the validity of this segment\n",
    "        valid = True\n",
    "        if np.isnan(segx).mean() > 0.1:\n",
    "            valid = False\n",
    "        elif np.isnan(segy).mean() > 0.1:\n",
    "            valid = False\n",
    "        elif (segx > 200).any():\n",
    "            valid = False\n",
    "        elif (segy > 200).any():\n",
    "            valid = False\n",
    "        elif (segx < 30).any():\n",
    "            valid = False\n",
    "        elif (segy < 30).any():\n",
    "            valid = False\n",
    "        elif np.max(segx) - np.min(segx) < 30:\n",
    "            valid = False\n",
    "        elif np.max(segy) - np.min(segy) < 30:\n",
    "            valid = False\n",
    "        elif (np.abs(np.diff(segx)) > 30).any():  # abrupt change -> noise\n",
    "            valid = False\n",
    "        elif (np.abs(np.diff(segy)) > 30).any():  # abrupt change -> noise\n",
    "            valid = False\n",
    "\n",
    "        # 2 sec moving avg\n",
    "        n = 2 * SRATE  \n",
    "        segy = np.nancumsum(segy, dtype=np.float32)\n",
    "        segy[n:] = segy[n:] - segy[:-n]\n",
    "        segy = segy[n - 1:] / n\n",
    "\n",
    "        evt = np.nanmax(segy) < 65\n",
    "        x.append(segx)\n",
    "        y.append(evt)\n",
    "        valid_mask.append(valid)\n",
    "        c.append(caseid)\n",
    "        \n",
    "        if valid:\n",
    "            case_sample += 1\n",
    "            if evt:\n",
    "                case_event += 1\n",
    "\n",
    "    if case_sample > 0:\n",
    "        print(\"{} samples {} ({:.1f} %) events\".format(case_sample, case_event, 100 * case_event / case_sample))\n",
    "    else:\n",
    "        print('no sample')\n",
    "\n",
    "    if len(np.unique(c)) >= MAX_CASES:\n",
    "        break\n",
    "\n",
    "# final caseids\n",
    "caseids = np.unique(c)\n",
    "\n",
    "# convert lists to numpy array\n",
    "x = np.array(x)\n",
    "y = np.array(y) \n",
    "valid_mask = np.array(valid_mask)\n",
    "c = np.array(c)\n",
    "\n",
    "# forward filling\n",
    "x = pd.DataFrame(x).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "\n",
    "# normalization\n",
    "x -= 65\n",
    "x /= 65\n",
    "\n",
    "# add axis for CNN\n",
    "x = x[...,None]  \n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting samples into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncase = len(caseids)\n",
    "ntest = int(ncase * 0.2)\n",
    "ntrain = ncase - ntest\n",
    "caseids_train = caseids[:ntrain]\n",
    "caseids_test = caseids[ncase - ntest:ncase]\n",
    "\n",
    "# splitting into train set and test set\n",
    "train_mask = np.isin(c, caseids_train)\n",
    "test_mask = np.isin(c, caseids_test)\n",
    "\n",
    "train_x = x[train_mask]\n",
    "train_y = y[train_mask]\n",
    "test_x = x[test_mask]\n",
    "test_y = y[test_mask]\n",
    "\n",
    "train_x_valid = x[train_mask & valid_mask]\n",
    "train_y_valid = y[train_mask & valid_mask]\n",
    "test_x_valid = x[test_mask & valid_mask]\n",
    "test_y_valid = y[test_mask & valid_mask]\n",
    "\n",
    "testname = '{}cases {}ahead batchsize={} total {}, train {} ({} events {:.1f}%), test {} ({} events {:.1f}%)'.format(MAX_CASES, MINUTES_AHEAD, BATCH_SIZE, len(y), \\\n",
    "    len(train_y_valid), sum(train_y_valid), 100 * np.mean(train_y_valid), \\\n",
    "    len(test_y_valid), sum(test_y_valid), 100 * np.mean(test_y_valid))\n",
    "print(testname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building and training (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "'''\n",
    "Supplementable Table S1 from https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0272055 dictates the hyperparameters used\n",
    "'''\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, size_down: bool = False) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.size_down = size_down\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n",
    "        \n",
    "        # unclear where in sequence this hsuold take place. Size down expressed in Supplemental table S1\n",
    "        if self.size_down:\n",
    "            self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv2(out)\n",
    "        out += identity\n",
    "        if self.size_down:\n",
    "            out = self.pool(out)\n",
    "        \n",
    "        '''out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out += identity\n",
    "        if self.size_down:\n",
    "            out = self.pool(out)'''\n",
    "\n",
    "        return  out\n",
    "\n",
    "class HypotensionCNN(nn.Module):\n",
    "    def __init__(self, useAbp: bool = True, useEeg: bool = False, useEcg: bool = False) -> None:\n",
    "        super(HypotensionCNN, self).__init__()\n",
    "\n",
    "        self.useAbp = useAbp\n",
    "        self.useEeg = useEeg\n",
    "        self.useEcg = useEcg\n",
    "\n",
    "        if useAbp:\n",
    "            self.abpBlock1 = ResidualBlock(1, 2, 7, 1, True)\n",
    "            self.abpBlock2 = ResidualBlock(2, 2, 7, 1, False)\n",
    "            self.abpBlock3 = ResidualBlock(2, 2, 7, 1, True)\n",
    "            self.abpBlock4 = ResidualBlock(2, 2, 7, 1, False)\n",
    "            self.abpBlock5 = ResidualBlock(2, 2, 7, 1, True)\n",
    "            self.abpBlock6 = ResidualBlock(2, 4, 7, 1, False)\n",
    "            self.abpBlock7 = ResidualBlock(2, 4, 3, 1, True)\n",
    "            self.abpBlock8 = ResidualBlock(4, 4, 3, 1, False)\n",
    "            self.abpBlock9 = ResidualBlock(4, 4, 3, 1, True)\n",
    "            self.abpBlock10 = ResidualBlock(4, 4, 3, 1, False)\n",
    "            self.abpBlock11 = ResidualBlock(4, 6, 3, 1, True)\n",
    "            self.abpBlock12 = ResidualBlock(6, 6, 3, 1, False)\n",
    "            self.abpFc = nn.Linear(6 * 120, 32)\n",
    "        \n",
    "        if useEcg:\n",
    "            self.ecgBlock1 = ResidualBlock(1, 2, 7, 1, True)\n",
    "            self.ecgBlock2 = ResidualBlock(2, 2, 7, 1, False)\n",
    "            self.ecgBlock3 = ResidualBlock(2, 2, 7, 1, True)\n",
    "            self.ecgBlock4 = ResidualBlock(2, 2, 7, 1, False)\n",
    "            self.ecgBlock5 = ResidualBlock(2, 2, 7, 1, True)\n",
    "            self.ecgBlock6 = ResidualBlock(2, 4, 7, 1, False)\n",
    "            self.ecgBlock7 = ResidualBlock(2, 4, 3, 1, True)\n",
    "            self.ecgBlock8 = ResidualBlock(4, 4, 3, 1, False)\n",
    "            self.ecgBlock9 = ResidualBlock(4, 4, 3, 1, True)\n",
    "            self.ecgBlock10 = ResidualBlock(4, 4, 3, 1, False)\n",
    "            self.ecgBlock11 = ResidualBlock(4, 6, 3, 1, True)\n",
    "            self.ecgBlock12 = ResidualBlock(6, 6, 3, 1, False)\n",
    "            self.ecgFc = nn.Linear(6 * 496, 32)\n",
    "        \n",
    "        if useEeg:\n",
    "            self.eegBlock1 = ResidualBlock(1, 2, 15, 1, True)\n",
    "            self.eegBlock2 = ResidualBlock(2, 2, 15, 1, False)\n",
    "            self.eegBlock3 = ResidualBlock(2, 2, 15, 1, True)\n",
    "            self.eegBlock4 = ResidualBlock(2, 2, 15, 1, False)\n",
    "            self.eegBlock5 = ResidualBlock(2, 2, 15, 1, True)\n",
    "            self.eegBlock6 = ResidualBlock(2, 4, 15, 1, False)\n",
    "            self.eegBlock7 = ResidualBlock(2, 4, 7, 1, True)\n",
    "            self.eegBlock8 = ResidualBlock(4, 4, 7, 1, False)\n",
    "            self.eegBlock9 = ResidualBlock(4, 4, 7, 1, True)\n",
    "            self.eegBlock10 = ResidualBlock(4, 4, 7, 1, False)\n",
    "            self.eegBlock11 = ResidualBlock(4, 6, 7, 1, True)\n",
    "            self.eegBlock12 = ResidualBlock(6, 6, 7, 1, False)\n",
    "            self.eegFc = nn.Linear(6 * 120, 32)\n",
    "\n",
    "        concatSize = 0\n",
    "        if useAbp:\n",
    "            concatSize += 32\n",
    "        if useEeg:\n",
    "            concatSize += 32\n",
    "        if useEcg:\n",
    "            concatSize += 32\n",
    "\n",
    "        self.fullLinear1 = nn.Linear(concatSize, 16)\n",
    "        self.fullLinear2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        print(x.shape)\n",
    "        # conditionally operate ABP, EEG, and ECG networks\n",
    "        if self.useAbp:\n",
    "            x = self.abpBlock1(x)\n",
    "            x = self.abpBlock2(x)\n",
    "            x = self.abpBlock3(x)\n",
    "            x = self.abpBlock4(x)\n",
    "            x = self.abpBlock5(x)\n",
    "            x = self.abpBlock6(x)\n",
    "            x = self.abpBlock7(x)\n",
    "            x = self.abpBlock8(x)\n",
    "            x = self.abpBlock9(x)\n",
    "            x = self.abpBlock10(x)\n",
    "            x = self.abpBlock11(x)\n",
    "            x = self.abpBlock12(x)\n",
    "            x = self.abpFc(torch.flatten(x, 1))\n",
    "\n",
    "        if self.useEeg:\n",
    "            y = self.ecgBlock1(y)\n",
    "            y = self.ecgBlock2(y)\n",
    "            y = self.ecgBlock3(y)\n",
    "            y = self.ecgBlock4(y)\n",
    "            y = self.ecgBlock5(y)\n",
    "            y = self.ecgBlock6(y)\n",
    "            y = self.ecgBlock7(y)\n",
    "            y = self.ecgBlock8(y)\n",
    "            y = self.ecgBlock9(y)\n",
    "            y = self.ecgBlock10(y)\n",
    "            y = self.ecgBlock11(y)\n",
    "            y = self.ecgBlock12(y)\n",
    "            y = self.ecgFc(torch.flatten(y, 1))\n",
    "        \n",
    "        if self.useEcg:\n",
    "            z = self.ecgBlock1(z)\n",
    "            z = self.ecgBlock2(z)\n",
    "            z = self.ecgBlock3(z)\n",
    "            z = self.ecgBlock4(z)\n",
    "            z = self.ecgBlock5(z)\n",
    "            z = self.ecgBlock6(z)\n",
    "            z = self.ecgBlock7(z)\n",
    "            z = self.ecgBlock8(z)\n",
    "            z = self.ecgBlock9(z)\n",
    "            z = self.ecgBlock10(z)\n",
    "            z = self.ecgBlock11(z)\n",
    "            z = self.ecgBlock12(z)\n",
    "            z = self.ecgFc(torch.flatten(z , 1))\n",
    "        \n",
    "        # concatenation\n",
    "        merged = None\n",
    "        if self.useAbp is not None and self.useEeg is not None and self.useEcg is not None:\n",
    "            merged = torch.cat(x, y, z)\n",
    "        elif self.useAbp is not None and self.useEeg is not None:\n",
    "            merged = torch.cat(x, y)\n",
    "        elif self.useAbp is not None and self.useEcg is not None:\n",
    "            merged = torch.cat(x, z)\n",
    "        elif self.useEeg is not None and self.useEcg is not None:\n",
    "            merged = torch.cat(y, z)\n",
    "        elif self.useAbp  is not None:\n",
    "            merged = x\n",
    "        elif self.useEeg  is not None:\n",
    "            merged = y\n",
    "        elif self.useEcg  is not None:\n",
    "            merged = z\n",
    "\n",
    "        out = self.fullLinear1(merged)\n",
    "        out = self.fullLinear2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useAbp = True\n",
    "useEcg = False\n",
    "useEeg = False\n",
    "\n",
    "model = HypotensionCNN(useAbp, useEeg, useEcg)\n",
    "\n",
    "n_epochs = 1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#def train_model(model, abpSet, eegSet, ecgSet, labels, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "def train_model(model, loader, n_epoch=n_epochs, optimizer=optimizer, criterion=criterion):\n",
    "    import torch.optim as optim\n",
    "\n",
    "    model.train() # prep model for training\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        curr_epoch_loss = []\n",
    "        for abp, eeg, ecg, label in tqdm(loader):\n",
    "            optimizer.zero_grad()\n",
    "            mdl = model(abp, eeg, ecg)\n",
    "            loss = criterion(mdl, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "    return model\n",
    "\n",
    "# get train data loader\n",
    "\n",
    "abpInput = torch.tensor(train_x_valid)\n",
    "ecgInput = torch.tensor(train_x_valid)\n",
    "eegInput = torch.tensor(train_x_valid)\n",
    "labelInput = torch.tensor(train_y_valid)\n",
    "\n",
    "train_dataset = TensorDataset(abpInput, ecgInput, eegInput, labelInput)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "model = train_model(model, train_loader)\n",
    "\n",
    "#print(torch.cuda.is_available())\n",
    "#print(torch.cuda.current_device())\n",
    "#print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "#model = train_model(model, train_x_valid, train_x_valid, train_x_valid, train_y_valid)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, f1_score, precision_recall_curve\n",
    "\n",
    "def eval_model(model, dataloader, device=None):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "        pred_all: prediction of model on the dataloder.\n",
    "            Should be an 2D numpy float array where the second dimension has length 2.\n",
    "        Y_test: truth labels. Should be an numpy array of ints\n",
    "    TODO:\n",
    "        evaluate the model using on the data in the dataloder.\n",
    "        Add all the prediction and truth to the corresponding list\n",
    "        Convert pred_all and Y_test to numpy arrays (of shape (n_data_points, 2))\n",
    "    \"\"\"\n",
    "    #device = device or torch.device('cpu')\n",
    "    model.eval()\n",
    "    pred_all = []\n",
    "    Y_test = []\n",
    "    for (abp, eeg, ecg, label) in dataloader:\n",
    "        # your code here\n",
    "        mdl = model(abp, eeg, ecg)\n",
    "        pred_all.append(mdl.detach())\n",
    "        Y_test.append(label.detach())\n",
    "        \n",
    "    pred_all = np.concatenate(pred_all, axis=0)\n",
    "    Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "    return pred_all, Y_test\n",
    "\n",
    "testAbpInput = torch.tensor(test_x_valid)\n",
    "testEcgInput = torch.tensor(test_x_valid)\n",
    "testEegInput = torch.tensor(test_x_valid)\n",
    "testLabelInput = torch.tensor(test_y_valid)\n",
    "\n",
    "test_dataset = TensorDataset(testAbpInput, testEcgInput, testEegInput, testLabelInput)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "pred, truth = eval_model(model, test_loader)\n",
    "\n",
    "auroc = roc_auc_score(truth, pred[:, 1])\n",
    "f1 = f1_score(truth, 1 * (pred[:, 1] > 0.5))\n",
    "\n",
    "\n",
    "test_p_valid = pred[valid_mask[test_mask]]\n",
    "\n",
    "precision, recall, thmbps = precision_recall_curve(truth, pred)\n",
    "auprc = auc(recall, precision)\n",
    "\n",
    "fpr, tpr, thmbps = roc_curve(truth, pred)\n",
    "auroc = auc(fpr, tpr)\n",
    "\n",
    "thval = 0.5\n",
    "f1 = f1_score(truth, pred > thval)\n",
    "acc = accuracy_score(truth, pred > thval)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, pred > thval).ravel()\n",
    "\n",
    "testres = 'auroc={:.3f}, auprc={:.3f} acc={:.3f}, F1={:.3f}, PPV={:.1f}, NPV={:.1f}, TN={}, fp={}, fn={}, TP={}'.format(auroc, auprc, acc, f1, tp/(tp+fp)*100, tn/(tn+fn)*100, tn, fp, fn, tp)\n",
    "print(testres)\n",
    "\n",
    "# rename final output folder\n",
    "odir = testname + ' ' + testres\n",
    "os.rename(tempdir, odir)\n",
    "\n",
    "# auroc curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.savefig('{}/auroc.png'.format(odir))\n",
    "plt.close()\n",
    "\n",
    "# auprc curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.savefig('{}/auprc.png'.format(odir))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting each case in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for caseid in caseids_test:\n",
    "    case_mask = (c[test_mask] == caseid)\n",
    "    case_len = np.sum(case_mask)\n",
    "    if case_len == 0:\n",
    "        continue\n",
    "\n",
    "    case_x = test_x[case_mask]\n",
    "    case_y = test_y[case_mask]\n",
    "    case_p = test_p[case_mask]\n",
    "    case_valid_mask = valid_mask[test_mask][case_mask]\n",
    "    case_p[~case_valid_mask] = np.nan\n",
    "    if sum(case_valid_mask) == 0:\n",
    "        continue\n",
    "    \n",
    "    # calculate error for this case\n",
    "    case_rmse = np.nanmean(np.square(case_y - case_p)) ** 0.5\n",
    "    print('{}\\t{}\\t'.format(caseid, case_rmse))\n",
    "\n",
    "    # draw\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.xlim([0, case_len])\n",
    "    t = np.arange(0, case_len)\n",
    "\n",
    "    # red bars for the event\n",
    "    ax1 = plt.gca()\n",
    "    for i in range(len(case_y)):\n",
    "        if case_y[i]:\n",
    "            ax1.axvspan(i + MINUTES_AHEAD * 6, i + MINUTES_AHEAD * 6 + 1, color='r', alpha=0.1, lw=0)\n",
    "        if not case_valid_mask[i]:\n",
    "            ax1.axvspan(i, i + 1, color='k', alpha=0.2, lw=0)\n",
    "\n",
    "    # 65 mmHg bar\n",
    "    ax1.axhline(y=65, color='r', alpha=0.5)\n",
    "    ax1.plot(t + 10, np.nanmean(test_x[case_mask], axis=1) * 65 + 65, color='r')\n",
    "    ax1.set_ylim([0, 150])\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # draw valid samples only\n",
    "    ax2.plot(t, case_p)\n",
    "    ax2.set_ylim([0, 1])\n",
    "    \n",
    "    # save\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
