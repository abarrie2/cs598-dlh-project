{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install vitaldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import vitaldb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ['PYTHONASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Set Up Local Data Caches\n",
    "\n",
    "Since the VitalDB data is static, local copies are stored and reused to avoid expensive downloads and to speed up data processing.\n",
    "\n",
    "The default directory defined below is already in the project `.gitignore` file. If later modified, it should also be added to the project `.gitignore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VITALDB_CACHE = './vitaldb_cache'\n",
    "VITAL_ALL = 'vital_all'\n",
    "VITAL_MINI = 'vital_mini'\n",
    "VITAL_METADATA = 'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $VITALDB_CACHE\n",
    "!mkdir -p $VITALDB_CACHE/$VITAL_ALL\n",
    "!mkdir -p $VITALDB_CACHE/$VITAL_MINI\n",
    "!mkdir -p $VITALDB_CACHE/$VITAL_METADATA\n",
    "!ls -l $VITALDB_CACHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# OSFS Bulk Data Download\n",
    "\n",
    "**This step is not required, but will significantly speed up downstream processing and avoid a high volume of API requests to the VitalDB web site.**\n",
    "\n",
    "The cache population code checks if OSFS bulk download data of VitalDB vital files is locally available.\n",
    "\n",
    "- Manually downloaded the OSF Store archives from the following site: https://osf.io/dtc45/\n",
    "    - `Vital Files 0001-2000`\n",
    "    - `Vital Files 2001-4000`\n",
    "    - `Vital Files 4001-6388`\n",
    "- Once the `OSF Storage (United States)` link is clicked a `Download as zip` link will appear.\n",
    "- Once downloaded, extract each of the 3 zip archives.\n",
    "- Move all files from each of the unzip directories into the `${VITALDB_CACHE}/${VITAL_ALL}` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pandas DataFrame for the specified dataset.\n",
    "#   One of 'cases', 'labs', or 'trks'\n",
    "# If the file exists locally, create and return the DataFrame.\n",
    "# Else, download and cache the csv first, then return the DataFrame.\n",
    "def vitaldb_dataframe_loader(dataset_name):\n",
    "    if dataset_name not in ['cases', 'labs', 'trks']:\n",
    "        raise ValueError(f'Invalid dataset name: {dataset_name}')\n",
    "    file_path = f'{VITALDB_CACHE}/{VITAL_METADATA}/{dataset_name}.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f'{dataset_name}.csv exists locally.')\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        print(f'downloading {dataset_name} and storing in the local cache for future reuse.')\n",
    "        df = pd.read_csv(f'https://api.vitaldb.net/{dataset_name}')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = vitaldb_dataframe_loader('cases')\n",
    "cases = cases.set_index('caseid')\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks = vitaldb_dataframe_loader('trks')\n",
    "trks = trks.set_index('caseid')\n",
    "trks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('tname').count().sort_values(by='tid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Parameters of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Hemodynamic Parameters Reference\n",
    "https://vitaldb.net/dataset/?query=overview#h.f7d712ycdpk2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Solar8000/ART_MBP**\n",
    "\n",
    "mean blood pressure\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "Solar8000/ART_MBP, Mean arterial pressure, N, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('Solar8000/ART_MBP')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "**SNUADC/ART**\n",
    "\n",
    "arterial blood pressure waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ART, Arterial pressure wave, W/500, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ART')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**SNUADC/ECG_II**\n",
    "\n",
    "electrocardiogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ECG_II, ECG lead II wave, W/500, mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ECG_II')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "**BIS/EEG1_WAV**\n",
    "\n",
    "electroencephalogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "BIS/EEG1_WAV, EEG wave from channel 1, W/128, uV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('BIS/EEG1_WAV')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Cases of Interest\n",
    "\n",
    "These are the subset of case ids for which modelling and analysis will be performed based upon inclusion criteria and waveform data availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in the paper, select cases which meet the following criteria:\n",
    "#\n",
    "# For patients, the inclusion criteria were as follows:\n",
    "# (1) adults (age >= 18)\n",
    "# (2) administered general anaesthesia\n",
    "# (3) undergone non-cardiac surgery. \n",
    "#\n",
    "# For waveform data, the inclusion criteria were as follows:\n",
    "# (1) no missing monitoring for ABP, ECG, and EEG waveforms\n",
    "# (2) no cases containing false events or non-events due to poor signal quality\n",
    "#     (checked in second stage of data preprocessing)\n",
    "\n",
    "# adult\n",
    "inclusion_1 = cases.loc[cases['age'] >= 18].index\n",
    "print(f'{len(cases)-len(inclusion_1)} cases excluded, {len(inclusion_1)} remaining due to age criteria')\n",
    "\n",
    "# general anesthesia\n",
    "inclusion_2 = cases.loc[cases['ane_type'] == 'General'].index\n",
    "print(f'{len(cases)-len(inclusion_2)} cases excluded, {len(inclusion_2)} remaining due to anesthesia criteria')\n",
    "\n",
    "# non-cardiac surgery\n",
    "inclusion_3 = cases.loc[\n",
    "    ~cases['opname'].str.contains(\"cardiac\", case=False)\n",
    "    & ~cases['opname'].str.contains(\"aneurysmal\", case=False)\n",
    "].index\n",
    "print(f'{len(cases)-len(inclusion_3)} cases excluded, {len(inclusion_3)} remaining due to non-cardiac surgery criteria')\n",
    "\n",
    "# ABP, ECG, EEG waveforms\n",
    "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']\n",
    "inclusion_4 = trks.loc[trks['tname'].isin(TRACK_NAMES)].index.value_counts()\n",
    "inclusion_4 = inclusion_4[inclusion_4 == len(TRACK_NAMES)].index\n",
    "print(f'{len(cases)-len(inclusion_4)} cases excluded, {len(inclusion_4)} remaining due to missing waveform data')\n",
    "\n",
    "cases_of_interest_idx = inclusion_1 \\\n",
    "    .intersection(inclusion_2) \\\n",
    "    .intersection(inclusion_3) \\\n",
    "    .intersection(inclusion_4)\n",
    "\n",
    "cases_of_interest = cases.loc[cases_of_interest_idx]\n",
    "\n",
    "print()\n",
    "print(f'{cases_of_interest_idx.shape[0]} out of {cases.shape[0]} total cases remaining after exclusions applied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Tracks of Interest\n",
    "\n",
    "These are the subset of tracks (waveforms) for the cases of interest identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single case maps to one or more waveform tracks. Select only the tracks required for analysis.\n",
    "trks_of_interest = trks.loc[cases_of_interest_idx][trks.loc[cases_of_interest_idx]['tname'].isin(TRACK_NAMES)]\n",
    "trks_of_interest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest_idx = trks_of_interest.set_index('tid').index\n",
    "trks_of_interest_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Build Tracks Cache for Local Processing\n",
    "\n",
    "Tracks data are large and therefore expensive to download every time used.\n",
    "By default, the vital file format stores all tracks for each case internally. Since only certain tracks per case are required, each vital file can be further truncated to only store the tracks for needed waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of cases of interest for which to download data.\n",
    "# Set to a small value for demo purposes, else set to None to disable and download all.\n",
    "MAX_CASES = None\n",
    "#MAX_CASES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the full vital file dataset is available for cases of interest.\n",
    "count_downloaded = 0\n",
    "count_present = 0\n",
    "\n",
    "#for i, idx in enumerate(cases.index):\n",
    "for i, idx in enumerate(cases_of_interest_idx):\n",
    "    if MAX_CASES and i >= MAX_CASES:\n",
    "        break\n",
    "\n",
    "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
    "    if not os.path.isfile(full_path):\n",
    "        print(f'Missing vital file: {full_path}')\n",
    "        # Download and save the file.\n",
    "        vf = vitaldb.VitalFile(idx)\n",
    "        vf.to_vital(full_path)\n",
    "        count_downloaded += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files downloaded:      {count_downloaded}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vital files to \"mini\" versions including only the subset of tracks based on TRACK_NAMES defined above.\n",
    "# Only perform conversion for the cases of interest.\n",
    "# NOTE: If this cell is interrupted, it can be restarted and will continue where it left off.\n",
    "count_minified = 0\n",
    "count_present = 0\n",
    "\n",
    "for i, idx in enumerate(cases_of_interest_idx):\n",
    "    if MAX_CASES and i >= MAX_CASES:\n",
    "        break\n",
    "    \n",
    "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
    "    mini_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{idx:04d}_mini.vital'\n",
    "    if not os.path.isfile(mini_path):\n",
    "        print(f'Creating mini vital file: {idx}')\n",
    "        vf = vitaldb.VitalFile(full_path, TRACK_NAMES)\n",
    "        vf.to_vital(mini_path)\n",
    "        count_minified += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files minified:        {count_minified}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# Track Plotting Examples\n",
    "\n",
    "These examples show multiple ways of accessing the same track data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf_path = f'{VITALDB_CACHE}/{VITAL_MINI}/0001_mini.vital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "tmp_vf.get_track_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "**`vitaldb.VitalFile.get_track_samples()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_00 = tmp_vf.get_track_samples(TRACK_NAMES[0], 1/100)\n",
    "tmp_art_00.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_00)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "**`vitaldb.VitalFile.to_numpy()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_01 = tmp_vf.to_numpy(TRACK_NAMES[0], 1/100)\n",
    "tmp_art_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_art_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "**`vitaldb.VitalFile.get_samples()`**\n",
    "\n",
    "This option allows returning timestamps as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_02 = tmp_vf.get_samples(TRACK_NAMES[0], 1/100, return_timestamp=True)\n",
    "tmp_art_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_02[0][0][-1] - tmp_art_02[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_art_02[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_02[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "**`vitaldb.vital_recs()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_03 = vitaldb.vital_recs(tmp_vf_path, TRACK_NAMES[0], 1/100)\n",
    "tmp_art_03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_art_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "**`vitaldb.dataset.load_trk()`**\n",
    "\n",
    "NOTE: This downloads a track based on raw id. Should not be needed, but showing how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_TRAK_DOWNLOAD = False\n",
    "\n",
    "if SHOW_TRAK_DOWNLOAD:\n",
    "    case_0001_trk_art_id = '724cdd7184d7886b8f7de091c5b135bd01949959'\n",
    "    tmp_art_04 = vitaldb.dataset.load_trk(case_0001_trk_art_id, 1/100)\n",
    "    print(tmp_art_04.shape)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(tmp_art_04)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Manual track download example skipped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# One Minute ABP Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf.dtstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.fromtimestamp(tmp_vf.dtstart).isoformat()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.datetime.fromtimestamp(tmp_vf.dtend).isoformat()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(tmp_vf.dtend) - datetime.datetime.fromtimestamp(tmp_vf.dtstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tmp_vf.get_dt(2024, 4, 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(d).isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = tmp_vf.get_samples(TRACK_NAMES, 1)\n",
    "type(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_00 = tmp_vf.get_track_samples(TRACK_NAMES[0], 1)\n",
    "type(tmp_art_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tmp_art_00[tmp_art_00 > 0]\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tmp_art_00[1000:10000].copy()\n",
    "z = z[z > 0]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for caseid in cases_of_interest_idx[:1]:\n",
    "    print(caseid)\n",
    "    tmp_vf_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{caseid:04d}_mini.vital'\n",
    "    print(tmp_vf_path)\n",
    "    tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "    arts = tmp_vf.to_numpy(TRACK_NAMES[0], 1/100)\n",
    "    print(arts.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hypotensive events\n",
    "# Hypotensive events are defined as a 1-minute interval with sustained ABP of less than 65 mmHg\n",
    "# Note: Hypotensive events should be at least 20 minutes apart to minimize potential residual effects from previous events\n",
    "# TODO: Implement hypotension event generation function\n",
    "# TODO: Generate hypotension events\n",
    "\n",
    "# Generate hypotension non-events\n",
    "# To sample non-events, 30-minute segments where the ABP was above 75 mmHG were selected, and then\n",
    "# three one-minute samples of each waveform were obtained from the middle of the segment\n",
    "# TODO: Implement hypotension non-event generation function\n",
    "# TODO: Generate hypotension non-events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "Adapted from: https://github.com/vitaldb/examples/blob/master/hypotension_art.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf.get_track_samples(TRACK_NAMES[0], 1/500).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf.get_track_samples(TRACK_NAMES[1], 1/500).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf.get_track_samples(TRACK_NAMES[2], 1/128).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf.get_track_samples(TRACK_NAMES[2], 1/128).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(cases_of_interest_idx, min_before_event=3, debug=False):\n",
    "    # Sampling rate for ABP and ECG, Hz. These rates should be the same. Default = 500\n",
    "    ABP_ECG_SRATE_HZ = 500\n",
    "\n",
    "    # Sampling rate for EEG. Default = 128\n",
    "    EEG_SRATE_HZ = 128\n",
    "\n",
    "    # Length of feature segment, seconds.\n",
    "    FEATURE_LENGTH_SEC = 60\n",
    "    # Look ahead to predict hypotension, seconds.\n",
    "    MIDDLE_LENGTH_SEC  = 60 * min_before_event\n",
    "    # Length of label segment, seconds.\n",
    "    LABEL_LENGTH_SEC   = 60\n",
    "\n",
    "    # Length to move down the ABP track for starting a new analysis segment, seconds.\n",
    "    NEW_SEGMENT_OFFSET_SEC = 10\n",
    "\n",
    "    # Final dataset for training and testing the model.\n",
    "    # inputs with shape of (segments, timepoints)\n",
    "    x_abp = []\n",
    "    x_ecg = []\n",
    "    x_eeg = []\n",
    "\n",
    "    # output with shape of (segments)\n",
    "    y = []\n",
    "\n",
    "    # validity of each segement; only valid segments are used for model building\n",
    "    valid_mask = []\n",
    "\n",
    "    # caseid of each segment\n",
    "    case_id_per_segment = []\n",
    "\n",
    "    # Process each case and extract segments. For each segment identify presence of an event in the label zone.\n",
    "    time_start = timer()\n",
    "    \n",
    "    count_cases = len(cases_of_interest_idx)\n",
    "\n",
    "    for case_count, caseid in enumerate(cases_of_interest_idx):\n",
    "        if debug:\n",
    "            print(f'Loading case: {caseid:04d}, ({case_count + 1} of {count_cases})')\n",
    "\n",
    "        # read the arterial waveform\n",
    "        tmp_vf_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{caseid:04d}_mini.vital'\n",
    "        tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "\n",
    "        abp = tmp_vf.to_numpy(TRACK_NAMES[0], 1/ABP_ECG_SRATE_HZ).ravel()\n",
    "        ecg = tmp_vf.to_numpy(TRACK_NAMES[1], 1/ABP_ECG_SRATE_HZ).ravel()\n",
    "        eeg = tmp_vf.to_numpy(TRACK_NAMES[2], 1/EEG_SRATE_HZ).ravel()\n",
    "\n",
    "        # EEG - Different sample rate, process alone\n",
    "        if debug:\n",
    "            print(f'Length of {TRACK_NAMES[2]}:     {eeg.shape[0]}')\n",
    "\n",
    "        print_first_segment = True\n",
    "\n",
    "        last_sample_start_index = len(eeg) - EEG_SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC + LABEL_LENGTH_SEC)\n",
    "        sample_index_offset = NEW_SEGMENT_OFFSET_SEC * EEG_SRATE_HZ\n",
    "\n",
    "        for i in range(0, last_sample_start_index, sample_index_offset):\n",
    "            segx_start = i\n",
    "            segx_end   = i + EEG_SRATE_HZ * FEATURE_LENGTH_SEC\n",
    "            segx = eeg[segx_start:segx_end]\n",
    "\n",
    "            if debug and print_first_segment:\n",
    "                print(f'  Feature Segment Length:   {segx.shape[0]} pts, {segx.shape[0] / EEG_SRATE_HZ} sec')\n",
    "                print_first_segment = False\n",
    "\n",
    "            # handle eeg, only care about extracting data from the same time interval used for abp\n",
    "            x_eeg.append(eeg[segx_start:segx_end])    \n",
    "\n",
    "        # ABP and ECG - Shared sample rate, process together    \n",
    "        if debug:\n",
    "            print(f'Length of {TRACK_NAMES[0]}:       {abp.shape[0]}')\n",
    "            print(f'Length of {TRACK_NAMES[1]}:    {ecg.shape[0]}')\n",
    "\n",
    "        segment_count = 0\n",
    "        segment_valid = 0\n",
    "        segment_event = 0\n",
    "        print_first_segment = True\n",
    "\n",
    "        last_sample_start_index = len(abp) - ABP_ECG_SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC + LABEL_LENGTH_SEC)\n",
    "        sample_index_offset = NEW_SEGMENT_OFFSET_SEC * ABP_ECG_SRATE_HZ\n",
    "\n",
    "        for i in range(0, last_sample_start_index, sample_index_offset):\n",
    "            segment_count += 1\n",
    "\n",
    "            segx_start = i\n",
    "            segx_end   = i + ABP_ECG_SRATE_HZ * FEATURE_LENGTH_SEC\n",
    "            segx = abp[segx_start:segx_end]\n",
    "\n",
    "            segy_start = i + ABP_ECG_SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC)\n",
    "            segy_end   = i + ABP_ECG_SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC + LABEL_LENGTH_SEC)\n",
    "            segy = abp[segy_start:segy_end]\n",
    "\n",
    "            if debug and print_first_segment:\n",
    "                print(f'  Feature Segment Length:   {segx.shape[0]} pts, {segx.shape[0] / ABP_ECG_SRATE_HZ} sec')\n",
    "                print(f'  Middle Segment Length:    {segy_start - segx_end} pts, {(segy_start - segx_end) / ABP_ECG_SRATE_HZ} sec')\n",
    "                print(f'  Label Segment Length:     {segy.shape[0]} pts, {segy.shape[0] / ABP_ECG_SRATE_HZ} sec')\n",
    "                print_first_segment = False\n",
    "\n",
    "            # check the validity of this segment\n",
    "            valid = True\n",
    "            if np.isnan(segx).mean() > 0.1:\n",
    "                valid = False\n",
    "            elif np.isnan(segy).mean() > 0.1:\n",
    "                valid = False\n",
    "            elif (segx > 200).any():\n",
    "                valid = False\n",
    "            elif (segy > 200).any():\n",
    "                valid = False\n",
    "            elif (segx < 30).any():\n",
    "                valid = False\n",
    "            elif (segy < 30).any():\n",
    "                valid = False\n",
    "            elif np.max(segx) - np.min(segx) < 30:\n",
    "                valid = False\n",
    "            elif np.max(segy) - np.min(segy) < 30:\n",
    "                valid = False\n",
    "            elif (np.abs(np.diff(segx)) > 30).any():  # abrupt change -> noise\n",
    "                valid = False\n",
    "            elif (np.abs(np.diff(segy)) > 30).any():  # abrupt change -> noise\n",
    "                valid = False\n",
    "\n",
    "            # 2 sec moving avg\n",
    "            n = 2 * ABP_ECG_SRATE_HZ  \n",
    "            segy = np.nancumsum(segy, dtype=np.float32)\n",
    "            segy[n:] = segy[n:] - segy[:-n]\n",
    "            segy = segy[n - 1:] / n\n",
    "\n",
    "            # forward filling - do this per case to avoid massive resource utilization at the end.\n",
    "            segx = pd.DataFrame(segx).fillna(method='ffill', axis=0).fillna(method='bfill', axis=0)[0].values\n",
    "\n",
    "            # Identify IOH event as < 65mm HG\n",
    "            evt = np.nanmax(segy) < 65\n",
    "            x_abp.append(segx)\n",
    "            y.append(evt)\n",
    "            valid_mask.append(valid)\n",
    "            case_id_per_segment.append(caseid)\n",
    "\n",
    "            # handle ecg, only care about extracting the same segment used for abp.\n",
    "            # data is already time aligned and has same sample rate.\n",
    "            x_ecg.append(ecg[segx_start:segx_end])\n",
    "\n",
    "            if valid:\n",
    "                segment_valid += 1\n",
    "                if evt:\n",
    "                    segment_event += 1\n",
    "\n",
    "        if debug:\n",
    "            print(f'Total Segments Evaluated:   {segment_count}')\n",
    "            segment_valid_percent = 0 if segment_count == 0 else 100 * segment_valid / segment_count \n",
    "            print(f'  Segments Valid:           {segment_valid}, {segment_valid_percent:.1f}%')\n",
    "            segment_event_percent = 0 if segment_valid == 0 else 100 * segment_event / segment_valid\n",
    "            print(f'  Segments with Event:      {segment_event}, {segment_event_percent:.1f}%')\n",
    "            time_delta = np.round(timer() - time_start, 3)\n",
    "            print(f'Total Processing Time:      {time_delta:.4f} sec')\n",
    "            print()\n",
    "\n",
    "    # final caseids\n",
    "    caseids = np.unique(case_id_per_segment)\n",
    "\n",
    "    # convert lists to numpy array\n",
    "    x_abp = np.array(x_abp)\n",
    "    y = np.array(y) \n",
    "    valid_mask = np.array(valid_mask)\n",
    "    case_id_per_segment = np.array(case_id_per_segment)\n",
    "\n",
    "    # forward filling\n",
    "    #x_abp = pd.DataFrame(x_abp).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "    #x_abp = pd.DataFrame(x_abp).values\n",
    "\n",
    "    # ABP normalization\n",
    "    x_abp -= 65\n",
    "    x_abp /= 65\n",
    "\n",
    "    # add axis for CNN; i.e. (# samples, feature segment length) -> (# samples, feature segment length, 1)\n",
    "    x_abp = x_abp[..., None]\n",
    "\n",
    "    # handle ecg\n",
    "    x_ecg = np.array(x_ecg)\n",
    "    x_ecg = x_ecg[..., None]\n",
    "\n",
    "    # handle eeg\n",
    "    x_eeg = np.array(x_eeg)\n",
    "    x_eeg = x_eeg[..., None]\n",
    "\n",
    "    # total processing time\n",
    "    time_end = timer()\n",
    "    time_delta = np.round(time_end - time_start, 3)\n",
    "\n",
    "    if debug:\n",
    "        print('OVERALL SUMMARY')\n",
    "        print(f'Total Processing Time:      {time_delta:.4f} sec')\n",
    "        print(f'Total Cases Processed:      {caseids.shape[0]}')\n",
    "        print(f'Total Segments Evaluated:   {x_abp.shape[0]}')\n",
    "\n",
    "        segment_valid_count = np.sum(valid_mask)\n",
    "        segment_valid_percent = 0 if x_abp.shape[0] == 0 else 100 * segment_valid_count / x_abp.shape[0] \n",
    "        print(f'  Segments Valid:           {segment_valid_count}, {segment_valid_percent:.1f}%')\n",
    "        segment_event_count = np.sum(y & valid_mask)\n",
    "        segment_event_percent = 0 if y.shape[0] == 0 else 100 * segment_event_count / y.shape[0]\n",
    "        print(f'  Segments with Event:      {segment_event_count}, {segment_event_percent:.1f}%')\n",
    "\n",
    "\n",
    "        print(f'Valid Samples Generated:    {(100 * np.mean(valid_mask)):.1f}%')\n",
    "        print()\n",
    "        print(f'Valid Mask Shape:           {valid_mask.shape}')\n",
    "        print(f'X_ABP Shape:                {x_abp.shape}')\n",
    "        print(f'X_ECG Shape:                {x_ecg.shape}')\n",
    "        print(f'X_EEG Shape:                {x_eeg.shape}')\n",
    "        print(f'Y Shape:                    {y.shape}')\n",
    "        print(f'CIPS Shape:                 {case_id_per_segment.shape}')\n",
    "    \n",
    "    return (x_abp, x_ecg, x_eeg, y, valid_mask, case_id_per_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_COUNT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_abp, x_ecg, x_eeg, y, valid_mask, case_id_per_segment = extract_segments(\n",
    "    cases_of_interest_idx[:CASE_COUNT], min_before_event=3, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_abp, x_ecg, x_eeg, y, valid_mask = extract_segments(\n",
    "    cases_of_interest_idx[:CASE_COUNT], min_before_event=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_abp, x_ecg, x_eeg, y, valid_mask = extract_segments(\n",
    "    cases_of_interest_idx[:CASE_COUNT], min_before_event=10, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_abp, x_ecg, x_eeg, y, valid_mask = extract_segments(\n",
    "    cases_of_interest_idx[:CASE_COUNT], min_before_event=15, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y & valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mask[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_abp[190].ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_ecg[190].ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_eeg[190].ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.DataFrame(x_abp.squeeze())\n",
    "xx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
