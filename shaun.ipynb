{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install vitaldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import vitaldb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ['PYTHONASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Set Up Local Data Caches\n",
    "\n",
    "Since the VitalDB data is static, local copies are stored and reused to avoid expensive downloads and to speed up data processing.\n",
    "\n",
    "The default directory defined below is already in the project `.gitignore` file. If later modified, it should also be added to the project `.gitignore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VITALDB_CACHE = './vitaldb_cache'\n",
    "VITAL_ALL = 'vital_all'\n",
    "VITAL_MINI = 'vital_mini'\n",
    "VITAL_METADATA = 'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $VITALDB_CACHE\n",
    "!mkdir -p $VITALDB_CACHE/$VITAL_ALL\n",
    "!mkdir -p $VITALDB_CACHE/$VITAL_MINI\n",
    "!mkdir -p $VITALDB_CACHE/$VITAL_METADATA\n",
    "!ls -l $VITALDB_CACHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# OSFS Bulk Data Download\n",
    "\n",
    "**This step is not required, but will significantly speed up downstream processing and avoid a high volume of API requests to the VitalDB web site.**\n",
    "\n",
    "The cache population code checks if OSFS bulk download data of VitalDB vital files is locally available.\n",
    "\n",
    "- Manually downloaded the OSF Store archives from the following site: https://osf.io/dtc45/\n",
    "    - `Vital Files 0001-2000`\n",
    "    - `Vital Files 2001-4000`\n",
    "    - `Vital Files 4001-6388`\n",
    "- Once the `OSF Storage (United States)` link is clicked a `Download as zip` link will appear.\n",
    "- Once downloaded, extract each of the 3 zip archives.\n",
    "- Move all files from each of the unzip directories into the `${VITALDB_CACHE}/${VITAL_ALL}` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pandas DataFrame for the specified dataset.\n",
    "#   One of 'cases', 'labs', or 'trks'\n",
    "# If the file exists locally, create and return the DataFrame.\n",
    "# Else, download and cache the csv first, then return the DataFrame.\n",
    "def vitaldb_dataframe_loader(dataset_name):\n",
    "    if dataset_name not in ['cases', 'labs', 'trks']:\n",
    "        raise ValueError(f'Invalid dataset name: {dataset_name}')\n",
    "    file_path = f'{VITALDB_CACHE}/{VITAL_METADATA}/{dataset_name}.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f'{dataset_name}.csv exists locally.')\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        print(f'downloading {dataset_name} and storing in the local cache for future reuse.')\n",
    "        df = pd.read_csv(f'https://api.vitaldb.net/{dataset_name}')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = vitaldb_dataframe_loader('cases')\n",
    "cases = cases.set_index('caseid')\n",
    "cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks = vitaldb_dataframe_loader('trks')\n",
    "trks = trks.set_index('caseid')\n",
    "trks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('caseid')[['tid']].count().hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks.groupby('tname').count().sort_values(by='tid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Parameters of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Hemodynamic Parameters Reference\n",
    "https://vitaldb.net/dataset/?query=overview#h.f7d712ycdpk2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Solar8000/ART_MBP**\n",
    "\n",
    "mean blood pressure\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "Solar8000/ART_MBP, Mean arterial pressure, N, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('Solar8000/ART_MBP')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "**SNUADC/ART**\n",
    "\n",
    "arterial blood pressure waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ART, Arterial pressure wave, W/500, mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ART')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**SNUADC/ECG_II**\n",
    "\n",
    "electrocardiogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "SNUADC/ECG_II, ECG lead II wave, W/500, mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('SNUADC/ECG_II')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "**BIS/EEG1_WAV**\n",
    "\n",
    "electroencephalogram waveform\n",
    "\n",
    "Parameter, Description, Type/Hz, Unit\n",
    "\n",
    "BIS/EEG1_WAV, EEG wave from channel 1, W/128, uV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks[trks['tname'].str.contains('BIS/EEG1_WAV')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Cases of Interest\n",
    "\n",
    "These are the subset of case ids for which modelling and analysis will be performed based upon inclusion criteria and waveform data availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in the paper, select cases which meet the following criteria:\n",
    "#\n",
    "# For patients, the inclusion criteria were as follows:\n",
    "# (1) adults (age >= 18)\n",
    "# (2) administered general anaesthesia\n",
    "# (3) undergone non-cardiac surgery. \n",
    "#\n",
    "# For waveform data, the inclusion criteria were as follows:\n",
    "# (1) no missing monitoring for ABP, ECG, and EEG waveforms\n",
    "# (2) no cases containing false events or non-events due to poor signal quality\n",
    "#     (checked in second stage of data preprocessing)\n",
    "\n",
    "# adult\n",
    "inclusion_1 = cases.loc[cases['age'] >= 18].index\n",
    "print(f'{len(cases)-len(inclusion_1)} cases excluded, {len(inclusion_1)} remaining due to age criteria')\n",
    "\n",
    "# general anesthesia\n",
    "inclusion_2 = cases.loc[cases['ane_type'] == 'General'].index\n",
    "print(f'{len(cases)-len(inclusion_2)} cases excluded, {len(inclusion_2)} remaining due to anesthesia criteria')\n",
    "\n",
    "# non-cardiac surgery\n",
    "inclusion_3 = cases.loc[\n",
    "    ~cases['opname'].str.contains(\"cardiac\", case=False)\n",
    "    & ~cases['opname'].str.contains(\"aneurysmal\", case=False)\n",
    "].index\n",
    "print(f'{len(cases)-len(inclusion_3)} cases excluded, {len(inclusion_3)} remaining due to non-cardiac surgery criteria')\n",
    "\n",
    "# ABP, ECG, EEG waveforms\n",
    "TRACK_NAMES = ['SNUADC/ART', 'SNUADC/ECG_II', 'BIS/EEG1_WAV']\n",
    "inclusion_4 = trks.loc[trks['tname'].isin(TRACK_NAMES)].index.value_counts()\n",
    "inclusion_4 = inclusion_4[inclusion_4 == len(TRACK_NAMES)].index\n",
    "print(f'{len(cases)-len(inclusion_4)} cases excluded, {len(inclusion_4)} remaining due to missing waveform data')\n",
    "\n",
    "cases_of_interest_idx = inclusion_1 \\\n",
    "    .intersection(inclusion_2) \\\n",
    "    .intersection(inclusion_3) \\\n",
    "    .intersection(inclusion_4)\n",
    "\n",
    "cases_of_interest = cases.loc[cases_of_interest_idx]\n",
    "\n",
    "print()\n",
    "print(f'{cases_of_interest_idx.shape[0]} out of {cases.shape[0]} total cases remaining after exclusions applied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Tracks of Interest\n",
    "\n",
    "These are the subset of tracks (waveforms) for the cases of interest identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single case maps to one or more waveform tracks. Select only the tracks required for analysis.\n",
    "trks_of_interest = trks.loc[cases_of_interest_idx][trks.loc[cases_of_interest_idx]['tname'].isin(TRACK_NAMES)]\n",
    "trks_of_interest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trks_of_interest_idx = trks_of_interest.set_index('tid').index\n",
    "trks_of_interest_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Build Tracks Cache for Local Processing\n",
    "\n",
    "Tracks data are large and therefore expensive to download every time used.\n",
    "By default, the vital file format stores all tracks for each case internally. Since only certain tracks per case are required, each vital file can be further truncated to only store the tracks for needed waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of cases of interest for which to download data.\n",
    "# Set to a small value for demo purposes, else set to None to disable and download all.\n",
    "MAX_CASES = None\n",
    "#MAX_CASES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the full vital file dataset is available for cases of interest.\n",
    "count_downloaded = 0\n",
    "count_present = 0\n",
    "\n",
    "#for i, idx in enumerate(cases.index):\n",
    "for i, idx in enumerate(cases_of_interest_idx):\n",
    "    if MAX_CASES and i >= MAX_CASES:\n",
    "        break\n",
    "\n",
    "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
    "    if not os.path.isfile(full_path):\n",
    "        print(f'Missing vital file: {full_path}')\n",
    "        # Download and save the file.\n",
    "        vf = vitaldb.VitalFile(idx)\n",
    "        vf.to_vital(full_path)\n",
    "        count_downloaded += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files downloaded:      {count_downloaded}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vital files to \"mini\" versions including only the subset of tracks based on TRACK_NAMES defined above.\n",
    "# Only perform conversion for the cases of interest.\n",
    "# NOTE: If this cell is interrupted, it can be restarted and will continue where it left off.\n",
    "count_minified = 0\n",
    "count_present = 0\n",
    "\n",
    "for i, idx in enumerate(cases_of_interest_idx):\n",
    "    if MAX_CASES and i >= MAX_CASES:\n",
    "        break\n",
    "    \n",
    "    full_path = f'{VITALDB_CACHE}/{VITAL_ALL}/{idx:04d}.vital'\n",
    "    mini_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{idx:04d}_mini.vital'\n",
    "    if not os.path.isfile(mini_path):\n",
    "        print(f'Creating mini vital file: {idx}')\n",
    "        vf = vitaldb.VitalFile(full_path, TRACK_NAMES)\n",
    "        vf.to_vital(mini_path)\n",
    "        count_minified += 1\n",
    "    else:\n",
    "        count_present += 1\n",
    "\n",
    "print()\n",
    "print(f'Count of cases of interest:           {cases_of_interest_idx.shape[0]}')\n",
    "print(f'Count of vital files minified:        {count_minified}')\n",
    "print(f'Count of vital files already present: {count_present}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# Track Plotting Examples\n",
    "\n",
    "These examples show multiple ways of accessing the same track data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf_path = f'{VITALDB_CACHE}/{VITAL_MINI}/0001_mini.vital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "tmp_vf.get_track_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "**`vitaldb.VitalFile.get_track_samples()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_00 = tmp_vf.get_track_samples(TRACK_NAMES[0], 1/100)\n",
    "tmp_art_00.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_00)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "**`vitaldb.VitalFile.to_numpy()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_01 = tmp_vf.to_numpy(TRACK_NAMES[0], 1/100)\n",
    "tmp_art_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_art_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "**`vitaldb.VitalFile.get_samples()`**\n",
    "\n",
    "This option allows returning timestamps as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_02 = tmp_vf.get_samples(TRACK_NAMES[0], 1/100, return_timestamp=True)\n",
    "tmp_art_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_02[0][0][-1] - tmp_art_02[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_art_02[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_02[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "**`vitaldb.vital_recs()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_03 = vitaldb.vital_recs(tmp_vf_path, TRACK_NAMES[0], 1/100)\n",
    "tmp_art_03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmp_art_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(tmp_art_03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "**`vitaldb.dataset.load_trk()`**\n",
    "\n",
    "NOTE: This downloads a track based on raw id. Should not be needed, but showing how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_TRAK_DOWNLOAD = False\n",
    "\n",
    "if SHOW_TRAK_DOWNLOAD:\n",
    "    case_0001_trk_art_id = '724cdd7184d7886b8f7de091c5b135bd01949959'\n",
    "    tmp_art_04 = vitaldb.dataset.load_trk(case_0001_trk_art_id, 1/100)\n",
    "    print(tmp_art_04.shape)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(tmp_art_04)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Manual track download example skipped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# One Minute ABP Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_vf.dtstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.fromtimestamp(tmp_vf.dtstart).isoformat()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.datetime.fromtimestamp(tmp_vf.dtend).isoformat()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(tmp_vf.dtend) - datetime.datetime.fromtimestamp(tmp_vf.dtstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tmp_vf.get_dt(2024, 4, 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(d).isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = tmp_vf.get_samples(TRACK_NAMES, 1)\n",
    "type(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_art_00 = tmp_vf.get_track_samples(TRACK_NAMES[0], 1)\n",
    "type(tmp_art_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tmp_art_00[tmp_art_00 > 0]\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tmp_art_00[1000:10000].copy()\n",
    "z = z[z > 0]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for caseid in cases_of_interest_idx[:1]:\n",
    "    print(caseid)\n",
    "    tmp_vf_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{caseid:04d}_mini.vital'\n",
    "    print(tmp_vf_path)\n",
    "    tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "    arts = tmp_vf.to_numpy(TRACK_NAMES[0], 1/100)\n",
    "    print(arts.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zzz = vitaldb.load_case(1, ['SNUADC/ART'], 1 / 100).flatten()\n",
    "#zzz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hypotensive events\n",
    "# Hypotensive events are defined as a 1-minute interval with sustained ABP of less than 65 mmHg\n",
    "# Note: Hypotensive events should be at least 20 minutes apart to minimize potential residual effects from previous events\n",
    "# TODO: Implement hypotension event generation function\n",
    "# TODO: Generate hypotension events\n",
    "\n",
    "# Generate hypotension non-events\n",
    "# To sample non-events, 30-minute segments where the ABP was above 75 mmHG were selected, and then\n",
    "# three one-minute samples of each waveform were obtained from the middle of the segment\n",
    "# TODO: Implement hypotension non-event generation function\n",
    "# TODO: Generate hypotension non-events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "Adapted from: https://github.com/vitaldb/examples/blob/master/hypotension_art.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of cases to process.\n",
    "COUNT_CASES = 2\n",
    "# Sampling rate for the arterial waveform signal, Hz.\n",
    "SRATE_HZ    = 100\n",
    "\n",
    "# Length of feature segment, seconds.\n",
    "FEATURE_LENGTH_SEC = 20\n",
    "# Look ahead to predict hypotension, seconds.\n",
    "MIDDLE_LENGTH_SEC  = 60\n",
    "# Length of label segment, seconds.\n",
    "LABEL_LENGTH_SEC   = 60\n",
    "\n",
    "# Length to move down the track for starting a new analysis segment, seconds.\n",
    "NEW_SEGMENT_OFFSET_SEC = 10\n",
    "\n",
    "# Final dataset for training and testing the model.\n",
    "x = []              # input with shape of (segements, timepoints)\n",
    "y = []              # output with shape of (segments)\n",
    "valid_mask = []     # validity of each segement\n",
    "c = []              # caseid of each segment\n",
    "\n",
    "# maximum number of cases\n",
    "for caseid in cases_of_interest_idx[:COUNT_CASES]:\n",
    "    print(f'Loading case: {caseid:04d}')\n",
    "\n",
    "    # read the arterial waveform\n",
    "    tmp_vf_path = f'{VITALDB_CACHE}/{VITAL_MINI}/{caseid:04d}_mini.vital'\n",
    "    tmp_vf = vitaldb.VitalFile(tmp_vf_path)\n",
    "    \n",
    "    arts = tmp_vf.to_numpy(TRACK_NAMES[0], 1/SRATE_HZ).ravel()\n",
    "    print(f'Length of {TRACK_NAMES[0]}:     {arts.shape[0]}')\n",
    "\n",
    "    segment_count = 0\n",
    "    case_sample = 0\n",
    "    case_event = 0\n",
    "    print_first_segment = True\n",
    "\n",
    "    last_sample_start_index = len(arts) - SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC + LABEL_LENGTH_SEC)\n",
    "    sample_index_offset = NEW_SEGMENT_OFFSET_SEC * SRATE_HZ\n",
    "    \n",
    "    for i in range(0, last_sample_start_index, sample_index_offset):\n",
    "        segment_count += 1\n",
    "        \n",
    "        segx_start = i\n",
    "        segx_end   = i + SRATE_HZ * FEATURE_LENGTH_SEC\n",
    "        segx = arts[segx_start:segx_end]\n",
    "        \n",
    "        segy_start = i + SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC)\n",
    "        segy_end   = i + SRATE_HZ * (FEATURE_LENGTH_SEC + MIDDLE_LENGTH_SEC + LABEL_LENGTH_SEC)\n",
    "        segy = arts[segy_start:segy_end]\n",
    "        \n",
    "        if print_first_segment:\n",
    "            print(f'Feature Segment Length:   {segx.shape[0]} pts, {segx.shape[0] / SRATE_HZ} sec')\n",
    "            print(f'Middle Segment Length:    {segy_start - segx_end} pts, {(segy_start - segx_end) / SRATE_HZ} sec')\n",
    "            print(f'Label Segment Length:     {segy.shape[0]} pts, {segy.shape[0] / SRATE_HZ} sec')\n",
    "            print_first_segment = False\n",
    "\n",
    "        # check the validity of this segment\n",
    "        valid = True\n",
    "        if np.isnan(segx).mean() > 0.1:\n",
    "            valid = False\n",
    "        elif np.isnan(segy).mean() > 0.1:\n",
    "            valid = False\n",
    "        elif (segx > 200).any():\n",
    "            valid = False\n",
    "        elif (segy > 200).any():\n",
    "            valid = False\n",
    "        elif (segx < 30).any():\n",
    "            valid = False\n",
    "        elif (segy < 30).any():\n",
    "            valid = False\n",
    "        elif np.max(segx) - np.min(segx) < 30:\n",
    "            valid = False\n",
    "        elif np.max(segy) - np.min(segy) < 30:\n",
    "            valid = False\n",
    "        elif (np.abs(np.diff(segx)) > 30).any():  # abrupt change -> noise\n",
    "            valid = False\n",
    "        elif (np.abs(np.diff(segy)) > 30).any():  # abrupt change -> noise\n",
    "            valid = False\n",
    "\n",
    "        # 2 sec moving avg\n",
    "        n = 2 * SRATE_HZ  \n",
    "        segy = np.nancumsum(segy, dtype=np.float32)\n",
    "        segy[n:] = segy[n:] - segy[:-n]\n",
    "        segy = segy[n - 1:] / n\n",
    "\n",
    "        evt = np.nanmax(segy) < 65\n",
    "        x.append(segx)\n",
    "        y.append(evt)\n",
    "        valid_mask.append(valid)\n",
    "        c.append(caseid)\n",
    "        \n",
    "        if valid:\n",
    "            case_sample += 1\n",
    "            if evt:\n",
    "                case_event += 1\n",
    "\n",
    "    \n",
    "    print(f'Total Segments Evaluated: {segment_count}')\n",
    "    print(f'Total Samples Generated:  {case_sample}')\n",
    "    case_event_percent = 0 if case_sample == 0 else 100 * case_event / case_sample\n",
    "    print(f'Total Events Detected:    {case_event}, {case_event_percent:.1f}%')\n",
    "    print()\n",
    "\n",
    "\n",
    "# final caseids\n",
    "caseids = np.unique(c)\n",
    "\n",
    "# convert lists to numpy array\n",
    "x = np.array(x)\n",
    "y = np.array(y) \n",
    "valid_mask = np.array(valid_mask)\n",
    "c = np.array(c)\n",
    "\n",
    "# forward filling\n",
    "x = pd.DataFrame(x).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "\n",
    "# normalization\n",
    "x -= 65\n",
    "x /= 65\n",
    "\n",
    "# add axis for CNN\n",
    "x = x[...,None]  \n",
    "\n",
    "print(f'Total Cases Processed:    {caseids.shape}')\n",
    "print(f'Valid Mask Shape:         {valid_mask.shape}')\n",
    "print(f'X Shape:                  {x.shape}')\n",
    "print(f'Y Shape:                  {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "Loading case: 0001\n",
    "Length of SNUADC/ART:     1154115\n",
    "Feature Segment Length:   2000 pts, 20.0 sec\n",
    "Middle Segment Length:    6000 pts, 60.0 sec\n",
    "Label Segment Length:     6000 pts, 60.0 sec\n",
    "Total Segments Evaluated: 1141\n",
    "Total Samples Generated:  818\n",
    "Total Events Detected:    74, 9.0%\n",
    "\n",
    "Loading case: 0003\n",
    "Length of SNUADC/ART:     439404\n",
    "Feature Segment Length:   2000 pts, 20.0 sec\n",
    "Middle Segment Length:    6000 pts, 60.0 sec\n",
    "Label Segment Length:     6000 pts, 60.0 sec\n",
    "Total Segments Evaluated: 426\n",
    "Total Samples Generated:  0\n",
    "Total Events Detected:    0, 0.0%\n",
    "\n",
    "Total Cases Processed:    (2,)\n",
    "Valid Mask Shape:         (1567,)\n",
    "X Shape:                  (1567, 2000, 1)\n",
    "Y Shape:                  (1567,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "2000 * 1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[0].ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y & valid_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
